2/6/23, 5:54‚ÄØPM - Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them. Tap to learn more.
2/6/23, 5:55‚ÄØPM - Amit: Farithi send karto pdf
2/6/23, 5:55‚ÄØPM - Amit: Pls
2/6/23, 5:55‚ÄØPM - Siddharth: <Media omitted>
2/6/23, 5:55‚ÄØPM - Amit: Download fail aave chhe koi biji karne
2/6/23, 5:56‚ÄØPM - Amit: Me farithi WhatsApp install karyu etle
2/6/23, 5:56‚ÄØPM - Siddharth: <Media omitted>
2/6/23, 5:56‚ÄØPM - Amit: You deleted this message
2/6/23, 5:57‚ÄØPM - Amit: Same tu aapni previous chat mathi send kare chho?
2/6/23, 5:57‚ÄØPM - Siddharth: Na
2/6/23, 5:57‚ÄØPM - Siddharth: Bija group
2/6/23, 5:57‚ÄØPM - Amit: To kem download nathi thatu
2/6/23, 5:57‚ÄØPM - Siddharth: Idk
2/6/23, 5:57‚ÄØPM - Amit: Tara local device mathi karto
2/6/23, 5:59‚ÄØPM - Siddharth: <Media omitted>
2/6/23, 5:59‚ÄØPM - Amit: Still not able to download
2/6/23, 5:59‚ÄØPM - Siddharth: Google kar
2/6/23, 6:18‚ÄØPM - Amit: Ok problem solved
2/6/23, 6:19‚ÄØPM - Amit: But lose my previous chat history üò•
2/7/23, 10:31‚ÄØAM - Amit: Major project ma kai code ready karyo presentation mate?
2/7/23, 11:14‚ÄØAM - Siddharth: Na, aaje
2/7/23, 11:15‚ÄØAM - Amit: ok
2/7/23, 1:40‚ÄØPM - Amit: Rahul bhaie transfer kari didha paisa?
2/7/23, 4:55‚ÄØPM - Siddharth: I don't think
2/7/23, 5:54‚ÄØPM - Amit: Me rahul bhai ne msg kari didho chhe
2/7/23, 5:54‚ÄØPM - Amit: Tu mane mara gpay kari deje mare emathi hostel ni fees bharvani chhe.
2/7/23, 6:13‚ÄØPM - Siddharth: üëç
2/8/23, 11:46‚ÄØAM - Siddharth: Kyare aave chhe?
2/8/23, 11:46‚ÄØAM - Amit: Aaje bapore pachhi
2/8/23, 11:46‚ÄØAM - Siddharth: Okay
2/8/23, 11:46‚ÄØAM - Siddharth: I am writing code for 3 to 4 different types of neural networks for major project
2/8/23, 11:46‚ÄØAM - Siddharth: Baaki PPT ratre banavie, okay?
2/8/23, 11:47‚ÄØAM - Amit: E to banavi daishu 30 min ma
2/8/23, 11:47‚ÄØAM - Siddharth: Ha
2/8/23, 12:54‚ÄØPM - Siddharth: Also, tu hostel aave etle hu paisa transfer kari dau tane
2/8/23, 1:01‚ÄØPM - Amit: Ok no problem üëç
2/8/23, 10:00‚ÄØPM - Siddharth: CNN
MobileNet
VGG19
DenseNet
2/9/23, 12:12‚ÄØAM - Siddharth: Deep learning models have been applied in the field of dermatology with success, mainly for the classification of skin diseases.

Convolutional Neural Networks (CNNs) have been the most commonly used architecture in the medical imaging domain, including skin disease diagnosis.

Transfer learning has been widely adopted in skin disease diagnosis, where pre-trained CNNs are fine-tuned on the skin disease dataset to improve accuracy.

The quality of the dataset is crucial for the performance of the deep learning model, and imbalanced datasets can lead to biased results.

The integration of dermatoscopic images and demographic information has shown to improve the performance of deep learning models in skin disease diagnosis.

The use of data augmentation techniques, such as random cropping, flipping, and rotation, has been demonstrated to increase the generalization of the model and prevent overfitting.

Ensemble methods have been proposed as a way to improve the performance and robustness of deep learning models in skin disease diagnosis.

The interpretability of deep learning models remains a challenge, and there is a need for methods that can provide insights into the decisions made by the model.

Deep learning models have shown to outperform traditional machine learning algorithms and human experts in skin disease diagnosis.

Further research is needed to evaluate the performance of deep learning models in different populations and under various imaging conditions, as well as to address the ethical and legal implications of their use in clinical practice.
2/9/23, 12:36‚ÄØAM - Amit: <Media omitted>
2/9/23, 7:42‚ÄØAM - Amit: Project stages sudhi hu bolu chhu
2/9/23, 7:43‚ÄØAM - Amit: Tu methodology and conclusion ready karje
2/10/23, 10:55‚ÄØAM - Amit: Bro mane 21100 gpay kari de.
Bank ma low balance no msg aayo chhe.
2/10/23, 10:55‚ÄØAM - Siddharth: Ha wait 
GPay karu chhu
2/10/23, 10:59‚ÄØAM - Siddharth: Done
11100: GPay
10000: Niyo
2/10/23, 10:59‚ÄØAM - Amit: Ok received üëç
2/10/23, 10:59‚ÄØAM - Siddharth: <Media omitted>
2/10/23, 10:59‚ÄØAM - Amit: Thanks bro
2/10/23, 10:59‚ÄØAM - Siddharth: Rahul bhai sathe vaat thai?
2/10/23, 11:00‚ÄØAM - Amit: Ha emne kidhu hatu aaje kari deshe
2/10/23, 11:00‚ÄØAM - Siddharth: Okay
2/10/23, 11:00‚ÄØAM - Amit: Hu karu msg chalnr
2/10/23, 11:00‚ÄØAM - Siddharth: üëç
2/10/23, 12:43‚ÄØPM - Siddharth: Haji nai aavya
2/10/23, 9:28‚ÄØPM - Amit: Account ma aavya paisa?
2/10/23, 9:29‚ÄØPM - Siddharth: Na
2/10/23, 9:32‚ÄØPM - Amit: Rahul bhai e kidhu ene transfer kari didhu chhe.
Tu taru niyo nu account check karto re and aave etle mane ke.
2/10/23, 9:34‚ÄØPM - Siddharth: Ha
2/10/23, 9:34‚ÄØPM - Amit: Aavi gaya?
2/10/23, 9:35‚ÄØPM - Siddharth: Na bhai
2/10/23, 9:35‚ÄØPM - Amit: Tari details farithi mokal to je pela mokali hati e
2/10/23, 9:35‚ÄØPM - Amit: Ek vaar hu check karai lav
2/10/23, 9:35‚ÄØPM - Amit: Bank details
2/10/23, 9:36‚ÄØPM - Siddharth: <Media omitted>
2/12/23, 11:59‚ÄØAM - Siddharth: Coding jungle growing

Should we start some work?
2/12/23, 12:00‚ÄØPM - Siddharth: Atleast 1 video a week level?
2/12/23, 12:00‚ÄØPM - Siddharth: I think algorithm selecting us
2/12/23, 12:17‚ÄØPM - Amit: Yeah we can start
2/15/23, 10:12‚ÄØAM - Amit: 2 vage yogesh sir e malva bolavya chhe
2/15/23, 10:13‚ÄØAM - Siddharth: Kem?
2/15/23, 10:13‚ÄØAM - Amit: No idea.
Sir no msg aavyo chhe
2/15/23, 10:13‚ÄØAM - Siddharth: Okay, jaie
2/15/23, 2:22‚ÄØPM - Amit: 8128530825
2/18/23, 10:32‚ÄØAM - Amit: Bro citypulse ma 4 vagya no show j nathi
2/18/23, 10:32‚ÄØAM - Amit: 1pm and 7pm j chhe
2/18/23, 10:32‚ÄØAM - Siddharth: Jova de to pachhi
Hu msg karu tane
2/18/23, 10:32‚ÄØAM - Amit: Ok
2/18/23, 10:33‚ÄØAM - Amit: Chhe 4 vagya no citypulse ma but hindi 3d
2/18/23, 10:35‚ÄØAM - Amit: <Media omitted>
2/18/23, 10:35‚ÄØAM - Siddharth: NO NO NO
2/18/23, 10:36‚ÄØAM - Siddharth: Koi nai aave Hindi ma
2/19/23, 9:45‚ÄØPM - Amit: https://www.bilibili.tv/en/video/2045053726
2/21/23, 11:32‚ÄØAM - Siddharth: Rahul bhai ne vaat kar ne, I am really low balance now
2/21/23, 11:33‚ÄØAM - Siddharth: Both accounts less than 5k
2/21/23, 11:33‚ÄØAM - Amit: Ok
2/21/23, 11:33‚ÄØAM - Siddharth: Baaki I need to sell stocks ü•π
2/21/23, 11:33‚ÄØAM - Siddharth: Because this time, I am not calling home for money
2/21/23, 11:34‚ÄØAM - Siddharth: 9 more days before we receive 10k from SSB.

Tya sudhi I need to manage anyhow
2/21/23, 11:34‚ÄØAM - Amit: Kari dho msg
2/21/23, 11:34‚ÄØAM - Amit: Dhidho*
2/21/23, 11:34‚ÄØAM - Siddharth: üëç
2/21/23, 12:31‚ÄØPM - Siddharth: Just received 10K
2/21/23, 12:31‚ÄØPM - Siddharth: Is that Rahul bhai?
2/21/23, 12:52‚ÄØPM - Amit: Yes
2/21/23, 12:52‚ÄØPM - Siddharth: üëç
2/21/23, 5:06‚ÄØPM - Siddharth: https://mostly.ai/synthetic-data-platform/generate-synthetic-data/?utm_source=LinkedIn&utm_medium=Social&utm_campaign=LinkedIn%20Video%20Ad%20Sponsored%20Post%20Sign-Up%20Page&hsa_acc=508243748&hsa_cam=613448124&hsa_grp=207810104&hsa_ad=197466794&hsa_net=linkedin&hsa_ver=3
2/23/23, 11:16‚ÄØAM - Amit: I have a surprise for you üòä
2/23/23, 11:16‚ÄØAM - Amit: Room ma aavu pachhi kav tane
2/23/23, 11:16‚ÄØAM - Siddharth: Okay vroo
2/23/23, 11:48‚ÄØAM - Siddharth: Me waiting
2/23/23, 10:50‚ÄØPM - Siddharth: https://github.com/lllyasviel/ControlNet
2/25/23, 11:55‚ÄØAM - Amit: import requests
import arxiv

keyword = "machine learning"

repo_url = f"https://api.github.com/search/repositories?q={keyword}"
repo_response = requests.get(repo_url)

paper_response = arxiv.Search(
  query = keyword,
  max_results = 5,
  sort_by = arxiv.SortCriterion.Relevance,
  sort_order = arxiv.SortOrder.Descending
)

if repo_response.status_code == 200:
    repo_data = repo_response.json()

    for item in repo_data["items"][:5]:
        print(f"{item['name']}: {item['html_url']}")
    
    for result in paper_response.results():
        print(result.title, result.pdf_url)

else:
    print("Failed to retrieve data")
2/25/23, 11:02‚ÄØPM - Siddharth: Sorry vro, I really forgot
2/25/23, 11:02‚ÄØPM - Siddharth: It was not intentional
2/26/23, 2:54‚ÄØPM - Siddharth: https://www.producthunt.com/posts/tldrbot
3/2/23, 8:55‚ÄØPM - Amit: Tu amul parlour thi lai leje naasto and coke ni ek moti bottle pan lai leje
3/2/23, 9:11‚ÄØPM - Amit: Coke ni bottle no bhulto
3/2/23, 9:20‚ÄØPM - Siddharth: Male to pakku
3/2/23, 9:22‚ÄØPM - Amit: Atyre parlour open hoy to naasto lai jeje pachhi tu nikal tyare bandh thai jashe
3/3/23, 11:11‚ÄØAM - Siddharth: https://www.synthesia.io/
3/3/23, 11:19‚ÄØAM - Siddharth: https://youtu.be/3KXz8X_mTQY

This video is made by Synthesia
3/3/23, 11:20‚ÄØAM - Siddharth: They charge 2000 INR for 10 minutes of content
3/3/23, 11:20‚ÄØAM - Siddharth: And 40000+ companies use it
3/3/23, 11:21‚ÄØAM - Siddharth: Bhai, just talked with one guy, he gave idea that now GPT is so cheap, how about creating ad supported website with AI which is free for users?
3/3/23, 12:17‚ÄØPM - Siddharth: https://collabgpt.vercel.app/room/t61uj
3/4/23, 9:15‚ÄØAM - Siddharth: Bro knows Victoria's secret
Bro knows who asked
Bro named his grandparents
Bro tells his parents to clean his room
Bro tells his mom to wash the dishes
Bro know What da dog doin
Bro knows what Amber Heard
Bro knows Obama's last name
Bro United the states
Bro cuts his barber's hair
Bro goes to Mc Donald and the ice machines starts working
Bro knows who let the dawgs out
Bro knows where's the iPhone 9 at
Bro can read qr code and make onion cry Bro knows the alphabet that comes before
"A"
Bro calls 911 and ask their emergency.
Bro can see John Cena
Bro did 9/11 and lived
Bro receive tips from the waiter
Bro tells his watch the hour
Bro got milk for his father
Bro gives homework to the teacher
Bro gives up Rick Astley
Bro tells his barber he didn't like the cut
Bro eat cereals with water
3/4/23, 9:44‚ÄØAM - Siddharth: Code mokal
3/4/23, 10:46‚ÄØAM - Amit: <Media omitted>
3/4/23, 4:16‚ÄØPM - Siddharth: <Media omitted>
3/5/23, 6:26‚ÄØPM - Siddharth: https://youtube.com/shorts/J8CkK2Ato7Q?feature=share


üòÅüòÅüòÅ
3/6/23, 12:19‚ÄØPM - Amit: Romm ni keys deto jaje mane
3/6/23, 12:40‚ÄØPM - Siddharth: Ha
3/9/23, 9:48‚ÄØAM - Amit: Atayre Vgg19 final model rakhelu chhe. 
Bija models try karie chie and frontend nu work start kari didhu chhe.
3/9/23, 9:48‚ÄØAM - Amit: Ok?
3/9/23, 9:48‚ÄØAM - Siddharth: Ha
3/9/23, 10:51‚ÄØAM - Amit: Aapne aama novelty mate sir me mali laie.
E j kaik suggestions aapshr
3/9/23, 10:51‚ÄØAM - Amit: Aapshe*
3/9/23, 10:51‚ÄØAM - Amit: Conference paper mate
3/9/23, 10:51‚ÄØAM - Siddharth: Okay
3/9/23, 10:51‚ÄØAM - Amit: Tu aav pachi jaie malva sir ne
3/9/23, 10:51‚ÄØAM - Siddharth: Ha
3/11/23, 5:33‚ÄØPM - Siddharth: https://www.codespeedy.com/how-to-pass-javascript-variables-to-python-in-flask/
3/15/23, 9:08‚ÄØPM - Siddharth: <Media omitted>
3/15/23, 9:11‚ÄØPM - Siddharth: import pandas as pd
import psycopg2

# connect to PostgreSQL
conn = psycopg2.connect(
    host="your_host_name",
    database="your_database_name",
    user="your_user_name",
    password="your_password"
)

# read Excel file into a Pandas dataframe
df = pd.read_excel('your_excel_file.xlsx')

# create a cursor object
cur = conn.cursor()

# create a table to store data
cur.execute("""
    CREATE TABLE your_table_name (
        column1 data_type1,
        column2 data_type2,
        column3 data_type3,
        ...
    );
""")

# insert data into the table
for row in df.itertuples():
    cur.execute("""
        INSERT INTO your_table_name (column1, column2, column3, ...)
        VALUES (%s, %s, %s, ...);
    """, row[1:])

# commit changes and close connection
conn.commit()
cur.close()
conn.close()
3/15/23, 9:25‚ÄØPM - Siddharth: <Media omitted>
3/15/23, 9:48‚ÄØPM - Siddharth: ('DEPOSIT NO.', 'Deposit identification number,Reference number,Transaction number,Receipt number'), ('Deposit identification number', 'DEPOSIT NO.,Reference number,Transaction number,Receipt number'), ('Reference number', 'DEPOSIT NO.,Deposit identification number,Transaction number,Receipt number'), ('Transaction number', 'DEPOSIT NO.,Deposit identification number,Reference number,Receipt number'), ('Receipt number', 'DEPOSIT NO.,Deposit identification number,Reference number,Transaction number'), ('OPEN DATE', 'Account opening date,Starting date,Commencement date'), ('Account opening date', 'OPEN DATE,Starting date,Commencement date'), ('Starting date', 'OPEN DATE,Account opening date,Commencement date'), ('Commencement date', 'OPEN DATE,Account opening date,Starting date'), ('DEP. AMT. #', 'Deposit amount,Principal,Initial deposit,Invested amount'), ('Deposit amount', 'DEP. AMT. #,Principal,Initial deposit,Invested amount'), ('Principal', 'DEP. AMT. #,Deposit amount,Initial deposit,Invested amount'), ('Initial deposit', 'DEP. AMT. #,Deposit amount,Principal,Invested amount'), ('Invested amount', 'DEP. AMT. #,Deposit amount,Principal,Initial deposit'), ('ROI%', 'Rate of Interest,Interest Rate,Yield,Return'), ('Rate of Interest', 'ROI%,Interest Rate,Yield,Return'), ('Interest Rate', 'ROI%,Rate of Interest,Yield,Return'), ('Yield', 'ROI%,Rate of Interest,Interest Rate,Return'), ('Return', 'ROI%,Rate of Interest,Interest Rate,Yield'), ('PERIOD', 'Deposit tenure,Duration,Term,Maturity period'), ('Deposit tenure', 'PERIOD,Duration,Term,Maturity period'), ('Duration', 'PERIOD,Deposit tenure,Term,Maturity period'), ('Term', 'PERIOD,Deposit tenure,Duration,Maturity period'), ('Maturity period', 'PERIOD,Deposit tenure,Duration,Term'), ('MAT. AMT. ^', 'Maturity amount,Final value,End balance,Total return'), ('Maturity amount', 'MAT. AMT. ^,Final value,End balance,Total return'), ('Final value', 'MAT. AMT. ^,Maturity amount,End balance,Total return'), ('End balance', 'MAT. AMT. ^,Maturity amount,Final value,Total return'), ('Total return', 'MAT. AMT. ^,Maturity amount,Final value,End balance'), ('MAT. DATE', 'Maturity date,Due date,Final date,End date'), ('Maturity date', 'MAT. DATE,Due date,Final date,End date'), ('Due date', 'MAT. DATE,Maturity date,Final date,End date'), ('Final date', 'MAT. DATE,Maturity date,Due date,End date'), ('End date', 'MAT. DATE,Maturity date,Due date,Final date'), ('BALANCE *', 'Current balance,Available balance,Remaining balance,Net balance'), ('Current balance', 'BALANCE *,Available balance,Remaining balance,Net balance,BALANCE,Available balance,Remaining balance,Net balance'), ('Available balance', 'BALANCE *,Current balance,Remaining balance,Net balance,BALANCE,Current balance,Remaining balance,Net balance'), ('Remaining balance', 'BALANCE *,Current balance,Available balance,Net balance,BALANCE,Current balance,Available balance,Net balance'), ('Net balance', 'BALANCE *,Current balance,Available balance,Remaining balance,BALANCE,Current balance,Available balance,Remaining balance'), ('NOMINATION', 'Beneficiary designation,Nominee,Heir,Successor'), ('Beneficiary designation', 'NOMINATION,Nominee,Heir,Successor'), ('Nominee', 'NOMINATION,Beneficiary designation,Heir,Successor'), ('Heir', 'NOMINATION,Beneficiary designation,Nominee,Successor,NAME OF NOMINEE*,Name of beneficiary,Name of nominee,Successor'), ('Successor', 'NOMINATION,Beneficiary designation,Nominee,Heir,NAME OF NOMINEE*,Name of beneficiary,Name of nominee,Heir'), ('TOTAL', 'Sum total,Aggregate,Grand total,Overall amount'), ('Sum total', 'TOTAL,Aggregate,Grand total,Overall amount'), ('Aggregate', 'TOTAL,Sum total,Grand total,Overall amount'), ('Grand total', 'TOTAL,Sum total,Aggregate,Overall amount'), ('Overall amount', 'TOTAL,Sum total,Aggregate,Grand total'), ('DATE', 'Transaction date,Entry date,Posting date,Effective date'), ('Transaction date', 'DATE,Entry date,Posting date,Effective date'), ('Entry date', 'DATE,Transaction date,Posting date,Effective date'), ('Posting date', 'DATE,Transaction date,Entry date,Effective date'), ('Effective date', 'DATE,Transaction date,Entry date,Posting date'), ('MODE', 'Method of payment,Mode of transfer,Payment mode,Transaction mode'), ('Method of payment', 'MODE,Mode of transfer,Payment mode,Transaction mode'), ('Mode of transfer', 'MODE,Method of payment,Payment mode,Transaction mode'), ('Payment mode', 'MODE,Method of payment,Mode of transfer,Transaction mode'), ('Transaction mode', 'MODE,Method of payment,Mode of transfer,Payment mode'), ('PARTICULARS', 'Transaction details,Account activity,Statement description,Transaction summary'), ('Transaction details', 'PARTICULARS,Account activity,Statement description,Transaction summary'), ('Account activity', 'PARTICULARS,Transaction details,Statement description,Transaction summary'), ('Statement description', 'PARTICULARS,Transaction details,Account activity,Transaction summary'), ('Transaction summary', 'PARTICULARS,Transaction details,Account activity,Statement description'), ('DEPOSITS', 'Credits,Money received,Inflows,Lodgments,Incoming payments'), ('Credits', 'DEPOSITS,Money received,Inflows,Lodgments,Incoming payments'), ('Money received', 'DEPOSITS,Credits,Inflows,Lodgments,Incoming payments'), ('Inflows', 'DEPOSITS,Credits,Money received,Lodgments,Incoming payments'), ('Lodgments', 'DEPOSITS,Credits,Money received,Inflows,Incoming payments'), ('Incoming payments', 'DEPOSITS,Credits,Money received,Inflows,Lodgments'), ('WITHDRAWALS', 'Debits,Money taken out,Outflows,Withdrawals,Outgoing payments'), ('Debits', 'WITHDRAWALS,Money taken out,Outflows,Withdrawals,Outgoing payments'), ('Money taken out', 'WITHDRAWALS,Debits,Outflows,Withdrawals,Outgoing payments'), ('Outflows', 'WITHDRAWALS,Debits,Money taken out,Withdrawals,Outgoing payments'), ('Withdrawals', 'WITHDRAWALS,Debits,Money taken out,Outflows,Outgoing payments'), ('Outgoing payments', 'WITHDRAWALS,Debits,Money taken out,Outflows,Withdrawals'), ('BALANCE', 'Current balance,Available balance,Remaining balance,Net balance'), ('ACCOUNT TYPE', 'Type of account,Account category,Account classification'), ('Type of account', 'ACCOUNT TYPE,Account category,Account classification'), ('Account category', 'ACCOUNT TYPE,Type of account,Account classification'), ('Account classification', 'ACCOUNT TYPE,Type of account,Account category'), ('ACCOUNT NUMBER', 'Account ID,Account code,Account reference number,Account identifier'), ('Account ID', 'ACCOUNT NUMBER,Account code,Account reference number,Account identifier'), ('Account code', 'ACCOUNT NUMBER,Account ID,Account reference number,Account identifier'), ('Account reference number', 'ACCOUNT NUMBER,Account ID,Account code,Account identifier'), ('Account identifier', 'ACCOUNT NUMBER,Account ID,Account code,Account reference number'), ('MICR CODE', 'Magnetic Ink Character Recognition Code,Routing number,Bank code,Branch code'), ('Magnetic Ink Character Recognition Code', 'MICR CODE,Routing number,Bank code,Branch code'), ('Routing number', 'MICR CODE,Magnetic Ink Character Recognition Code,Bank code,Branch code'), ('Bank code', 'MICR CODE,Magnetic Ink Character Recognition Code,Routing number,Branch code'), ('Branch code', 'MICR CODE,Magnetic Ink Character Recognition Code,Routing number,Bank code'), ('IFS CODE', 'Indian Financial System Code,Bank identifier code,SWIFT code'), ('Indian Financial System Code', 'IFS CODE,Bank identifier code,SWIFT code'), ('Bank identifier code', 'IFS CODE,Indian Financial System Code,SWIFT code'), ('SWIFT code', 'IFS CODE,Indian Financial System Code,Bank identifier code'), ('NAME OF NOMINEE*', 'Name of beneficiary,Name of nominee,Heir,Successor'), ('Name of beneficiary', 'NAME OF NOMINEE*,Name of nominee,Heir,Successor'), ('Name of nominee', 'NAME OF NOMINEE*,Name of beneficiary,Heir,Successor')
3/16/23, 11:49‚ÄØAM - Siddharth: https://www.thepythoncode.com/article/redact-and-highlight-text-in-pdf-with-python#:~:text=Initialize%20a%20variable%20for%20storing,%22Highlight%22%20%2C%20etc.
3/16/23, 7:32‚ÄØPM - Amit: <Media omitted>
3/16/23, 7:32‚ÄØPM - Amit: <Media omitted>
3/16/23, 10:50‚ÄØPM - Siddharth: <Media omitted>
3/17/23, 2:23‚ÄØAM - Siddharth: We need to rethink about product. If we should keep it free or paid.
chefgpt have monthly plan for 3 USD
3/17/23, 2:29‚ÄØAM - Siddharth: I cannot think about just 3 USD a month product.
And they are giving lots of features for 3 USD.
3/17/23, 3:08‚ÄØPM - Siddharth: <Media omitted>
3/17/23, 3:19‚ÄØPM - Amit: Motivation - Objectives
Methedology - It's image
Result's Graph - Result's Table
Outcomes - References
3/17/23, 8:25‚ÄØPM - Amit: <Media omitted>
3/18/23, 10:19‚ÄØAM - Amit: <Media omitted>
3/18/23, 10:19‚ÄØAM - Siddharth: Karu hu check
3/18/23, 10:19‚ÄØAM - Amit: Ok
3/18/23, 3:40‚ÄØPM - Siddharth: aa lodo emj keto to
3/18/23, 3:40‚ÄØPM - Siddharth: aai jaje
3/18/23, 3:40‚ÄØPM - Siddharth: ~nandan
3/18/23, 3:41‚ÄØPM - Amit: Khabar padi gai ti
Taro qvaj avto hato background mathi
3/18/23, 3:41‚ÄØPM - Amit: Avaz*
3/18/23, 4:04‚ÄØPM - Amit: Balaji tikhi waffer - 10 vali 1
Balaji nachos - 10 vala 2
Cheese Popring - 10 vala 2
Gopal na koi pan - 5 vala 2
3/18/23, 4:06‚ÄØPM - Amit: Ek nani bottle maza.
3/19/23, 5:57‚ÄØPM - Amit: <Media omitted>
3/19/23, 11:43‚ÄØPM - Siddharth: Done?
3/19/23, 11:43‚ÄØPM - Siddharth: <Media omitted>
3/20/23, 11:50‚ÄØAM - Siddharth: Thayu kai?
3/20/23, 11:50‚ÄØAM - Siddharth: Search ma?
3/20/23, 11:56‚ÄØAM - Siddharth: Aatlo code alag file ma try kar please, flask app ma nai karto, e integration aapne banne sathe karishu

import fitz

# Open the PDF document
doc = fitz.open('example.pdf')

# Define the list of words to highlight
highlight_words = ['hello', 'world']

# Iterate through the pages of the document
for page in doc:
    # Search for the words on the page
    matches = []
    for word in highlight_words:
        matches += page.search(word)

    # Add a highlight annotation to each match
    for match in matches:
        highlight = page.add_highlight_annot(match)
        highlight.update()

# Save the modified document
doc.save('highlighted.pdf')
3/20/23, 12:07‚ÄØPM - Amit: import fitz

pdf_file = fitz.open("C:/Users/admin/Desktop/Amit Hirpara.pdf")

for page in pdf_file:
    mylist=['Machine Learning','Deep Learning']
    for i in mylist:
        text_to_be_highlighted = i

        highlight = page.search_for(text_to_be_highlighted)

        for inst in highlight:

            highlight = page.add_highlight_annot(inst)

            highlight.update()

pdf_file.save("output.pdf", garbage=4, deflate=True, clean=True)
3/20/23, 1:41‚ÄØPM - Siddharth: Kyare aave chhe?
3/20/23, 2:12‚ÄØPM - Amit: Aavi gayo
3/20/23, 9:58‚ÄØPM - Siddharth: openai.api_key = os.getenv('API_KEY')
3/20/23, 10:54‚ÄØPM - Siddharth: MLBrothers2024@#
3/20/23, 10:57‚ÄØPM - Siddharth: flask
openai
gunicorn
spotipy
3/20/23, 11:01‚ÄØPM - Siddharth: https://musicnbook.com/
3/20/23, 11:08‚ÄØPM - Amit: UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 454: character maps to <undefined>
3/21/23, 12:01‚ÄØAM - Siddharth: from flask_login import LoginManager
login_manager = LoginManager()
3/21/23, 12:02‚ÄØAM - Siddharth: https://flask-login.readthedocs.io/en/latest/
3/21/23, 11:38‚ÄØAM - Amit: <Media omitted>
3/21/23, 8:02‚ÄØPM - Amit: dannydaniels10@gmail.com 
01001.@Ryn
3/22/23, 9:48‚ÄØPM - Siddharth: https://platform.openai.com/docs/guides/chat/introduction
3/23/23, 4:40‚ÄØPM - Amit: Tu mane taro pelo mail forward karne je te ssb ma mokalyo hato full time mate
3/23/23, 4:40‚ÄØPM - Amit: Mare send karvo chhe etle
3/23/23, 5:47‚ÄØPM - Siddharth: Karu thodi vaar ma
3/24/23, 12:26‚ÄØPM - Amit: Mail
3/24/23, 12:26‚ÄØPM - Amit: Mokal
3/24/23, 1:09‚ÄØPM - Siddharth: Exactly kayo mail?
3/24/23, 1:10‚ÄØPM - Amit: Te je ssb ma send karyo to e
3/24/23, 1:10‚ÄØPM - Amit: First time jyrae full time ne vaat kari to e
3/24/23, 1:10‚ÄØPM - Siddharth: Use it just for reference, write your own
3/24/23, 1:10‚ÄØPM - Siddharth: Respected ma'am,
I am Siddharth, working as a junior ML developer intern. I have been working with SSB Digital since august as an intern and now I want to convert my role to full time. I have received an offer from a Bengluru based startup who are offering me a junior data scientist role for next 2 months and after that it will be converted to senior role once I join full time. 

They are offering me 30k as a stipend now and it will be revised after two months once I join full time with the position being fully remote.

I really enjoyed my work at SSB digital and I want to continue working with SSB as an ML engineer position full time. However, I need to make a decision about it. So, if SSB can offer me a full time role as an ML engineer, I would love to discuss possibilities. Just to note that, the position should be remote because I am involved with work at university and cannot join the office physically. Although I can start working full time as a remote engineer. 

Looking forward to hearing from you.
3/24/23, 1:11‚ÄØPM - Amit: And to and cc ma kone rakhvana?
3/24/23, 1:12‚ÄØPM - Siddharth: Just HR ne lakhyo chhe aa
3/24/23, 1:12‚ÄØPM - Amit: Ok
3/26/23, 12:18‚ÄØAM - Amit: <Media omitted>
3/26/23, 2:02‚ÄØAM - Amit: <Media omitted>
3/27/23, 12:17‚ÄØPM - Amit: <Media omitted>
3/27/23, 12:53‚ÄØPM - Amit: You deleted this message
3/27/23, 3:42‚ÄØPM - Amit: mvjxgqbspbecprij
3/27/23, 3:47‚ÄØPM - Amit: Full time salary?
3/27/23, 3:48‚ÄØPM - Siddharth: 60-70k minimum for remote
3/27/23, 3:48‚ÄØPM - Amit: Arre discuss koni sathe karvani?
3/27/23, 3:48‚ÄØPM - Amit: Aaje aavya chie to patavi daie ne
3/28/23, 6:45‚ÄØPM - Amit: <Media omitted>
3/28/23, 6:49‚ÄØPM - Amit: <Media omitted>
3/28/23, 7:23‚ÄØPM - Siddharth: https://eportal.incometax.gov.in/iec/foservices/#/pre-login/link-aadhaar-status
3/29/23, 10:46‚ÄØAM - Siddharth: Tu sir ne mali leje, me going home
3/29/23, 10:47‚ÄØAM - Amit: Nandu vai gayo?
3/29/23, 10:47‚ÄØAM - Siddharth: Na, kale
3/29/23, 10:47‚ÄØAM - Amit: Ok
3/29/23, 10:47‚ÄØAM - Siddharth: Or maybe aaje j
3/29/23, 10:47‚ÄØAM - Siddharth: He will decide by 2
3/29/23, 10:47‚ÄØAM - Amit: Ok
3/29/23, 2:07‚ÄØPM - Siddharth: Karu call thodi vaar ma
3/29/23, 3:38‚ÄØPM - Siddharth: Bhai, hu tane key aapvanu bhuli gayo
3/29/23, 3:47‚ÄØPM - Amit: Kai vandho nai chalshe
3/31/23, 11:12‚ÄØAM - Siddharth: Bhai, Tata Power ma exit laie ek target par?
4/2/23, 7:38‚ÄØPM - Amit: Tare ssb ma full time last month thi start thai gayu hatu?
4/2/23, 7:38‚ÄØPM - Siddharth: Evu j lage chhe
4/2/23, 7:38‚ÄØPM - Amit: Because mane aa vakhte 10,000 j aavya chhe etle
4/2/23, 7:39‚ÄØPM - Amit: Mare to aa month thi start thayu chhe
4/2/23, 7:39‚ÄØPM - Siddharth: So maybe next month for you
4/2/23, 7:39‚ÄØPM - Amit: Guess so
4/2/23, 7:50‚ÄØPM - Amit: Baar khava javu chhe?
4/2/23, 7:51‚ÄØPM - Siddharth: Na bhai, order karvu hoy to interested
4/2/23, 7:51‚ÄØPM - Siddharth: Thakyo chhu travel kari ne
4/2/23, 7:51‚ÄØPM - Amit: Hi and dhaivat vicharie chie etle
4/2/23, 7:51‚ÄØPM - Amit: Hu*
4/2/23, 7:51‚ÄØPM - Siddharth: Shu khava jao chho?
4/2/23, 7:51‚ÄØPM - Amit: Maybe pizza unlimited
4/2/23, 7:51‚ÄØPM - Amit: Not final yet
4/2/23, 7:52‚ÄØPM - Siddharth: Na, humna bau khadha pizza.
Jo jao to mara mate kaik leta aavjo if possible
4/2/23, 7:52‚ÄØPM - Amit: Ok
4/2/23, 9:41‚ÄØPM - Amit: https://youtube.com/shorts/1VmkKqxwkO4?feature=share
4/3/23, 10:50‚ÄØAM - Siddharth: CNN
DenseNet
MobileNet
VGG-19
Vision transformer
4/3/23, 11:50‚ÄØAM - Siddharth: https://openai.com/form/openai-tour-2023
4/3/23, 1:43‚ÄØPM - Amit: <Media omitted>
4/3/23, 1:43‚ÄØPM - Amit: <Media omitted>
4/3/23, 6:09‚ÄØPM - Siddharth: I accept the offer.¬†

Thanks and¬†regards,
4/3/23, 8:36‚ÄØPM - Amit: <Media omitted>
4/4/23, 11:58‚ÄØAM - Amit: Mere liye kuch packets le lena pls
4/4/23, 12:00‚ÄØPM - Amit: Balaji tikhi waffer - 2 packets
Balaji nachos - 2 packets
Cheese Popring - 2 packets

Badha 10 vala packets
4/4/23, 12:07‚ÄØPM - Siddharth: Be wapas aa gaye, bandh tha
4/4/23, 12:45‚ÄØPM - Siddharth: Aavi ja ahi, kaam chhe
4/6/23, 10:11‚ÄØAM - Amit: Yogesh sir no msg chhe.
11 vage bolavya chhe.
4/6/23, 10:11‚ÄØAM - Siddharth: üëç
4/6/23, 12:04‚ÄØPM - Siddharth: Shared route
From (23.1597007,72.6635779) to Aarya Epoch via Gandhinagar - Ahmedabad Rd.

39 min (23¬†km)
39 min in current traffic


1. Head southwest toward PDPU Hostel Rd
2. Turn right onto PDPU Rd
3. Turn left
4. Turn right
5. Turn left onto PDPU Rd
6. Slight left onto IAR Rd
7. Continue straight to stay on IAR Rd
8. Turn left onto Gandhinagar - Ahmedabad Rd
9. At Koba Cir, take the 2nd exit and stay on Gandhinagar - Ahmedabad Rd
10. Exit the roundabout onto Gandhinagar - Ahmedabad Rd
11. At Bhat Cir, take the 5th exit onto Sardar Patel Ring Rd
12. Exit the roundabout onto Sardar Patel Ring Rd
13. Turn left onto Motera Rd
14. Turn right at Motera Stadium Rd
15. Turn left onto Gujarat State Highway 71
16. At the roundabout, continue straight to stay on Gujarat State Highway 71
17. At ONGC Cir, continue straight to stay on Gujarat State Highway 71
18. At Vishat Cir, take the 1st exit onto Ahmedabad - Patan Highway Rd
19. At RTO Cir, take the 1st exit
20. Exit the roundabout
21. At Subhash Cir, take the 3rd exit onto Ashram Rd
22. Exit the roundabout onto Ashram Rd
23. Continue straight past State Bank Of India to stay on Ashram Rd
24. Continue straight to stay on Ashram Rd
25. Slight left toward Ashram Rd
26. Slight left onto Ashram Rd
27. Turn right at Usmanpura Char Rasta onto 120 Feet Ring Rd
28. At Sardar Patel Statue Cir, continue straight to stay on 120 Feet Ring Rd
29. At Navrang Cir, take the 1st exit and stay on 120 Feet Ring Rd
30. Exit the roundabout onto 120 Feet Ring Rd
31. At Darpan Cir, take the 3rd exit and stay on 120 Feet Ring Rd
32. Exit the roundabout onto 120 Feet Ring Rd
33. Turn right at Vijay Cross Roads onto Drive In Rd
34. Arrive at location: Aarya Epoch
For the best route in current traffic visit https://maps.app.goo.gl/TpHAUctt4oUBvoNi6
4/8/23, 1:14‚ÄØAM - Siddharth: <Media omitted>
4/9/23, 1:24‚ÄØPM - Amit: <Media omitted>
4/10/23, 10:15‚ÄØAM - Amit: <Media omitted>
4/10/23, 10:30‚ÄØAM - Amit: Smit SSB.vcf (file attached)
4/10/23, 2:50‚ÄØPM - Amit: <Media omitted>
4/11/23, 9:33‚ÄØAM - Siddharth: Complete poster
Complete JSON
4/11/23, 11:44‚ÄØAM - Siddharth: <Media omitted>
4/11/23, 6:23‚ÄØPM - Amit: <Media omitted>
4/11/23, 6:42‚ÄØPM - Amit: People today suffer from a wide range of skin problems as a result of rising pollution levels and poor diets.
Every time you go to the doctor for a skin examination or consultation, you'll have to pay a fee, which might be expensive for some people or families.
Our main goal is to offer a web app to all of these individuals and families who are unable to pay for a skin disease scan.
Users only need to upload a picture of the diseased area of their skin, and our web application will identify the most likely skin disease for them.
4/11/23, 6:43‚ÄØPM - Siddharth: Note that, this model is for primary analysis and not to replace medical professional.
4/11/23, 6:58‚ÄØPM - Amit: We strive to create a comprehensive, user-friendly web interface for classifying skin diseases throughout this project.
We have currently finalized¬†and trained our deep learning models for the task of classifying skin diseases. The final stage is to build a web interface and use our best deep learning model on it to do a prediction task.
And also we are writing a research paper regarding this problem statement with our mentor.
4/11/23, 7:14‚ÄØPM - Siddharth: Eczema
Urticaria
Seborrheic Keratoses
4/11/23, 7:26‚ÄØPM - Siddharth: Resize
Random rotate
Random flip
Random zoom
Random crop
4/11/23, 7:34‚ÄØPM - Siddharth: TinyVGG
TinyVGG with Data Augmentation
CNN (shallow)
MobileNet_v2
MobileNet_v3
DenseNet
VGG11
4/11/23, 8:35‚ÄØPM - Siddharth: TinyVGG: 49%
TinyVGG with Data Augmentation: 54%
VGG: 82%
MobileNet: 64%
DenseNet: 72%
4/11/23, 8:38‚ÄØPM - Siddharth: <Media omitted>
4/11/23, 8:44‚ÄØPM - Amit: First we have collected the data (images) for various skin diseases from Kaggle, which is online opensource platform for publicly available datasets. Our training dataset contains 10 different types of skin diseases like Eczema, Urticaria, Seborrheic Keratoses and many more.

The second step is data pre-processing. We pre-processed each and every image from the training dataset before feeding them into models. In this stage we have performed various processing steps like Image Resizing and Image Augmentation (Random Rotate, Random Flip, Random Zoom and Random Crop).

The third step is to create various deep learning models based on pre-processed dataset. We have already developed multiple deep learning models to classify skin diseases. Below is the list of deep learning models which we have trained:
      1. TinyVGG    2. TinyVGG with Data Augmentation    3. CNN (shallow)  
      4. MobileNet_v2    5. DenseNet 

The fourth step is to select best model among all of the above mentioned. We have trained all 5 models on same training dataset. After training the models, we have observed that CNN (VGG19) performed the best on this particular problem statement with the highest accuracy 82%. So we finalized to use VGG19 model to deploy it on our web interface.

We are currently on the fifth step right now. We are developing our user interface for web app.

The final and the last step is to deploy VGG19 model on web app. For this task we will use Flask API. Using Flask we will simply deploy our model‚Äôs weights on the web app and then use them to predict the skin diseases of the user given image.
4/11/23, 9:10‚ÄØPM - Siddharth: An Introduction to Convolutional Neural Networks - Keiron O'Shea, Ryan Nash

MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam

Very Deep Convolutional Networks for Large-Scale Image Recognition
Karen Simonyan, Andrew Zisserman

EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks
Mingxing Tan, Quoc V. Le

Densely Connected Convolutional Networks
Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger
4/11/23, 9:42‚ÄØPM - Siddharth: 8128530825
4/13/23, 11:50‚ÄØAM - Siddharth: <Media omitted>
4/13/23, 11:58‚ÄØAM - Siddharth: https://www.youtube.com/@marketersdiary
4/13/23, 12:18‚ÄØPM - Amit: https://www.google.com/imgres?imgurl=https%3A%2F%2Fneoretina.com%2Fblog%2Fwp-content%2Fuploads%2F2019%2F12%2FWhatsApp-Image-2019-12-27-at-6.45.43-PM.jpeg&tbnid=P0r1uigu3B8_wM&vet=12ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygEegUIARDnAQ..i&imgrefurl=https%3A%2F%2Fneoretina.com%2Fblog%2Fnuclear-cataracts-symptoms-causes-treatment%2F&docid=rFGJOYFuI_GG9M&w=800&h=400&q=cataract%20image&ved=2ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygEegUIARDnAQ
4/13/23, 12:19‚ÄØPM - Amit: https://www.google.com/imgres?imgurl=https%3A%2F%2Fdmei.org%2Fwp-content%2Fuploads%2F2020%2F05%2Fwomans-eye-with-cataract-2.5-scaled.jpeg&tbnid=4VFmtjSmqgkYSM&vet=12ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygPegUIARD9AQ..i&imgrefurl=https%3A%2F%2Fdmei.org%2Fservices-specialties%2Fcataracts%2F&docid=47csyJekpbj8YM&w=2560&h=1957&q=cataract%20image&ved=2ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygPegUIARD9AQ
4/13/23, 12:21‚ÄØPM - Amit: https://www.google.com/imgres?imgurl=https%3A%2F%2Fwww.hopkinsmedicine.org%2F-%2Fmedia%2Fimages%2Fhealth%2F1_-conditions%2Feyes%2Fcataracts-eye--closeup-hero.ashx%3Fh%3D500%26iar%3D0%26mh%3D500%26mw%3D1300%26w%3D1297%26hash%3D9BC20EECDB4B694907DF846567873848&tbnid=Y6p26Xctxz6kUM&vet=12ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygVegUIARCJAg..i&imgrefurl=https%3A%2F%2Fwww.hopkinsmedicine.org%2Fhealth%2Fconditions-and-diseases%2Fcataracts&docid=DsGglFosR6Sy3M&w=1297&h=500&q=cataract%20image&ved=2ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygVegUIARCJAg
4/13/23, 12:31‚ÄØPM - Amit: https://www.google.com/imgres?imgurl=https%3A%2F%2Fneoretina.com%2Fblog%2Fwp-content%2Fuploads%2F2019%2F12%2FWhatsApp-Image-2019-12-27-at-6.45.43-PM.jpeg&tbnid=P0r1uigu3B8_wM&vet=12ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygEegUIARDnAQ..i&imgrefurl=https%3A%2F%2Fneoretina.com%2Fblog%2Fnuclear-cataracts-symptoms-causes-treatment%2F&docid=rFGJOYFuI_GG9M&w=800&h=400&q=cataract%20image&ved=2ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygEegUIARDnAQ
4/13/23, 12:31‚ÄØPM - Amit: https://www.google.com/imgres?imgurl=https%3A%2F%2Fd31g6oeq0bzej7.cloudfront.net%2FAssets%2Fimage%2Fjpeg%2F569d372d-deb0-487c-8300-2d00eba68b4b.jpg&tbnid=_Mx4wdSzm7XKCM&vet=12ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygAegUIARDfAQ..i&imgrefurl=https%3A%2F%2Fwww.aao.org%2Feye-health%2Fdiseases%2Fwhat-are-cataracts&docid=u8La4MJTIPiCiM&w=830&h=415&q=cataract%20image&ved=2ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygAegUIARDfAQ
4/13/23, 12:32‚ÄØPM - Amit: https://www.google.com/imgres?imgurl=https%3A%2F%2Fdmei.org%2Fwp-content%2Fuploads%2F2020%2F05%2Fwomans-eye-with-cataract-2.5-scaled.jpeg&tbnid=4VFmtjSmqgkYSM&vet=12ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygPegUIARD9AQ..i&imgrefurl=https%3A%2F%2Fdmei.org%2Fservices-specialties%2Fcataracts%2F&docid=47csyJekpbj8YM&w=2560&h=1957&q=cataract%20image&ved=2ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMygPegUIARD9AQ
4/13/23, 12:33‚ÄØPM - Amit: https://www.google.com/imgres?imgurl=https%3A%2F%2Fwww.godigit.com%2Fcontent%2Fdam%2Fgodigit%2Fdirectportal%2Fen%2Fcontenthm%2Fcataract1.jpg&tbnid=MwDJ3yJyK5nyNM&vet=12ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMyg6egQIARB1..i&imgrefurl=https%3A%2F%2Fwww.godigit.com%2Fhealth-insurance%2Fdiseases%2Fwhat-is-cataract&docid=atyFPqA9UiYc-M&w=1146&h=765&q=cataract%20image&ved=2ahUKEwiexY7moKb-AhU2_XMBHdYuB8QQMyg6egQIARB1
4/13/23, 3:25‚ÄØPM - Amit: https://www.simplifiedcoding.net/android-save-bitmap-to-gallery/
4/13/23, 4:35‚ÄØPM - Amit: Run configuration app is not supported in the curent project. Cannot obtain the package.
4/14/23, 3:44‚ÄØPM - Amit: <Media omitted>
4/14/23, 3:48‚ÄØPM - Amit: <Media omitted>
4/14/23, 11:34‚ÄØPM - Siddharth: a distributed file system that handles large data sets running on commodity hardware
4/14/23, 11:35‚ÄØPM - Siddharth: <Media omitted>
4/14/23, 11:38‚ÄØPM - Amit: <Media omitted>
4/14/23, 11:42‚ÄØPM - Amit: <Media omitted>
4/14/23, 11:44‚ÄØPM - Siddharth: <Media omitted>
4/14/23, 11:48‚ÄØPM - Siddharth: SAIGE software report: Some Preliminary Investigations
4/15/23, 11:38‚ÄØAM - Amit: <Media omitted>
4/15/23, 11:42‚ÄØAM - Amit: <Media omitted>
4/15/23, 4:24‚ÄØPM - Amit: Debayan sathe vaat pate etle call karje ke shu karvanu chhe
4/16/23, 4:46‚ÄØPM - Siddharth: <Media omitted>
4/16/23, 5:00‚ÄØPM - Siddharth: final_data = {
        "RPT result": len(RPT_result[0]) , 
        "FLG result": len(FLG_result[0]), 
        "Credits":len(credit_result[0]), 
        "Debits": len(debit_result[0]), 
        "RPT credits": len(credit_RPT_result[0]), 
        "RPT debits": len(debit_RPT_result[0])
        }
4/16/23, 5:02‚ÄØPM - Amit: Statement ni pdf pan mokal
4/16/23, 5:02‚ÄØPM - Siddharth: Mail karu
4/16/23, 5:02‚ÄØPM - Siddharth: WA na paadi chhe
4/16/23, 5:02‚ÄØPM - Amit: Ok
4/16/23, 5:23‚ÄØPM - Amit: query mokal je postman ma pass karie chie
4/16/23, 5:24‚ÄØPM - Siddharth: Ha
4/16/23, 5:24‚ÄØPM - Siddharth: {
    "path": "/Sample_Statement_Format_Bancslink.pdf",
    "query": [[["Deb Jhonson", 10781632742],["Vladim Stark", 3268468487]],[["08/12/17", "30918003100"],["14/09/17", "TFR FROM 10781632742"]]]
}
4/16/23, 5:28‚ÄØPM - Amit: OSError: Ghostscript is not installed. You can install it using the instructions here: https://camelot-py.readthedocs.io/en/master/user/install-deps.html
4/16/23, 5:29‚ÄØPM - Amit: Mare camelot ni error aave chhe
4/16/23, 5:29‚ÄØPM - Siddharth: Ha wait
4/16/23, 5:29‚ÄØPM - Amit: tare aavi hati?
4/16/23, 5:29‚ÄØPM - Siddharth: First download ghostscript
4/16/23, 5:29‚ÄØPM - Siddharth: Pachhi
Add the following two paths on Windows Environment Variables:

C:\Program Files(x86)\gs\gs9.26\bin

C:\Program Files(x86)\gs\gs9.26\lib
4/16/23, 5:30‚ÄØPM - Siddharth: And at last, restart
4/16/23, 5:30‚ÄØPM - Amit: ok
4/16/23, 5:30‚ÄØPM - Siddharth: For my reference:

    check_cols = ['Post Date']  

    df = df.astype(str) 
    df = df.replace('nan','') 

    for i, s in df.iterrows():  
        try:
            if all(s[check_cols] != ''):
                lvi, last_valid = i, s
                continue
            else:  
                extra_vals = s[s != '']  
                for col in extra_vals.index:
                    last_valid[col] = last_valid[col] + " " + extra_vals[col] 
                df.iloc[lvi, :] = last_valid
        except:
            pass
4/16/23, 5:32‚ÄØPM - Amit: https://ghostscript.com/releases/gsdnld.html
4/16/23, 5:32‚ÄØPM - Amit: Ahiya thi download karvani chhe ne?
4/16/23, 5:32‚ÄØPM - Siddharth: Ha
4/16/23, 5:32‚ÄØPM - Amit: k
4/16/23, 5:51‚ÄØPM - Amit: TypeError: to_excel() got an unexpected keyword argument 'encoding'
4/16/23, 5:51‚ÄØPM - Amit: encoding pass j nathi karta to pan kem error aave chhe?
4/16/23, 5:51‚ÄØPM - Siddharth: E error mare to nai aavti pan server ma aave chhe
4/16/23, 5:52‚ÄØPM - Amit: Tu taru pandas nu version check karne
4/16/23, 5:52‚ÄØPM - Siddharth: Wait
4/16/23, 5:52‚ÄØPM - Siddharth: 1.3.0
4/16/23, 5:52‚ÄØPM - Siddharth: Tare?
4/16/23, 5:52‚ÄØPM - Amit: 2.0.0
4/16/23, 5:52‚ÄØPM - Amit: lateste
4/16/23, 5:52‚ÄØPM - Amit: old version ma error nathi
4/16/23, 5:52‚ÄØPM - Amit: debayan ne ke
4/16/23, 5:52‚ÄØPM - Siddharth: Let me try
4/16/23, 5:52‚ÄØPM - Siddharth: Kidhu just
4/16/23, 5:54‚ÄØPM - Amit: Issue solve?
4/16/23, 5:54‚ÄØPM - Siddharth: Trying
4/16/23, 5:55‚ÄØPM - Siddharth: Tara ma 1.3.0 kari check kar
4/16/23, 5:55‚ÄØPM - Amit: ok
4/16/23, 5:58‚ÄØPM - Amit: working on version 1.3.0
4/16/23, 5:58‚ÄØPM - Amit: Debayan ne ke 1.3.0 install kare
4/16/23, 5:58‚ÄØPM - Siddharth: Cool
I think I figured out without excel too
4/16/23, 5:58‚ÄØPM - Siddharth: Let me test
4/16/23, 5:58‚ÄØPM - Amit: ok
4/16/23, 5:59‚ÄØPM - Amit: To hu HW karu have?
4/16/23, 5:59‚ÄØPM - Siddharth: Haal kai nai
4/16/23, 8:10‚ÄØPM - Siddharth: Everything working, testing in production now
4/16/23, 8:21‚ÄØPM - Siddharth: Bhai, production working
4/16/23, 8:28‚ÄØPM - Siddharth: Now need to add few more constraints
4/17/23, 9:48‚ÄØAM - Amit: Meeting ketla vage chhe aaje?
4/17/23, 9:55‚ÄØAM - Amit: Great effort & and work, Bhai
Really appreciate the effort infused to get a demonstrable product in place 

Good day
4/17/23, 9:55‚ÄØAM - Amit: Msg from saptarshi sirüòÅüëç
4/17/23, 9:57‚ÄØAM - Siddharth: Same
4/17/23, 9:57‚ÄØAM - Siddharth: Kai?
4/17/23, 9:59‚ÄØAM - Amit: Product demo
4/17/23, 10:00‚ÄØAM - Siddharth: Aapne kai nathi ne?
4/17/23, 10:00‚ÄØAM - Siddharth: Koie kidhu?
4/17/23, 10:00‚ÄØAM - Amit: No idea
4/17/23, 10:00‚ÄØAM - Amit: Hu pan tane puchhu chhu
4/17/23, 10:00‚ÄØAM - Siddharth: Bhai sir gaya chhe badha Mumbai for demo
4/17/23, 10:00‚ÄØAM - Amit: Ok
4/17/23, 10:00‚ÄØAM - Amit: Mane thayu online chhe
4/18/23, 11:05‚ÄØAM - Amit: <Media omitted>
4/18/23, 11:49‚ÄØAM - Amit: Pelu doc valu badha border vala statement ma chale chhe ne?
4/18/23, 11:49‚ÄØAM - Siddharth: Ha
100%
4/18/23, 11:49‚ÄØAM - Amit: To aa product bank ne j propose karvani chhe to border valu j rakhie?
4/18/23, 11:51‚ÄØAM - Siddharth: Na, Debayan told that there are possibilities of non-border.
Also, our tabula+camelot engine giving really good results, just couple of issues due to excel files
4/18/23, 11:51‚ÄØAM - Amit: E to pandas version
4/18/23, 11:51‚ÄØAM - Siddharth: Also, we need to figure out condition when to use tabula and when to use camelot
4/18/23, 11:51‚ÄØAM - Amit: ha
4/18/23, 11:52‚ÄØAM - Siddharth: Bhai e test thai jaay to shanti
4/18/23, 12:02‚ÄØPM - Siddharth: <Media omitted>
4/18/23, 12:49‚ÄØPM - Amit: <Media omitted>
4/18/23, 1:01‚ÄØPM - Amit: import tabula
import os

tables = tabula.read_pdf("C:/Users/admin/Desktop/GSTR3B_Sample.pdf", pages="all")
print(tables)
4/18/23, 1:18‚ÄØPM - Siddharth: <Media omitted>
4/19/23, 11:22‚ÄØAM - Siddharth: Kya chhe tu?
4/19/23, 11:46‚ÄØAM - Siddharth: Bhai
4/19/23, 11:46‚ÄØAM - Siddharth: A
4/19/23, 11:46‚ÄØAM - Siddharth: M
4/19/23, 11:46‚ÄØAM - Siddharth: I
4/19/23, 11:46‚ÄØAM - Siddharth: T
4/19/23, 11:46‚ÄØAM - Siddharth: Reply
4/19/23, 11:46‚ÄØAM - Siddharth: Fast
4/19/23, 11:46‚ÄØAM - Siddharth: I
4/19/23, 11:46‚ÄØAM - Siddharth: have
4/19/23, 11:46‚ÄØAM - Siddharth: ques
4/19/23, 12:46‚ÄØPM - Amit: 11 days pachhi mokalu to chalshe?

Atayre 3116 chhe acc ma etle (min balance 3000 compulsory etle)
4/19/23, 12:46‚ÄØPM - Siddharth: Ha
4/19/23, 12:47‚ÄØPM - Amit: Thanks bro üôè
4/19/23, 1:05‚ÄØPM - Amit: https://colab.research.google.com/drive/1Sfz6Jr0C9RkxMbbshhqQ82RdOti4-_i9?usp=sharing
4/19/23, 1:05‚ÄØPM - Amit: Ask sir about data preservation
4/19/23, 5:52‚ÄØPM - Siddharth: Be Or nu kyare kevano hato tu?
4/19/23, 5:52‚ÄØPM - Siddharth: Ke ene natu kidhu?
4/19/23, 5:52‚ÄØPM - Amit: Or nu mane pan noti khabar.
Kale vaat thai etle e name and acc thi j keto hato
4/19/23, 5:53‚ÄØPM - Siddharth: To have karvu padshe ne?
4/19/23, 5:53‚ÄØPM - Amit: Ha
4/19/23, 5:53‚ÄØPM - Siddharth: Aavi ja ne ahi, kari daie
4/19/23, 5:53‚ÄØPM - Siddharth: Logic ma help joishe
4/19/23, 5:53‚ÄØPM - Amit: Aavu on the way
4/19/23, 5:53‚ÄØPM - Siddharth: Okay
4/21/23, 12:43‚ÄØPM - Amit: https://myjms.mohe.gov.my/index.php/ijbtm/article/view/20641
4/21/23, 12:46‚ÄØPM - Amit: https://iopscience.iop.org/article/10.1088/1742-6596/1871/1/012115/meta
4/21/23, 12:47‚ÄØPM - Amit: https://arxiv.org/abs/2002.02011
4/21/23, 1:01‚ÄØPM - Amit: https://www.tandfonline.com/doi/abs/10.1080/00472778.2022.2135718
4/21/23, 1:03‚ÄØPM - Amit: https://www.sciencedirect.com/science/article/pii/S0378437119313652
4/21/23, 1:09‚ÄØPM - Amit: Comparing Performance of Machine 
Learning Algorithms for Default Risk 
Prediction in Peer to Peer Lending
4/21/23, 6:56‚ÄØPM - Siddharth: https://worldresearchlibrary.org/proceeding.php?pid=5513
4/21/23, 11:01‚ÄØPM - Siddharth: https://youtu.be/KlzQBavpUNU
4/22/23, 9:56‚ÄØAM - Amit: Aapne je interval vala transaction kathi chie ne ema jo name and amount same hoy eva alag kari daie etle issue solve
4/22/23, 10:06‚ÄØAM - Siddharth: Tu mane e check kari aap ke aapna statement ma repeat entries chhe ke nai
4/22/23, 10:06‚ÄØAM - Siddharth: Na, interval pan same joie
4/22/23, 10:08‚ÄØAM - Siddharth: And jo repeat hoy to mane mokal kaya chhe
4/22/23, 10:23‚ÄØAM - Amit: Room par aavi ne mokalu and aapne kayu statement follow karie chie mane eni pdf mokal etle hu ema check kari lav
4/22/23, 10:23‚ÄØAM - Siddharth: <Media omitted>
4/22/23, 10:23‚ÄØAM - Amit: Ok
4/22/23, 9:57‚ÄØPM - Siddharth: https://www.linkedin.com/in/siddharth-patel-5a73751b2
4/24/23, 10:15‚ÄØAM - Siddharth: 1:05 e campus, I need to meet Jay
4/24/23, 10:29‚ÄØAM - Amit: Vinay sir no call hato
4/24/23, 10:29‚ÄØAM - Amit: Hu class me chhu
4/24/23, 10:29‚ÄØAM - Amit: Tu karne emne call
4/24/23, 10:30‚ÄØAM - Siddharth: Okay
4/24/23, 10:33‚ÄØAM - Siddharth: 11:45 e malvanu chhe sir ne
4/24/23, 10:21‚ÄØPM - Siddharth: <Media omitted>
4/25/23, 12:49‚ÄØAM - Amit: <Media omitted>
4/25/23, 12:49‚ÄØAM - Amit: <Media omitted>
4/25/23, 11:18‚ÄØAM - Siddharth: Test this
4/25/23, 11:18‚ÄØAM - Siddharth: <Media omitted>
4/25/23, 11:34‚ÄØAM - Amit: Ok
4/26/23, 10:19‚ÄØPM - Siddharth: https://github.com/Siddharth1India/Python-for-everyone-else/blob/master/Lecture_01.ipynb
4/27/23, 9:30‚ÄØAM - Siddharth: Reminder, office
4/27/23, 9:36‚ÄØAM - Amit: Hu aavi gayo chhu hostel
4/27/23, 9:37‚ÄØAM - Amit: Tu ready thai jaje
4/27/23, 11:02‚ÄØAM - Siddharth: <Media omitted>
4/27/23, 2:22‚ÄØPM - Siddharth: saptarshi@ssbi.in
4/27/23, 2:22‚ÄØPM - Siddharth: indrajit@ssbi.in
4/27/23, 2:23‚ÄØPM - Amit: s.das@ssbi.in
4/27/23, 2:38‚ÄØPM - Amit: .
4/27/23, 2:39‚ÄØPM - Amit: .
4/27/23, 5:26‚ÄØPM - Amit: <Media omitted>
4/28/23, 8:21‚ÄØPM - Amit: <Media omitted>
4/29/23, 10:39‚ÄØAM - Siddharth: Reminder, project
4/29/23, 10:42‚ÄØAM - Amit: Ha yaad chhe
4/30/23, 10:52‚ÄØAM - Siddharth: https://www.kaggle.com/datasets/haroonalam16/20-skin-diseases-dataset
4/30/23, 12:02‚ÄØPM - Amit: https://www.kaggle.com/datasets/ismailpromus/skin-diseases-image-dataset
4/30/23, 12:49‚ÄØPM - Siddharth: import tensorflow as tf
from tensorflow.keras import layers

def create_mobilenet_model():
    model = tf.keras.Sequential()
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(32, (3,3), strides=(2,2), activation='relu', name='conv_1'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(64, (3,3), strides=(1,1), activation='relu', name='conv_2'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(128, (3,3), strides=(2,2), activation='relu', name='conv_3'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(128, (3,3), strides=(1,1), activation='relu', name='conv_4'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(256, (3,3), strides=(2,2), activation='relu', name='conv_5'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(256, (3,3), strides=(1,1), activation='relu', name='conv_6'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(512, (3,3), strides=(2,2), activation='relu', name='conv_7'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(512, (3,3), strides=(1,1), activation='relu', name='conv_8'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(1024, (3,3), strides=(2,2), activation='relu', name='conv_9'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(1024, (3,3), strides=(1,1), activation='relu', name='conv_10'))
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(10, activation='softmax'))

    return model


import keras
from keras.preprocessing.image import ImageDataGenerator

input_shape = (224,224,3)
num_classes = 10

model = create_mobilenet_model()
# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

TRAIN_DIR = './Dataset/resized_images/train'
TEST_DIR = './Dataset/resized_images/test'

train_datagen = ImageDataGenerator(rescale=1./255,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)

val_datagen = ImageDataGenerator(rescale=1./255)


training_set = train_datagen.flow_from_directory(directory=TRAIN_DIR,
                                                  target_size=input_shape[:2],
                                                  batch_size=16,
                                                  class_mode='categorical')

validation_set = val_datagen.flow_from_directory(directory=TEST_DIR,
                                                  target_size=input_shape[:2],
                                                  batch_size=16,
                                                  class_mode='categorical')


LR = 1e-4

# Train the model
history = model.fit_generator(training_set,
                              epochs=25,
                              validation_data=validation_set)
model.save('myMobileNet.h5')
4/30/23, 1:04‚ÄØPM - Siddharth: import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define some hyperparameters
image_size = (224, 224)
batch_size = 32
num_classes = 6

# Data augmentation for training set
train_datagen = keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True
)

# Data augmentation for testing set
test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

# Load the training set
train_set = train_datagen.flow_from_directory(
    'train/',
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

# Load the testing set
test_set = test_datagen.flow_from_directory(
    'test/',
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

# Build the model
model = keras.Sequential(
    [
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(256, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.Dense(num_classes, activation='softmax')
    ]
)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_set, epochs=10, validation_data=test_set)

# Evaluate the model on the testing set
test_loss, test_acc = model.evaluate(test_set)
print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')
4/30/23, 9:26‚ÄØPM - Amit: ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None), where axis -1 (0-based) is the channel dimension, which 
found to be `None`.
4/30/23, 9:35‚ÄØPM - Siddharth: image_decoded.set_shape([None, None, 3])
4/30/23, 10:20‚ÄØPM - Siddharth: <Media omitted>
5/1/23, 11:37‚ÄØAM - Siddharth: Next time tu laundry ma kapda aape etle mane keje. Mare 2 shirt ne 2 T shirt aapva chhe
5/1/23, 7:19‚ÄØPM - Amit: User types:
A. Small Business Owner with less budget looking Flor Next Opportunity via LinkedIn, Clutch, Facebook and other marketplaces 
B. Student or professional ready to work to gain experience and build a new career path 
C. Project Manager trying to streamline the operations want to cut costs, improve productivity and be resourceful needs a daily prompt or advice to see how his project is going and alert him or her with necessary change recommendations
Something on those lines
Each user type will need to have standard KPIs to measure their growth, assess their performance and build their capabilities. 

We might start with assessment of their credentials in the first phase and provide them with a roadmap (Option A, Option B, Option C) and have them pick their path to build their capabilities and value in the market compared to other providers or professionals in the market.

Once that‚Äôs in place, we will work on other items as mentioned above. As it needs to be broken down into smaller chunks based on solutions
5/1/23, 8:43‚ÄØPM - Amit: <Media omitted>
5/2/23, 3:34‚ÄØPM - Siddharth: https://arxiv.org/pdf/2110.00061.pdf
5/2/23, 3:43‚ÄØPM - Amit: https://www.osti.gov/biblio/1460210
5/2/23, 4:08‚ÄØPM - Siddharth: https://youtu.be/T35ba_VXkMY
5/2/23, 4:08‚ÄØPM - Siddharth: https://github.com/microsoft/table-transformer
5/2/23, 4:09‚ÄØPM - Siddharth: https://huggingface.co/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection
5/2/23, 4:09‚ÄØPM - Siddharth: https://huggingface.co/microsoft/table-transformer-detection
5/2/23, 4:10‚ÄØPM - Siddharth: https://arxiv.org/abs/2005.12872
5/2/23, 4:10‚ÄØPM - Siddharth: https://ai.facebook.com/blog/end-to-end-object-detection-with-transformers/
5/2/23, 4:10‚ÄØPM - Siddharth: https://github.com/facebookresearch/detr
5/2/23, 4:15‚ÄØPM - Siddharth: PubTables-1M: Towards comprehensive table extraction from unstructured documents
5/2/23, 4:15‚ÄØPM - Siddharth: Recently, significant progress has been made applying machine learning to the problem of table structure inference and extraction from unstructured documents. However, one of the greatest challenges remains the creation of datasets with complete, unambiguous ground truth at scale. To address this, we develop a new, more comprehensive dataset for table extraction, called PubTables-1M. PubTables-1M contains nearly one million tables from scientific articles, supports multiple input modalities, and contains detailed header and location information for table structures, making it useful for a wide variety of modeling approaches. It also addresses a significant source of ground truth inconsistency observed in prior datasets called oversegmentation, using a novel canonicalization procedure. We demonstrate that these improvements lead to a significant increase in training performance and a more reliable estimate of model performance at evaluation for table structure recognition. Further, we show that transformer-based object detection models trained on PubTables-1M produce excellent results for all three tasks of detection, structure recognition, and functional analysis without the need for any special customization for these tasks.
5/2/23, 4:16‚ÄØPM - Siddharth: End-to-End Object Detection with Transformers
5/2/23, 4:16‚ÄØPM - Siddharth: We present a new method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster RCNN baseline on the challenging COCO object detection dataset. Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines.
5/2/23, 4:23‚ÄØPM - Amit: <Media omitted>
5/2/23, 5:02‚ÄØPM - Siddharth: <Media omitted>
5/3/23, 12:20‚ÄØPM - Siddharth: Reminder: Meeting with Sir
5/3/23, 12:20‚ÄØPM - Siddharth: Also, We both need to go
5/3/23, 12:32‚ÄØPM - Amit: Ketla vage?
5/3/23, 12:32‚ÄØPM - Siddharth: After lunch kidhu hatu ne?
5/3/23, 12:32‚ÄØPM - Amit: Ha
5/3/23, 12:32‚ÄØPM - Siddharth: So 2 i guesssssss
5/3/23, 12:32‚ÄØPM - Amit: Ok
5/3/23, 1:06‚ÄØPM - Amit: Hu atyare sui jav chhu mane 2 vage call karine jagadhr
5/3/23, 1:06‚ÄØPM - Amit: You deleted this message
5/3/23, 1:07‚ÄØPM - Siddharth: Bhai 1:45 e javanu chhe
5/3/23, 1:07‚ÄØPM - Siddharth: Hu 1:40 e call karu
5/3/23, 1:07‚ÄØPM - Amit: 1 thi 2 hoy ne lunch?
5/3/23, 1:07‚ÄØPM - Siddharth: .
5/3/23, 1:07‚ÄØPM - Amit: Ok
5/3/23, 7:13‚ÄØPM - Siddharth: Respected Sir,

We are working on details of paper "End-to-End Object Detection with Transformers" for bank statements. It will take couple of more days to analyze paper completely.

Thanks
5/4/23, 5:32‚ÄØPM - Amit: 878 2077 2665
5/4/23, 5:33‚ÄØPM - Amit: password: 441539
5/4/23, 6:20‚ÄØPM - Amit: <Media omitted>
5/4/23, 7:47‚ÄØPM - Amit: Kya gaya chho?
5/4/23, 7:48‚ÄØPM - Siddharth: GIFT
5/4/23, 7:48‚ÄØPM - Amit: Exactly shu khava ?
5/4/23, 9:12‚ÄØPM - Amit: 2 dry Manchurian
2 20 vali sprite
5/4/23, 9:13‚ÄØPM - Siddharth: üëç
5/5/23, 4:48‚ÄØPM - Siddharth: Respected Sir,

We are working on two different mechanisms to extract tables.

Thanks
5/6/23, 7:33‚ÄØPM - Amit: You deleted this message
5/6/23, 7:33‚ÄØPM - Amit: Respected sir,

Today, I have continued my work on table extraction using RegEx.

Thank you.
5/6/23, 7:33‚ÄØPM - Siddharth: Banne no nearly same moklish
5/6/23, 7:33‚ÄØPM - Amit: No problem
5/6/23, 7:34‚ÄØPM - Amit: Credentials:

Email ID: amit.hirpara@ssbi.in 
App Password: mvjxgqbspbecprij
5/6/23, 7:34‚ÄØPM - Amit: Account login no thay to mane call karje.
5/6/23, 10:38‚ÄØPM - Siddharth: This message was deleted
5/6/23, 10:38‚ÄØPM - Siddharth: Khali code mokli dau to?
5/6/23, 10:46‚ÄØPM - Siddharth: Bhai, aa logout j kya chhe?
5/6/23, 10:49‚ÄØPM - Siddharth: Mail done ho
5/6/23, 11:51‚ÄØPM - Amit: Thank you sir üôèüôè
5/6/23, 11:51‚ÄØPM - Siddharth: üòÖ
5/7/23, 2:31‚ÄØPM - Siddharth: Abstract lakhyo
5/7/23, 2:32‚ÄØPM - Siddharth: Baaki aagal format nathi, should we write as per our own choice?
5/7/23, 3:31‚ÄØPM - Amit: You deleted this message
5/7/23, 3:32‚ÄØPM - Amit: Guidelines ma sections aapela chhe ke kya kya lakhvana chhe e
5/7/23, 3:58‚ÄØPM - Siddharth: Okayyy
5/8/23, 11:35‚ÄØAM - Siddharth: <Media omitted>
5/8/23, 12:25‚ÄØPM - Amit: The recent advancements in deep learning and neural network architectures enable us to take-on various problems and solve them with fundamentally different methods than what we have been doing in past since long time. Medical field, especially diagnosis of disease is one of the main focus of research in deep learning as neural networks make it extremely simple to identify health condition with either basic reports or with photos without help of any medical domain expert with good accuracy which make process fast as well as easy for people. 

Deep neural networks can detect and classify almost all medical conditions which can be recognized by human eyes as they are extremely good at identifying patterns. Deep neural networks are not intended to replace doctors or any other health professionals but are created to reduce burden on existing health infrastructure. There main purpose is to FastTrack process of diagnosis of disease and save time between reports and starting treatment. 

In this study, our main focus is to compare various neural network architectures to identify skin disease from images of patient. These images can be taken directly with user‚Äôs camera without any requirement of medical equipment and can give good results in classifying 10 major skin diseases. We have performed basic level of process on each image while keeping computation limitations in mind. Our models can work on smallest of computation devices of consumer usage such as smartphone with basic processor and basic personal computers.

While it is simple task to get very high accuracy in classification task for standard datasets and limited number of classes, it is difficult to get similar results with real-world dataset and smaller, shallow neural networks. The complete experiment was performed in many parts including identifying suitable smaller neural networks, finding and cleaning dataset, writing base model in PyTorch for design, running experiment to test computational resource consumption, make changes in models as per requirement, tracking experiments for updated models, replicating similar model in Tensorflow for production purpose, creation of backend API for deployment purpose, writing frontend for webapp and writing android app in Java for mobile usage. 

The end results were accurate enough to put model in production with user interface (discussed in more details in results section). We have tested multiple models including classic CNNs, VGG11, MobileNet, EfficientNet, DenseNet and state-of-the-art Vision Transformers. Some are written from scratch while some are pre-trained and fine tuning was done for our dataset. While vision transformers perform best, it is almost impossible to put them into production due to their massive size and requirement of really high computational resources. We are using MobileNet as our model in production.
5/8/23, 12:29‚ÄØPM - Siddharth: Skin diseases have been a major health concern for a long time, and their identification has been a challenging task for medical practitioners. In the past, conventional methods were used to diagnose skin diseases, which involved a combination of visual examination and clinical assessment. The process was time-consuming and required expertise, which made it difficult to scale up the process. Medical professionals had to rely on their experience and training to make a diagnosis, which often led to misdiagnosis and delayed treatment.

The development of computer technology and classic programming has enabled medical professionals to use image-based analysis to identify skin diseases. This approach involves capturing images of the affected area and analyzing them using computer programs to identify the type of skin disease. The use of classic programming involved developing algorithms and models that could identify the patterns in the images and classify them into different categories of skin diseases. However, this approach had limited success as it was dependent on the ability of the programmers to identify the relevant features and develop the appropriate models.

The recent advancements in deep learning and neural network architectures have revolutionized the field of medical diagnosis. Deep neural networks have been found to be extremely effective in identifying patterns and classifying them into different categories, making it possible to identify skin diseases with a high degree of accuracy. The use of deep learning has made the process of identifying skin diseases faster, more accurate, and less reliant on the expertise of medical professionals.

In this context, the main focus of research in deep learning has been to develop models that can identify skin diseases from images with a high degree of accuracy. These models have been trained on large datasets of images, which have been labeled with the type of skin disease. The models have been designed to identify the patterns in the images that are indicative of the presence of a skin disease and classify them into different categories.

The challenge in developing these models has been to ensure that they are accurate and reliable, even when working with real-world datasets and smaller, shallow neural networks. This has required researchers to experiment with different architectures and algorithms to find the most effective combination. Additionally, the computational resources required to run these models have been a major consideration, with researchers needing to develop models that can run on smaller devices such as smartphones and personal computers.

Overall, the development of deep learning and neural network architectures has enabled medical professionals to improve the accuracy and efficiency of skin disease diagnosis. The use of image-based analysis has made the process faster and more accurate, while the development of deep learning models has made it possible to identify skin diseases with a high degree of accuracy. The ongoing research in this area is focused on developing even more accurate and reliable models that can be used to diagnose a wider range of skin diseases.
5/8/23, 12:32‚ÄØPM - Siddharth: The motivation behind this project was to develop a deep learning model that can accurately identify skin diseases from images. Skin diseases can be difficult to diagnose, and misdiagnosis can lead to delayed treatment and poor outcomes. The use of deep learning and neural network architectures offered a promising solution to this problem, as these models are capable of identifying patterns in images and classifying them into different categories.

The project aimed to compare different neural network architectures and identify the most effective model for skin disease classification. The models were tested on a real-world dataset of images, which contained a variety of skin diseases. The goal was to develop a model that could accurately classify the different types of skin diseases with a high degree of accuracy, while also being efficient enough to run on smaller devices such as smartphones and personal computers.

The development of such a model would have significant implications for the field of medical diagnosis, as it would enable medical professionals to quickly and accurately identify skin diseases, even in remote or resource-limited settings. The model could also be used to develop mobile applications or web-based tools that could be used by patients to self-diagnose skin conditions, potentially reducing the burden on healthcare systems and improving access to care.

Overall, the motivation behind this project was to leverage the power of deep learning and neural network architectures to improve the accuracy and efficiency of skin disease diagnosis. The project aimed to develop a model that could be easily integrated into existing healthcare infrastructure, while also being accessible to patients and medical professionals alike.
5/8/23, 12:46‚ÄØPM - Siddharth: The objective of this project was to develop a deep learning model that could accurately identify and classify different types of skin diseases from images. The model should be able to differentiate between 10 major skin diseases, including eczema, psoriasis, and Melanoma, with a high degree of accuracy. To achieve this objective, we aimed to compare different neural network architectures and identify the most effective model for skin disease classification.

Specifically, the project aimed to achieve an accuracy rate of at least 85% in identifying the 10 major skin diseases from images. The model should also be designed to be lightweight and efficient enough to run on smaller devices such as smartphones and basic personal computers. Additionally, the project aimed to develop a user-friendly interface for the model, including web and mobile applications, to enable easy access for patients and medical professionals alike.

In summary, the objective of this project was to develop a highly accurate, lightweight, and accessible deep learning model for skin disease identification, which can improve the speed and accuracy of medical diagnosis and potentially reduce the burden on healthcare systems.
5/8/23, 12:48‚ÄØPM - Siddharth: PROBLEM STATEMENT

Skin diseases can be difficult to diagnose accurately, and misdiagnosis can lead to delayed treatment and poor outcomes. The traditional methods of skin disease identification relied on manual examination by medical professionals, which can be time-consuming and require specialized knowledge. In addition, the availability of medical professionals can be limited in remote or resource-limited settings.

To address these challenges, the use of deep learning and neural network architectures offers a promising solution. However, developing an accurate and efficient deep learning model for skin disease identification is not without its challenges. Real-world datasets can be complex, and the identification of suitable neural network architectures can be time-consuming and computationally expensive. Additionally, the development of user-friendly interfaces for these models can be a significant challenge.

The problem statement of this project, therefore, is to develop an accurate, efficient, and accessible deep learning model for skin disease identification that can be easily integrated into existing healthcare infrastructure. This model should be capable of accurately identifying and classifying 10 major skin diseases from images, while also being lightweight enough to run on smaller devices such as smartphones and personal computers. Additionally, the model should be complemented by user-friendly interfaces such as web and mobile applications, to improve accessibility for patients and medical professionals alike.
5/8/23, 1:31‚ÄØPM - Siddharth: The approach taken in this project involved several steps, including:

Dataset selection and preprocessing:

Identify a dataset of skin disease images containing 10 major skin diseases, including Atopic Dermatitis, Basal Cell Carcinoma (BCC), Benign Keratosis-like Lesions (BKL), Eczema, Melanocytic Nevi (NV), Melanoma, Psoriasis, Seborrheic Keratoses, Tinea Ringworm Candidiasis, Warts Molluscum, and other Viral Infections.
Apply preprocessing techniques to enhance the quality of the images.
Model selection and evaluation:

Evaluate six different deep learning models for their performance in accurately classifying skin diseases.
The models evaluated include classic Convolutional Neural Networks (CNNs), VGG11, MobileNet, EfficientNet, DenseNet, and state-of-the-art Vision Transformers.
Model optimization:

Fine-tune the selected model to improve its performance on the skin disease dataset.
Test the optimized model on a validation dataset to ensure that it generalizes well to new data.
Deployment:

Develop an API to provide access to the trained model.
Build a web application and Android app to enable users to upload skin images and receive a diagnosis of the detected skin disease.
5/8/23, 1:34‚ÄØPM - Siddharth: Dataset selection: We searched for publicly available datasets of skin disease images and selected a dataset that contained 10 major skin diseases. Out of multiple datasets, most were in very bad format and not suitable for any deep learning tasks. We found our dataset on Kaggle which contains 27,200 images belongs to 10 different classes.
5/8/23, 1:34‚ÄØPM - Siddharth: Dataset preprocessing: The dataset contained images of various resolutions and sizes. We resized all the images to a common size of 224 x 224 pixels. We also applied data augmentation techniques such as rotation, horizontal and vertical flipping, and brightness and contrast adjustment to increase the diversity of the dataset and improve the generalization performance of the models.
5/8/23, 1:35‚ÄØPM - Siddharth: Class balancing: The dataset was imbalanced, with some classes having significantly fewer images than others. To address this issue, we manually selected images. We got 1000 images per class.
5/8/23, 1:36‚ÄØPM - Siddharth: Dataset splitting: We split the dataset into three subsets - training, validation, and testing. The training set was used to train the models, the validation set was used to tune the hyperparameters and avoid overfitting, and the testing set was used to evaluate the performance of the models.
5/8/23, 1:37‚ÄØPM - Siddharth: Data shuffling: We shuffled the training and validation sets to avoid any bias in the training process.
5/8/23, 1:38‚ÄØPM - Siddharth: Model selection: We evaluated several state-of-the-art deep learning models for image classification, including Convolutional Neural Networks (CNN), VGG, MobileNet, EfficientNet, DenseNet, and Vision Transformers. We selected these models based on their performance on standard image classification datasets and their suitability for mobile and web deployment.
5/8/23, 1:38‚ÄØPM - Siddharth: Model architecture: For each selected model, we customized the architecture to fit the requirements of the skin disease classification task. We added a final fully connected layer with 10 outputs, corresponding to the 10 skin diseases in the dataset. We also froze the weights of the initial layers (for pretrained models) of the models and fine-tuned the weights of the final layers on our dataset.
5/8/23, 1:38‚ÄØPM - Siddharth: Hyperparameter tuning: We fine-tuned the hyperparameters of the models using the validation set. The hyperparameters we tuned included learning rate, optimizer, batch size, and number of epochs.
5/8/23, 1:38‚ÄØPM - Siddharth: Model training: We trained the models on the training set using the optimized hyperparameters. We used a categorical cross-entropy loss function and the Adam optimizer to optimize the weights of the models.
5/8/23, 1:39‚ÄØPM - Siddharth: Model evaluation: We evaluated the performance of the models on the testing set using various evaluation metrics, including accuracy, precision, recall, and F1 score. We also generated confusion matrices to visualize the classification performance of the models for each skin disease. We used these metrics to compare the performance of different models and select the best-performing model for deployment.
5/8/23, 1:41‚ÄØPM - Siddharth: Deployment: We created simple Flask API for backend. We created android interface as well as web platform to deploy created model for user engagement.
5/8/23, 1:42‚ÄØPM - Siddharth: The scope of this project is to develop an end-to-end solution for the identification and classification of skin diseases using deep learning techniques. The project involves collecting and preprocessing a dataset of skin disease images, training and evaluating various deep neural network architectures on the dataset, selecting the best-performing model, and deploying the model as a Flask API that can be called from a website or mobile app.

The project is limited to the classification of ten common skin diseases, namely Atopic Dermatitis, Basal Cell Carcinoma (BCC), Benign Keratosis-like Lesions (BKL), Eczema, Melanocytic Nevi (NV), Melanoma, Psoriasis, Seborrheic Keratoses, Tinea Ringworm Candidiasis, Warts Molluscum and other Viral Infections, using six different deep neural network architectures, namely CNN, VGG, MobileNet, EfficientNet, DenseNet, and Vision Transformers. The project also focuses on creating a user-friendly web interface and Android app for the prediction of skin diseases using the deployed deep learning model.
5/8/23, 1:50‚ÄØPM - Siddharth: In the paper "SKIN DISEASE PREDICTION" by Sanas et al., a neural network based on image analysis is used to predict skin diseases. The authors argue that traditional diagnosis and prediction of skin diseases require a long process, including a patient's history, physical examination, and laboratory tests. Moreover, the complexity and number of features of the disease make the diagnosis and prediction difficult. To address these challenges, the authors introduce a computer-aided diagnosis and recognition system that uses ResNet152V2 algorithm with an artificial neural network (ANN) as a classifier.

The proposed system involves several steps, including image processing, image feature extraction, and data classification using the feature extraction and soft-max classifier of Convolutional Neural Network (CNN). The system aims to provide more accuracy and efficiency, making it more reliable for dermatology.

The paper provides insights into the use of neural networks and image analysis in predicting skin diseases, which can potentially contribute to the development of computer-aided diagnosis and recognition systems for dermatology. However, the study has limitations in terms of the dataset used and the types of skin diseases considered.
5/8/23, 2:04‚ÄØPM - Siddharth: <Media omitted>
5/8/23, 2:08‚ÄØPM - Siddharth: https://docs.google.com/document/d/1rT9RBvSpFssS1OtGP_5j6coEcEUIK9H3lYYFSfKsDsw/edit?usp=sharing
5/8/23, 2:12‚ÄØPM - Siddharth: The paper by Ahmed A. Elngar et al. proposes an intelligent system for skin disease prediction using machine learning. The authors acknowledge the complexity of diagnosing skin diseases and the lack of medical infrastructure and facilities to detect them. To address this challenge, the proposed system combines Convolutional Neural Network (CNN) with Support Vector Machine (SVM) classifier to develop a Mobile Android Application (MAA). The system is trained and evaluated on a dataset consisting of around 3000 images collected from various sources like hospitals and websites.

The authors conduct several experiments on the dataset, applying different feature extraction algorithms with different classifiers. They compare the results and conclude that the proposed (CNN-SVM-MAA) system is effective in detecting skin diseases and providing the user with the disease name and treatment-related prescription with high accuracy. The system is expected to be helpful for dermatologists, general physicians, and the general public to detect and diagnose skin diseases. The study presents a novel approach to using machine learning and mobile applications for skin disease prediction and diagnosis.
5/8/23, 2:23‚ÄØPM - Siddharth: Rao et al. proposed a multiclass deep learning model for skin disease detection and classification using a Convolutional Neural Network (CNN) algorithm. The authors highlighted the difficulty in diagnosing and treating skin diseases due to the unpredictable and uneven nature of human skin, environmental factors, and lack of medical facilities in remote areas. The proposed model was trained to differentiate between healthy skin and skin suffering from a disease, and classify skin diseases into their main classes such as MelanocyticNevi, Melanoma, Benign keratosis-like lesions, Basal cell Carcinoma, ActinicKeratoses, Vascular lesion, and Dermatofibroma. The authors used Deep Learning, a subset of Machine Learning, to train the model, which reduced the number of classifiers required. The CNN algorithm was preferred due to its effectiveness in image classification. The proposed model has the potential to improve dermatology diagnosis and treatment, especially in areas where medical facilities are limited.
5/8/23, 2:27‚ÄØPM - Siddharth: SKIN DISEASE PREDICTION
Prof .Shrikant Sanas(Guide) , Prabhakar Pawale1, Gaurav Ghadage2, Monish Sahani3

Intelligent System for Skin Disease Prediction using Machine 
Learning 
Ahmed A. Elngar 1
, Rishabh Kumar 2
, Amber Hayat 3
, Prathamesh Churi 4

Skin Disease Detection using Machine Learning
Kritika Sujay Rao
Department of Computer Engineering
Vidyvardhini‚Äôs College of Engineering And
Technology (Mumbai University)
Vasai, India
Pooja Suresh Yelkar 
Department of Computer Engineering
Vidyavardhini‚Äôs College of Engineering And
Technology (Mumbai University)
Vasai, India
Omkar Narayan Pise
Department of Computer Engineering
Vidyavardhini‚Äôs College of Engineering And
Technology (Mumbai University)
Vasai, India
Dr. Swapna Borde
Department of Computer Engineering
Vidyavardhini‚Äôs College of Engineering And
Technology(Mumbai University)
5/8/23, 2:59‚ÄØPM - Siddharth: This message was deleted
5/8/23, 5:21‚ÄØPM - Siddharth: Respected Sir,

As per our current progress, it looks like deep neural network approach will work only on images so only way is to convert PDF, get table structure and fill data with OCR. That is why, we are working on regex approach first.

Thanks
5/8/23, 6:22‚ÄØPM - Siddharth: We have tested various models for image classification with lot of experimentations and hyperparameter tuning. The models we have currently are very optimized in terms of resource consumption and accuracy. Here, we will discuss architecture and general theory of each model in detail.
5/8/23, 6:25‚ÄØPM - Siddharth: This message was deleted
5/8/23, 6:29‚ÄØPM - Siddharth: Convolutional Neural Networks (CNN) are a type of artificial neural network used for image recognition and processing tasks. They were inspired by the architecture and functionality of the visual cortex in animals. CNNs are made up of a series of layers that can learn features of the input images at increasingly complex levels. The layers include a convolutional layer, a pooling layer, and a fully connected layer.

The convolutional layer is responsible for the feature extraction process. It applies a set of filters, also known as kernels or weights, to the input image to extract various features such as edges, corners, and other shapes. These filters slide over the entire input image, producing a feature map that highlights the important features in the image.

The pooling layer is responsible for reducing the size of the feature maps produced by the convolutional layer. It works by applying a pooling function, such as max pooling or average pooling, to a specific region of the feature map, reducing the size of the map while preserving its important features.

The fully connected layer is responsible for the classification process. It takes the output of the previous layers and flattens it into a one-dimensional vector, which is then passed through a series of fully connected neurons. These neurons use the learned features to classify the input image into different categories.

CNNs are trained using a process known as backpropagation, which adjusts the weights of the filters to minimize the error between the predicted output and the actual output. The training data is typically labeled with the correct outputs, allowing the network to learn from the data and improve its accuracy over time.

CNNs have become a popular tool in computer vision applications such as image classification, object detection, and image segmentation. They have also been used in natural language processing tasks such as sentiment analysis and text classification. Their ability to learn and extract important features from large datasets has made them a powerful tool for many machine learning tasks.
5/8/23, 6:33‚ÄØPM - Siddharth: MobileNet

MobileNetv2 is a convolutional neural network architecture that was proposed by Google researchers in 2018. It is designed to be a highly efficient network for mobile and embedded devices, with a small number of parameters and low computational complexity. The architecture is based on depthwise separable convolutions, which allow for a significant reduction in the number of computations required for convolutional layers.

MobileNetv2 consists of a series of building blocks called inverted residuals, which are composed of a combination of depthwise separable convolutions and linear transformations. Each inverted residual block has a bottleneck structure that reduces the number of channels before applying the depthwise convolution, and then expands the channels again with a 1x1 convolution. This allows the network to capture more complex features while using fewer parameters.

MobileNetv2 also employs a feature map pooling technique called squeeze-and-excitation, which selectively amplifies important features by learning channel-wise scaling factors. This technique is used to improve the discriminative power of the network and further reduce the number of parameters.

MobileNetv2 has achieved state-of-the-art performance on several image classification benchmarks while requiring significantly fewer parameters and lower computational complexity compared to other popular architectures such as VGG and ResNet. Its compact size and efficient computation make it well-suited for deployment on mobile and embedded devices with limited resources.
5/8/23, 6:38‚ÄØPM - Siddharth: EfficientNet is a convolutional neural network (CNN) architecture that was introduced in 2019. It is designed to provide an efficient balance between accuracy and computational complexity, making it well-suited for applications with limited computational resources. The architecture is based on a compound scaling method that uniformly scales the network depth, width, and resolution, which leads to improved performance over existing models.

The EfficientNet architecture is comprised of several building blocks, including depthwise separable convolutions, linear bottleneck layers, and squeeze-and-excitation modules. Depthwise separable convolutions reduce the number of parameters by decomposing a standard convolution into a depthwise convolution and a pointwise convolution. Linear bottleneck layers use a low-dimensional projection before and after the depthwise convolution to reduce computational complexity. Squeeze-and-excitation modules adaptively recalibrate channel-wise feature responses by using a learnable gating mechanism.

EfficientNet has achieved state-of-the-art results on several image classification benchmarks, while being smaller and faster than existing models. The architecture is also flexible and can be easily adapted for other computer vision tasks such as object detection and semantic segmentation. EfficientNet has been widely adopted in industry and academia, and continues to be an active area of research in the computer vision community.
5/8/23, 6:41‚ÄØPM - Siddharth: DenseNet, or Densely Connected Convolutional Networks, is a deep learning architecture that aims to solve the vanishing gradient problem in traditional convolutional neural networks. It was proposed by Huang et al. in 2016 and has since been used in a variety of computer vision tasks.

The key innovation of DenseNet is its dense connectivity pattern, where each layer is connected to all subsequent layers in a feed-forward fashion. This means that the output of each layer is fed into all subsequent layers, creating a dense connectivity graph. This results in a highly efficient use of parameters and feature reuse across the network, leading to better performance with fewer parameters than traditional networks.

DenseNet consists of multiple dense blocks, each of which contains a set of layers that are densely connected to each other. The output of each dense block is fed into a transition layer, which performs down-sampling and dimensionality reduction to reduce the number of parameters and computational complexity of the network. The transition layers also introduce convolutional layers with 1x1 kernels to adjust the number of feature maps and increase network depth.

DenseNet has been shown to achieve state-of-the-art results on a wide range of computer vision tasks, including image classification, object detection, semantic segmentation, and more. Its efficient use of parameters and strong feature reuse make it particularly well-suited for applications with limited computational resources.
5/8/23, 6:42‚ÄØPM - Siddharth: VGG11 is a convolutional neural network architecture with a total of 11 layers, including 8 convolutional layers and 3 fully connected layers. The name "VGG" stands for Visual Geometry Group, which is the research group at the University of Oxford where this architecture was developed.

VGG11 has a simple and uniform architecture, where all convolutional layers have a fixed kernel size of 3x3 and a stride of 1 pixel, and all max pooling layers have a fixed size of 2x2 and a stride of 2 pixels. This simple and uniform design makes it easy to implement and train VGG11 on various image classification tasks.

VGG11 uses ReLU activation after each convolutional and fully connected layer, except for the output layer, which uses a softmax activation to generate class probabilities. Dropout regularization is also applied to the fully connected layers to prevent overfitting.

VGG11 has achieved impressive performance on image classification tasks, including the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) where it achieved a top-5 error rate of 7.3%. Its simple and uniform architecture has also served as a baseline for many subsequent CNN architectures.
5/8/23, 6:44‚ÄØPM - Siddharth: Vision Transformers (ViT) is a recently proposed deep learning architecture for computer vision tasks that utilizes the self-attention mechanism of transformers in natural language processing. Unlike convolutional neural networks, ViT models do not use any convolutional layers and instead rely solely on multi-head self-attention to capture relationships between input image patches.

The ViT architecture consists of a patch embedding layer that divides the input image into non-overlapping patches and flattens each patch into a vector representation. These patch embeddings are then fed into a transformer encoder consisting of multiple layers of multi-head self-attention and feed-forward neural networks. The self-attention mechanism allows the model to learn which patches are most relevant to each other and aggregate information across the entire image.

ViT models are trained on large-scale image classification datasets such as ImageNet using a supervised learning approach, where the model is trained to predict the correct class label given an input image. During training, the model is optimized using backpropagation and gradient descent to minimize the cross-entropy loss between the predicted and actual class labels.

ViT has shown promising results on various computer vision tasks such as image classification, object detection, and segmentation, outperforming traditional convolutional neural network architectures in some cases. However, ViT models typically require a larger amount of training data and computational resources compared to traditional convolutional neural network models.
5/8/23, 6:47‚ÄØPM - Siddharth: In deep learning, optimizers are algorithms that are used to adjust the parameters of a model to minimize the loss function during training. The loss function measures how well the model performs on the training data, and the goal is to minimize this function so that the model can make accurate predictions on new, unseen data.

Optimizers work by updating the weights and biases of the model based on the gradient of the loss function with respect to these parameters. The gradient indicates the direction of steepest descent, which is the direction that will lead to a decrease in the loss function. Optimizers use this gradient to adjust the parameters in small steps, moving closer and closer to the optimal values that minimize the loss function.

There are many different optimizers available in deep learning, each with their own strengths and weaknesses. Some popular optimizers include stochastic gradient descent (SGD), RMSprop, and Adam. Each optimizer has its own hyperparameters that can be tuned to improve performance on a specific task. The choice of optimizer and its hyperparameters can have a significant impact on the performance of a model, so it is important to choose wisely and experiment with different options.
5/8/23, 6:54‚ÄØPM - Siddharth: Adam

Adam (Adaptive Moment Estimation) is a popular optimization algorithm used in deep learning for stochastic gradient descent optimization. It is a combination of the ideas of the RMSprop and momentum algorithms.

Adam optimizer maintains an adaptive learning rate for each parameter of the model, which is updated at every iteration of the training process. It calculates the exponential moving average of the gradient and the squared gradient for each parameter. It also keeps track of the bias-corrected first and second moments of the gradients.

The Adam optimizer updates the parameters of the model by taking a step in the direction of the gradient with a learning rate that is adaptively tuned for each parameter. The learning rate for each parameter is determined by a combination of the estimated first and second moments of the gradient, which allows the learning rate to be adjusted based on the magnitude of the gradient and the history of gradients for that parameter.

Adam optimizer has shown to be effective in a wide range of deep learning applications and has become one of the most commonly used optimization algorithms in the field.
5/8/23, 6:55‚ÄØPM - Siddharth: SGD

Stochastic Gradient Descent (SGD) is a popular optimization algorithm used in deep learning. It is a variant of Gradient Descent (GD) that randomly samples a subset of training data, also known as a minibatch, to compute the gradient at each iteration. This is done to reduce the computational cost and improve convergence speed.

At each iteration, SGD updates the model parameters in the opposite direction of the gradient with respect to the minibatch. The learning rate determines the step size of the parameter update and is usually set to a small value to ensure that the algorithm converges to a minimum.

SGD suffers from high variance in the gradient estimation due to the random sampling of the minibatch. To mitigate this, various extensions to SGD have been proposed, such as Momentum, Nesterov Accelerated Gradient (NAG), Adagrad, and RMSProp. Despite its limitations, SGD remains a popular optimization algorithm due to its simplicity and effectiveness.
5/8/23, 6:57‚ÄØPM - Siddharth: RMSprop

RMSProp (Root Mean Square Propagation) is another widely used optimizer in deep learning. It was introduced in 2012 by Geoffrey Hinton. It is an adaptive learning rate method that modifies the learning rate of each weight in the network based on the average of the magnitudes of recent gradients for that weight. The idea is to scale the learning rate of each weight by a running average of the magnitudes of recent gradients for that weight. This allows the learning rate to adapt to the landscape of the loss function, which can lead to faster convergence and better generalization.

The RMSProp algorithm maintains a moving average of the squared gradient for each weight. The moving average is calculated as a decaying average of past squared gradients, where the decay rate is controlled by a hyperparameter called the decay rate or momentum. The formula for calculating the moving average is similar to that of the exponential moving average used in other optimizers like momentum and Adam.

The update rule for RMSProp involves dividing the gradient by the square root of the moving average of the squared gradient for that weight. This normalization scales the gradient based on the average of the recent gradient magnitudes, which helps to prevent oscillations in the weight updates. The learning rate is also scaled by the same normalization factor, which ensures that larger gradients receive smaller updates.

RMSProp has been shown to work well on a wide range of deep learning problems and is often used as a baseline optimizer for comparison with other optimizers. However, it can still suffer from some of the same issues as other optimizers, such as getting stuck in local minima or plateaus, and can benefit from additional techniques like learning rate schedules or momentum.
5/8/23, 7:05‚ÄØPM - Siddharth: In deep learning, a loss function is a measure of how well a model can make predictions on the given data. The goal of a machine learning model is to minimize the loss function during training, which means finding the model parameters that can predict the output as close to the actual output as possible. The loss function is typically defined based on the type of problem being solved, such as regression or classification.

In regression problems, the mean squared error (MSE) loss function is commonly used, which calculates the average squared difference between the predicted and actual output. Another loss function used in regression is mean absolute error (MAE), which calculates the average absolute difference between the predicted and actual output.

In classification problems, the cross-entropy loss function is often used, which measures the difference between the predicted class probabilities and the actual class labels. Binary cross-entropy is used for binary classification problems, while categorical cross-entropy is used for multi-class classification problems.

There are many other loss functions available for specific applications, such as dice loss for image segmentation, focal loss for imbalanced classification problems, and triplet loss for metric learning. The choice of loss function depends on the problem being solved and the desired performance metrics of the model.
5/8/23, 7:07‚ÄØPM - Siddharth: Categorical cross-entropy is a commonly used loss function in deep learning for classification problems. It measures the dissimilarity between the predicted probability distribution and the actual probability distribution. The predicted probability distribution is obtained using a softmax activation function on the output layer of the neural network. The actual probability distribution is a one-hot encoded vector representing the true label of the input data. The categorical cross-entropy loss function is then calculated by taking the negative logarithm of the predicted probability of the true label. This penalizes the model more heavily for larger prediction errors. The overall loss function is the mean of the categorical cross-entropy loss across all training examples. The goal of the training process is to minimize this loss function, which results in a model that can accurately predict the correct label for new input data.
5/9/23, 1:54‚ÄØAM - Siddharth: Just wrote entire experiment.
Model printing, result graphs, everything done.

Me freaking genius
5/9/23, 1:12‚ÄØPM - Siddharth: <Media omitted>
5/9/23, 2:28‚ÄØPM - Amit: https://drive.google.com/drive/folders/1AKvme6iwPVFp1Oe9GhdANofcTVak5CpD?usp=sharing
5/9/23, 3:29‚ÄØPM - Siddharth: <Media omitted>
5/9/23, 3:30‚ÄØPM - Siddharth: <Media omitted>
5/9/23, 3:30‚ÄØPM - Siddharth: <Media omitted>
5/9/23, 3:30‚ÄØPM - Siddharth: <Media omitted>
5/9/23, 3:31‚ÄØPM - Siddharth: <Media omitted>
5/9/23, 8:05‚ÄØPM - Siddharth: CNN

Train acc: 0.6307
Test acc: 0.6767
Train loss: 1.0554
Test loss: 0.9886
5/9/23, 9:07‚ÄØPM - Siddharth: <Media omitted>
5/9/23, 9:08‚ÄØPM - Siddharth: import tensorflow as tf
from tensorflow.keras import layers
import matplotlib.pyplot as plt
def create_mobilenet_model(input_shape=(224,224,3)):
    model = tf.keras.Sequential()
    model.add(layers.Input(shape=input_shape))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(32, (3,3), strides=(2,2), activation='relu', name='conv_1'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(64, (3,3), strides=(1,1), activation='relu', name='conv_2'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(128, (3,3), strides=(2,2), activation='relu', name='conv_3'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(128, (3,3), strides=(1,1), activation='relu', name='conv_4'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(256, (3,3), strides=(2,2), activation='relu', name='conv_5'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(256, (3,3), strides=(1,1), activation='relu', name='conv_6'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(512, (3,3), strides=(2,2), activation='relu', name='conv_7'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(512, (3,3), strides=(1,1), activation='relu', name='conv_8'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(1024, (3,3), strides=(2,2), activation='relu', name='conv_9'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(1024, (3,3), strides=(1,1), activation='relu', name='conv_10'))
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(10, activation='softmax'))

    return model



import keras
from keras.preprocessing.image import ImageDataGenerator

input_shape = (224,224,3)
num_classes = 10

model = create_mobilenet_model()
# Compile the model
opt = tf.keras.optimizers.Adam(learning_rate=1e-4)
model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])

TRAIN_DIR = './dataset/train'
TEST_DIR = './dataset/test'

train_datagen = ImageDataGenerator(rescale=1./255,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)

val_datagen = ImageDataGenerator(rescale=1./255)


training_set = train_datagen.flow_from_directory(directory=TRAIN_DIR,
                                                  target_size=input_shape[:2],
                                                  batch_size=16,
                                                  class_mode='categorical')

validation_set = val_datagen.flow_from_directory(directory=TEST_DIR,
                                                  target_size=input_shape[:2],
                                                  batch_size=16,
                                                  class_mode='categorical')


LR = 1e-4

# Train the model
history = model.fit_generator(training_set,
                              epochs=1,
                              validation_data=validation_set)
model.save('myMobileNet.h5')

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
plt.show()
5/9/23, 9:12‚ÄØPM - Amit: from google.colab import drive
drive.mount('/content/drive')
5/9/23, 9:13‚ÄØPM - Amit: import tensorflow as tf
from tensorflow.keras import layers
import matplotlib.pyplot as plt
def create_mobilenet_model(input_shape=(224,224,3)):
    model = tf.keras.Sequential()
    model.add(layers.Input(shape=input_shape))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(32, (3,3), strides=(2,2), activation='relu', name='conv_1'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(64, (3,3), strides=(1,1), activation='relu', name='conv_2'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(128, (3,3), strides=(2,2), activation='relu', name='conv_3'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(128, (3,3), strides=(1,1), activation='relu', name='conv_4'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(256, (3,3), strides=(2,2), activation='relu', name='conv_5'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(256, (3,3), strides=(1,1), activation='relu', name='conv_6'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(512, (3,3), strides=(2,2), activation='relu', name='conv_7'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(512, (3,3), strides=(1,1), activation='relu', name='conv_8'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(1024, (3,3), strides=(2,2), activation='relu', name='conv_9'))
    model.add(layers.ZeroPadding2D(((0,1),(0,1))))
    model.add(layers.Conv2D(1024, (3,3), strides=(1,1), activation='relu', name='conv_10'))
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(10, activation='softmax'))

    return model



import keras
from keras.preprocessing.image import ImageDataGenerator

input_shape = (224,224,3)
num_classes = 10

model = create_mobilenet_model()
# Compile the model
opt = tf.keras.optimizers.Adam(learning_rate=1e-4)
model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])

TRAIN_DIR = '/content/drive/MyDrive/dataset/train'
TEST_DIR = '/content/drive/MyDrive/dataset/test'

train_datagen = ImageDataGenerator(rescale=1./255,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)

val_datagen = ImageDataGenerator(rescale=1./255)


training_set = train_datagen.flow_from_directory(directory=TRAIN_DIR,
                                                  target_size=input_shape[:2],
                                                  batch_size=16,
                                                  class_mode='categorical')

validation_set = val_datagen.flow_from_directory(directory=TEST_DIR,
                                                  target_size=input_shape[:2],
                                                  batch_size=16,
                                                  class_mode='categorical')


LR = 1e-4

# Train the model
history = model.fit_generator(training_set,
                              epochs=1,
                              validation_data=validation_set)
model.save('myMobileNet.h5')

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
plt.show()
5/9/23, 11:06‚ÄØPM - Siddharth: <Media omitted>
5/9/23, 11:07‚ÄØPM - Siddharth: <Media omitted>
5/10/23, 8:20‚ÄØAM - Amit: Maru pouch room par chhe
5/10/23, 8:54‚ÄØAM - Siddharth: ?
5/10/23, 9:25‚ÄØAM - Siddharth: Ahiya j chhe bhai
5/10/23, 11:33‚ÄØAM - Siddharth: {
    "pdfpath": "uploads/Document.pdf",
    "xlsxpath": "uploads/CMA Format LLAMP Test.xlsx",
    "financialYear": "2022",
    "bankdates": ["07/09/15", "30/06/22"],
    "query": [[["stark", 30918003100], ["stark", 10781632742]]],
    "gstpath":'GSTR3B_Sample.pdf'
}
5/10/23, 11:33‚ÄØAM - Siddharth: {
    "pdfpath": "uploads/Document.pdf",
    "xlsxpath": "uploads/CMA Format LLAMP Test.xlsx",
    "financialYear": "2022",
    "bankdates": ["07/09/15", "30/06/22"],
    "query": [[["stark", 30918003100], ["stark", 10781632742]]],
    "gstpath":'GSTR3B_Sample.pdf'
}
5/10/23, 8:54‚ÄØPM - Siddharth: .
5/11/23, 12:59‚ÄØAM - Siddharth: <Media omitted>
5/11/23, 10:09‚ÄØAM - Amit: add atleast 5 to 6 more pages
5/11/23, 10:09‚ÄØAM - Siddharth: F
Aav tu etle karie
5/11/23, 10:09‚ÄØAM - Amit: Model na into vadhari daie
5/11/23, 10:09‚ÄØAM - Siddharth: I have no idea what to add
5/11/23, 10:09‚ÄØAM - Siddharth: Ha e j thay
5/11/23, 10:09‚ÄØAM - Amit: Hu aavi ne kari laish
5/11/23, 7:35‚ÄØPM - Siddharth: <Media omitted>
5/12/23, 11:44‚ÄØAM - Siddharth: https://maps.app.goo.gl/u8Kt3omXKfWFJzYh7
5/12/23, 11:45‚ÄØAM - Siddharth: https://in.linkedin.com/in/jagdeep-kochar-b677015
5/12/23, 2:01‚ÄØPM - Amit: You deleted this message
5/12/23, 2:01‚ÄØPM - Amit: You deleted this message
5/12/23, 2:01‚ÄØPM - Amit: You deleted this message
5/12/23, 2:07‚ÄØPM - Amit: You deleted this message
5/12/23, 4:21‚ÄØPM - Amit: <Media omitted>
5/12/23, 4:21‚ÄØPM - Amit: <Media omitted>
5/12/23, 4:21‚ÄØPM - Amit: <Media omitted>
5/13/23, 6:44‚ÄØPM - Amit: <Media omitted>
5/13/23, 6:54‚ÄØPM - Amit: <Media omitted>
5/13/23, 6:55‚ÄØPM - Siddharth: <Media omitted>
5/13/23, 6:56‚ÄØPM - Amit: <Media omitted>
5/13/23, 6:56‚ÄØPM - Amit: <Media omitted>
5/13/23, 6:56‚ÄØPM - Amit: <Media omitted>
5/13/23, 6:56‚ÄØPM - Amit: <Media omitted>
5/13/23, 6:58‚ÄØPM - Amit: <Media omitted>
5/13/23, 7:06‚ÄØPM - Amit: Project Offer Letter, Project/Internship Competition Certificate, Job Offer Letter, Score-Cards, Admission Letter, GST registration certificate, conference/journal paper
5/13/23, 7:07‚ÄØPM - Siddharth: https://www.kaggle.com/datasets/ismailpromus/skin-diseases-image-dataset
5/13/23, 7:15‚ÄØPM - Siddharth: <Media omitted>
5/13/23, 7:20‚ÄØPM - Siddharth: <Media omitted>
5/13/23, 7:20‚ÄØPM - Siddharth: <Media omitted>
5/13/23, 7:20‚ÄØPM - Siddharth: <Media omitted>
5/13/23, 7:20‚ÄØPM - Siddharth: <Media omitted>
5/13/23, 7:20‚ÄØPM - Siddharth: <Media omitted>
5/13/23, 7:20‚ÄØPM - Siddharth: <Media omitted>
5/14/23, 6:26‚ÄØPM - Amit: https://www.canva.com/design/DAFi3a-_78Y/UceCrtTfislwaRHTinLSzw/edit?utm_content=DAFi3a-_78Y&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton
5/15/23, 12:06‚ÄØAM - Amit: <Media omitted>
5/15/23, 10:22‚ÄØAM - Siddharth: <Media omitted>
5/15/23, 3:04‚ÄØPM - Amit: <Media omitted>
5/15/23, 3:04‚ÄØPM - Amit: <Media omitted>
5/16/23, 1:31‚ÄØPM - Amit: Sir no call aavyo?
5/16/23, 2:44‚ÄØPM - Siddharth: Yup
5/16/23, 7:27‚ÄØPM - Siddharth: We are working on table transformer with DeTr, results are not good currently and we are trying to improve it.
5/16/23, 7:31‚ÄØPM - Siddharth: https://colab.research.google.com/drive/1-eZ5IdR07QKEWkUx8FlQfPl1IhWE5JVL?usp=sharing
5/18/23, 1:36‚ÄØPM - Siddharth: Mail jo IT Admin no for paper presentation
5/18/23, 1:40‚ÄØPM - Amit: Pela Dhaivat ne Cocoden na features mokali de brochure mate
5/18/23, 1:41‚ÄØPM - Amit: Aapne karvu chhe submit?
5/18/23, 2:28‚ÄØPM - Siddharth: Ask Nandan
5/18/23, 2:28‚ÄØPM - Siddharth: Vicharo
5/18/23, 5:08‚ÄØPM - Amit: Divya vali meeting ma karvanu shu chhe?
5/18/23, 6:53‚ÄØPM - Amit: Hdfc and ICICI ni pdf mokale ne
5/18/23, 6:57‚ÄØPM - Siddharth: 20 min please
5/18/23, 6:57‚ÄØPM - Siddharth: Tane kau chhu ne ke save rakho sirrrrr
5/18/23, 8:44‚ÄØPM - Amit: .
5/18/23, 8:45‚ÄØPM - Siddharth: <Media omitted>
5/18/23, 8:45‚ÄØPM - Siddharth: <Media omitted>
5/19/23, 9:52‚ÄØAM - Amit: Pela row merging no code mokali deje
5/19/23, 9:55‚ÄØAM - Siddharth: Need to find
5/19/23, 11:01‚ÄØAM - Amit: Ok
5/19/23, 11:01‚ÄØAM - Amit: Try karje ke 3 pm pela goti le.

Mane thodo time male set karva mate
5/19/23, 11:07‚ÄØAM - Siddharth: https://www.deskera.com/in
5/19/23, 11:08‚ÄØAM - Siddharth: check_cols = ['Post Date']  

    df = df.astype(str) 
    df = df.replace('nan','') 

    for i, s in df.iterrows():  
        try:
            if all(s[check_cols] != ''):
                lvi, last_valid = i, s
                continue
            else:  
                extra_vals = s[s != '']  
                for col in extra_vals.index:
                    last_valid[col] = last_valid[col] + " " + extra_vals[col] 
                df.iloc[lvi, :] = last_valid
        except:
            pass
5/19/23, 3:44‚ÄØPM - Amit: .
5/19/23, 4:07‚ÄØPM - Amit: Ama NaN blank space thi replace thai jay chhe Pan 2 rows merge nathi thati
5/19/23, 4:15‚ÄØPM - Siddharth: https://stackoverflow.com/questions/56568791/how-to-merge-rows-up-based-on-nan-index-value

aa jo
5/19/23, 4:23‚ÄØPM - Amit: Not working
5/19/23, 4:23‚ÄØPM - Siddharth: Thik, jova de
5/19/23, 4:23‚ÄØPM - Siddharth: Meet link mokal
5/19/23, 4:24‚ÄØPM - Amit: https://meet.google.com/sfm-pvdi-ikc
5/19/23, 4:27‚ÄØPM - Siddharth: g = df['Date'].notna().cumsum()

df = df.groupby(g).agg({'Date':'first', 'Comment': ' '.join}).reset_index(drop=True)
5/19/23, 10:05‚ÄØPM - Siddharth: 10 min ma start
5/19/23, 10:07‚ÄØPM - Amit: Ok
5/19/23, 10:14‚ÄØPM - Siddharth: Start?
5/19/23, 10:14‚ÄØPM - Amit: Ok
5/19/23, 10:15‚ÄØPM - Amit: .
5/19/23, 10:20‚ÄØPM - Siddharth: im = cv2.imread("/content/pages/page0.jpeg")
cv2.imwrite('/content/ext_im.jpg', im[495:1526,125:1554])
5/19/23, 10:27‚ÄØPM - Siddharth: !wget https://paddleocr.bj.bcebos.com/whl/layoutparser-0.0.0-py3-none-any.whl
!pip install -U layoutparser-0.0.0-py3-none-any.whl
5/19/23, 10:27‚ÄØPM - Siddharth: !python3 -m pip install paddlepaddle-gpu
!python3 -m pip install paddlepaddle
!pip3 install "paddleocr>=2.6.0.3"
!git clone https://github.com/PaddlePaddle/PaddleDetection.git
5/19/23, 10:27‚ÄØPM - Siddharth: import os
import cv2
from paddleocr import PPStructure,draw_structure_result,save_structure_res

table_engine = PPStructure(show_log=True)

save_folder = './output_sbi'
img_path = '/content/pages/page0.jpeg'
img = cv2.imread(img_path)
result = table_engine(img)
save_structure_res(result, save_folder,os.path.basename(img_path).split('.')[0])
5/19/23, 10:40‚ÄØPM - Siddharth: # im = im.astype("uint8")
filepath = '/content/pages_sbi/page0.jpeg'
img = cv2.imread(filepath,0)
thresh,img_bin = cv2.threshold(img,128,255,cv2.THRESH_BINARY |cv2.THRESH_OTSU)
img_bin = 255-img_bin
# cv2.imwrite('/content/bin_images/test_1.png',img_bin)
plotting = plt.imshow(img_bin,cmap='gray')
plt.show()
5/19/23, 10:41‚ÄØPM - Siddharth: import numpy as np

kernel_len = np.array(img).shape[1]//100# Defining a vertical kernel to detect all vertical lines of image 
ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_len))# Defining a horizontal kernel to detect all horizontal lines of image
hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_len, 1))# A kernel of 2x2
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))

image_1 = cv2.erode(img_bin, ver_kernel, iterations=3)
vertical_lines = cv2.dilate(image_1, ver_kernel, iterations=3)
plotting = plt.imshow(image_1,cmap='gray')
plt.show()
5/19/23, 10:42‚ÄØPM - Siddharth: image_2 = cv2.erode(img_bin, hor_kernel, iterations=3)
horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=3)
plotting = plt.imshow(image_2,cmap='gray')
plt.show()
5/19/23, 10:42‚ÄØPM - Siddharth: contours, hierarchy = cv2.findContours(img_vh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
5/19/23, 10:43‚ÄØPM - Siddharth: img_vh = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0.0)
#Eroding and thesholding the image
img_vh = cv2.erode(~img_vh, kernel, iterations=2)
thresh, img_vh = cv2.threshold(img_vh,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
# cv2.imwrite("/Users/marius/Desktop/img_vh.jpg", img_vh)
bitxor = cv2.bitwise_xor(img,img_vh)
bitnot = cv2.bitwise_not(bitxor)
#Plotting the generated image
plotting = plt.imshow(bitnot,cmap='gray')
plt.show()
5/19/23, 10:43‚ÄØPM - Siddharth: def sort_contours(cnts, method="left-to-right"):
    # initialize the reverse flag and sort index
    reverse = False
    i = 0
    # handle if we need to sort in reverse
    if method == "right-to-left" or method == "bottom-to-top":
        reverse = True
    # handle if we are sorting against the y-coordinate rather than
    # the x-coordinate of the bounding box
    if method == "top-to-bottom" or method == "bottom-to-top":
        i = 1
    # construct the list of bounding boxes and sort them from top to
    # bottom
    boundingBoxes = [cv2.boundingRect(c) for c in cnts]
    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),
    key=lambda b:b[1][i], reverse=reverse))
    # return the list of sorted contours and bounding boxes
    return (cnts, boundingBoxes)

# Sort all the contours by top to bottom.
contours, boundingBoxes = sort_contours(contours, method="top-to-bottom")

#Creating a list of heights for all detected boxes
heights = [boundingBoxes[i][3] for i in range(len(boundingBoxes))]

#Get mean of heights
mean = np.mean(heights)

#Create list box to store all boxes in  
box = []
# Get position (x,y), width and height for every contour and show the contour on image
for c in contours:
    x, y, w, h = cv2.boundingRect(c)
    if (w<1000 and h<500):
        image = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
        box.append([x,y,w,h])
        
plotting = plt.imshow(image,cmap='gray')
plt.show()

#Creating two lists to define row and column in which cell is located
row=[]
column=[]
j=0

#Sorting the boxes to their respective row and column
for i in range(len(box)):    
        
    if(i==0):
        column.append(box[i])
        previous=box[i]    
    
    else:
        if(box[i][1]<=previous[1]+mean/2):
            column.append(box[i])
            previous=box[i]            
            
            if(i==len(box)-1):
                row.append(column)        
            
        else:
            row.append(column)
            column=[]
            previous = box[i]
            column.append(box[i])
            
print(column)
print(row)

#calculating maximum number of cells
countcol = 0
for i in range(len(row)):
    countcol = len(row[i])
    if countcol > countcol:
        countcol = countcol

#Retrieving the center of each column
center = [int(row[i][j][0]+row[i][j][2]/2) for j in range(len(row[i])) if row[0]]

center=np.array(center)
center.sort()
print(center)
#Regarding the distance to the columns center, the boxes are arranged in respective order

finalboxes = []
for i in range(len(row)):
    lis=[]
    for k in range(countcol):
        lis.append([])
    for j in range(len(row[i])):
        diff = abs(center-(row[i][j][0]+row[i][j][2]/4))
        minimum = min(diff)
        indexing = list(diff).index(minimum)
        lis[indexing].append(row[i][j])
    finalboxes.append(lis)


#from every single image-based cell/box the strings are extracted via pytesseract and stored in a list
outer=[]
for i in range(len(finalboxes)):
    for j in range(len(finalboxes[i])):
        inner=''
        if(len(finalboxes[i][j])==0):
            outer.append(' ')
        else:
            for k in range(len(finalboxes[i][j])):
                y,x,w,h = finalboxes[i][j][k][0],finalboxes[i][j][k][1], finalboxes[i][j][k][2],finalboxes[i][j][k][3]
                finalimg = bitnot[x:x+h, y:y+w]
                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))
                border = cv2.copyMakeBorder(finalimg,2,2,2,2, cv2.BORDER_CONSTANT,value=[255,255])
                resizing = cv2.resize(border, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
                dilation = cv2.dilate(resizing, kernel,iterations=1)
                erosion = cv2.erode(dilation, kernel,iterations=2)
                
                out = pytesseract.image_to_string(erosion)
                if(len(out)==0):
                    out = pytesseract.image_to_string(erosion, config='--psm 3')
                inner = inner +" "+ out
            outer.append(inner)

#Creating a dataframe of the generated OCR list
arr = np.array(outer)
dataframe = pd.DataFrame(arr.reshape(len(row), countcol))
print(dataframe)
data = dataframe.style.set_properties(align="left")
data
5/19/23, 10:44‚ÄØPM - Siddharth: import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import csv

try:
    from PIL import Image
except ImportError:
    import Image
import pytesseract

#read your file
file=r'/content/pages_sbi/page0.jpeg'
img = cv2.imread(file,0)
img.shape

#thresholding the image to a binary image
thresh,img_bin = cv2.threshold(img,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)

#inverting the image 
img_bin = 255-img_bin
# cv2.imwrite('/Users/marius/Desktop/cv_inverted.png',img_bin)
#Plotting the image to see the output
plotting = plt.imshow(img_bin,cmap='gray')
plt.show()

# countcol(width) of kernel as 100th of total width
kernel_len = np.array(img).shape[1]//100
# Defining a vertical kernel to detect all vertical lines of image 
ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_len))
# Defining a horizontal kernel to detect all horizontal lines of image
hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_len, 1))
# A kernel of 2x2
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))

#Use vertical kernel to detect and save the vertical lines in a jpg
image_1 = cv2.erode(img_bin, ver_kernel, iterations=3)
vertical_lines = cv2.dilate(image_1, ver_kernel, iterations=3)
# cv2.imwrite("/Users/marius/Desktop/vertical.jpg",vertical_lines)
#Plot the generated image
plotting = plt.imshow(image_1,cmap='gray')
plt.show()

#Use horizontal kernel to detect and save the horizontal lines in a jpg
image_2 = cv2.erode(img_bin, hor_kernel, iterations=3)
horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=3)
# cv2.imwrite("/Users/marius/Desktop/horizontal.jpg",horizontal_lines)
#Plot the generated image
plotting = plt.imshow(image_2,cmap='gray')
plt.show()

# Combine horizontal and vertical lines in a new third image, with both having same weight.
img_vh = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0.0)
#Eroding and thesholding the image
img_vh = cv2.erode(~img_vh, kernel, iterations=2)
thresh, img_vh = cv2.threshold(img_vh,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
# cv2.imwrite("/Users/marius/Desktop/img_vh.jpg", img_vh)
bitxor = cv2.bitwise_xor(img,img_vh)
bitnot = cv2.bitwise_not(bitxor)
#Plotting the generated image
plotting = plt.imshow(bitnot,cmap='gray')
plt.show()

# Detect contours for following box detection
contours, hierarchy = cv2.findContours(img_vh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

def sort_contours(cnts, method="left-to-right"):
    # initialize the reverse flag and sort index
    reverse = False
    i = 0
    # handle if we need to sort in reverse
    if method == "right-to-left" or method == "bottom-to-top":
        reverse = True
    # handle if we are sorting against the y-coordinate rather than
    # the x-coordinate of the bounding box
    if method == "top-to-bottom" or method == "bottom-to-top":
        i = 1
    # construct the list of bounding boxes and sort them from top to
    # bottom
    boundingBoxes = [cv2.boundingRect(c) for c in cnts]
    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),
    key=lambda b:b[1][i], reverse=reverse))
    # return the list of sorted contours and bounding boxes
    return (cnts, boundingBoxes)

# Sort all the contours by top to bottom.
contours, boundingBoxes = sort_contours(contours, method="top-to-bottom")

#Creating a list of heights for all detected boxes
heights = [boundingBoxes[i][3] for i in range(len(boundingBoxes))]

#Get mean of heights
mean = np.mean(heights)

#Create list box to store all boxes in  
box = []
# Get position (x,y), width and height for every contour and show the contour on image
for c in contours:
    x, y, w, h = cv2.boundingRect(c)
    if (w<1000 and h<500):
        image = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
        box.append([x,y,w,h])
        
plotting = plt.imshow(image,cmap='gray')
plt.show()

#Creating two lists to define row and column in which cell is located
row=[]
column=[]
j=0

#Sorting the boxes to their respective row and column
for i in range(len(box)):    
        
    if(i==0):
        column.append(box[i])
        previous=box[i]    
    
    else:
        if(box[i][1]<=previous[1]+mean/2):
            column.append(box[i])
            previous=box[i]            
            
            if(i==len(box)-1):
                row.append(column)        
            
        else:
            row.append(column)
            column=[]
            previous = box[i]
            column.append(box[i])
            
print(column)
print(row)

#calculating maximum number of cells
countcol = 0
for i in range(len(row)):
    countcol = len(row[i])
    if countcol > countcol:
        countcol = countcol

#Retrieving the center of each column
center = [int(row[i][j][0]+row[i][j][2]/2) for j in range(len(row[i])) if row[0]]

center=np.array(center)
center.sort()
print(center)
#Regarding the distance to the columns center, the boxes are arranged in respective order

finalboxes = []
for i in range(len(row)):
    lis=[]
    for k in range(countcol):
        lis.append([])
    for j in range(len(row[i])):
        diff = abs(center-(row[i][j][0]+row[i][j][2]/4))
        minimum = min(diff)
        indexing = list(diff).index(minimum)
        lis[indexing].append(row[i][j])
    finalboxes.append(lis)


#from every single image-based cell/box the strings are extracted via pytesseract and stored in a list
outer=[]
for i in range(len(finalboxes)):
    for j in range(len(finalboxes[i])):
        inner=''
        if(len(finalboxes[i][j])==0):
            outer.append(' ')
        else:
            for k in range(len(finalboxes[i][j])):
                y,x,w,h = finalboxes[i][j][k][0],finalboxes[i][j][k][1], finalboxes[i][j][k][2],finalboxes[i][j][k][3]
                finalimg = bitnot[x:x+h, y:y+w]
                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))
                border = cv2.copyMakeBorder(finalimg,2,2,2,2, cv2.BORDER_CONSTANT,value=[255,255])
                resizing = cv2.resize(border, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
                dilation = cv2.dilate(resizing, kernel,iterations=1)
                erosion = cv2.erode(dilation, kernel,iterations=2)
                
                out = pytesseract.image_to_string(erosion)
                if(len(out)==0):
                    out = pytesseract.image_to_string(erosion, config='--psm 3')
                inner = inner +" "+ out
            outer.append(inner)

#Creating a dataframe of the generated OCR list
arr = np.array(outer)
dataframe = pd.DataFrame(arr.reshape(len(row), countcol))
print(dataframe)
data = dataframe.style.set_properties(align="left")
#Converting it in a excel-file
# data.to_excel("/Users/marius/Desktop/output.xlsx")
5/19/23, 10:45‚ÄØPM - Siddharth: ! apt install tesseract-ocr
! apt install libtesseract-dev
5/19/23, 10:45‚ÄØPM - Siddharth: !pip install pytesseract
5/19/23, 10:50‚ÄØPM - Siddharth: https://towardsdatascience.com/a-table-detection-cell-recognition-and-text-extraction-algorithm-to-convert-tables-to-excel-files-902edcf289ec
5/19/23, 11:07‚ÄØPM - Siddharth: import camelot
import copy
import cv2


def draw_bbox(img, start_point, end_point, ratio=1):
    start_point = tuple(map(lambda x: round(x * ratio), start_point))
    end_point = tuple(map(lambda x: round(x * ratio), end_point))
    cv2.rectangle(img, start_point, end_point, (0, 255, 0), 2)


pdf_path = 'foo.pdf'
tables = camelot.read_pdf(pdf_path, flavor='lattice', backend="poppler")
table = tables[0]

table_x0, table_y0, table_x1, table_y1 = table._bbox
img = table._image[0]

ratio = 300 / 72
new_tmp_img = copy.deepcopy(img)
pdf_height = img.shape[0] / ratio
draw_bbox(new_tmp_img,
          start_point=(table_x0, pdf_height - table_y0),
          end_point=(table_x1, pdf_height - table_y1),
          ratio=ratio)
cv2.imwrite('foo_right.jpg', new_tmp_img)
5/19/23, 11:20‚ÄØPM - Siddharth: !pip install ghostscript
!pip install camelot-py[cv]
!pip install excalibur-py
!apt install ghostscript python3-tk
from ctypes.util import find_library
print(find_library("gs")) #will display libgs.so.9 if installed; will print None if not
!excalibur initdb
5/20/23, 10:17‚ÄØAM - Siddharth: Contact Dhruvil for RPi
5/20/23, 10:37‚ÄØAM - Amit: Ok
5/20/23, 10:37‚ÄØAM - Siddharth: We need it at Jeni's place
5/20/23, 10:38‚ÄØAM - Amit: Eni pase j chhe and free padeli chhe
5/20/23, 10:38‚ÄØAM - Amit: Have mangavanu jov chhu hu
5/20/23, 10:38‚ÄØAM - Siddharth: Ha kar e
5/20/23, 10:39‚ÄØAM - Siddharth: Pchhi Jeni ne to parcel kari deje
5/20/23, 10:39‚ÄØAM - Siddharth: Also, call me once free
5/20/23, 10:39‚ÄØAM - Amit: Ok
5/20/23, 3:52‚ÄØPM - Amit: Not working properly
5/20/23, 3:52‚ÄØPM - Amit: Info cut thay chhe and amuk rows nathi aavti
5/20/23, 3:52‚ÄØPM - Siddharth: üò≠
5/20/23, 3:52‚ÄØPM - Amit: Trying something new
5/20/23, 3:57‚ÄØPM - Amit: What are your thoughts on this?

https://github.com/eihli/image-table-ocr
5/20/23, 3:58‚ÄØPM - Siddharth: Without border ma?
5/20/23, 3:58‚ÄØPM - Amit: I guess aa verticle and horizontal lines thi nathi karto
5/20/23, 3:58‚ÄØPM - Amit: Direct OCR
5/20/23, 3:59‚ÄØPM - Siddharth: Try kar, hu biji method try karu chhu
5/20/23, 4:01‚ÄØPM - Siddharth: Aa try kar tables par
5/20/23, 4:01‚ÄØPM - Siddharth: import cv2
import pytesseract
from pytesseract import Output
import pandas as pd

img = cv2.imread("HZ29h.png")
img = cv2.resize(img, (int(img.shape[1] + (img.shape[1] * .1)),
                       int(img.shape[0] + (img.shape[0] * .25))),
                 interpolation=cv2.INTER_AREA)

img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)

custom_config = r'-l eng --oem 3 --psm 6 -c tessedit_char_whitelist="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-:.$%./@& *"'
d = pytesseract.image_to_data(img_rgb, config=custom_config, output_type=Output.DICT)
df = pd.DataFrame(d)
5/20/23, 4:01‚ÄØPM - Amit: Direct crop kareli image par ne?
5/20/23, 4:01‚ÄØPM - Siddharth: Ha
5/20/23, 4:01‚ÄØPM - Amit: ok
5/20/23, 4:04‚ÄØPM - Amit: Alag j output aave chhe

Vadharani info pan df ma aave che
5/20/23, 4:04‚ÄØPM - Siddharth: Mokal SS
5/20/23, 4:04‚ÄØPM - Amit: <Media omitted>
5/20/23, 4:05‚ÄØPM - Siddharth: Looks good
5/20/23, 4:05‚ÄØPM - Siddharth: Aa OCR chhe bhai
5/20/23, 4:06‚ÄØPM - Siddharth: Try
5/20/23, 4:06‚ÄØPM - Siddharth: import cv2
import pytesseract
from pytesseract import Output
import pandas as pd

img = cv2.imread("HZ29h.png")
img = cv2.resize(img, (int(img.shape[1] + (img.shape[1] * .1)),
                       int(img.shape[0] + (img.shape[0] * .25))),
                 interpolation=cv2.INTER_AREA)

img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)

custom_config = r'-l eng --oem 3 --psm 6 -c tessedit_char_whitelist="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-:.$%./@& *"'
d = pytesseract.image_to_data(img_rgb, config=custom_config, output_type=Output.DICT)
df = pd.DataFrame(d)

# clean up blanks
df1 = df[(df.conf != '-1') & (df.text != ' ') & (df.text != '')]
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

# sort blocks vertically
sorted_blocks = df1.groupby('block_num').first().sort_values('top').index.tolist()
for block in sorted_blocks:
    curr = df1[df1['block_num'] == block]
    sel = curr[curr.text.str.len() > 3]
    # sel = curr
    char_w = (sel.width / sel.text.str.len()).mean()
    prev_par, prev_line, prev_left = 0, 0, 0
    text = ''
    for ix, ln in curr.iterrows():
        # add new line when necessary
        if prev_par != ln['par_num']:
            text += '\n'
            prev_par = ln['par_num']
            prev_line = ln['line_num']
            prev_left = 0
        elif prev_line != ln['line_num']:
            text += '\n'
            prev_line = ln['line_num']
            prev_left = 0

        added = 0  # num of spaces that should be added
        if ln['left'] / char_w > prev_left + 1:
            added = int((ln['left']) / char_w) - prev_left
            text += ' ' * added
        text += ln['text'] + ' '
        prev_left += len(ln['text']) + added + 1
    text += '\n'
    print(text)
5/20/23, 4:07‚ÄØPM - Amit: <Media omitted>
5/20/23, 4:07‚ÄØPM - Siddharth: Data correct?
5/20/23, 4:08‚ÄØPM - Amit: yes bas khali header line nathi
5/20/23, 4:08‚ÄØPM - Amit: Let me try this on sbi
5/20/23, 4:08‚ÄØPM - Siddharth: Thik chhe, kar try
5/20/23, 4:11‚ÄØPM - Amit: <Media omitted>
5/20/23, 4:11‚ÄØPM - Amit: Sbi ok
with headers
5/20/23, 4:11‚ÄØPM - Siddharth: Keep going
5/20/23, 4:11‚ÄØPM - Amit: now icici
5/20/23, 4:16‚ÄØPM - Amit: <Media omitted>
5/20/23, 4:20‚ÄØPM - Amit: Trying all other formates
5/20/23, 4:32‚ÄØPM - Amit: All working great except Paytm
5/20/23, 4:32‚ÄØPM - Amit: <Media omitted>
5/20/23, 4:37‚ÄØPM - Siddharth: Anyway, this method will take lot of time loading data in csv
5/20/23, 4:37‚ÄØPM - Amit: Aama output text chhe to ene csv ma pan convert karvu padshe ne
5/20/23, 4:38‚ÄØPM - Siddharth: Ha e j
5/20/23, 4:38‚ÄØPM - Amit: Baki perfect aavi jatu hatu badhu
5/20/23, 5:17‚ÄØPM - Siddharth: output_type='data.frame'
5/20/23, 5:22‚ÄØPM - Siddharth: import io
import pandas as pd

df = pd.read_csv(io.StringIO(text), sep='\s+', skiprows=list(range(16))+[17])
5/20/23, 5:22‚ÄØPM - Amit: ParserError: Error tokenizing data. C error: Expected 5 fields in line 21, saw 6
5/20/23, 5:23‚ÄØPM - Siddharth: , on_bad_lines='skip'
5/20/23, 5:24‚ÄØPM - Amit: <Media omitted>
5/20/23, 5:25‚ÄØPM - Siddharth: splitted = text.split("\n")

columns = splitted[16].split()
data = map(str.split,splitted[18:-1])

pd.DataFrame(data, columns = columns).astype(float)
5/20/23, 5:27‚ÄØPM - Amit: ValueError: 5 columns passed, passed data had 7 columns
5/20/23, 5:27‚ÄØPM - Siddharth: df = pd.read_csv(results_file, delimiter='\t')
5/20/23, 5:28‚ÄØPM - Amit: ValueError: Specified \n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.
5/20/23, 5:32‚ÄØPM - Siddharth: # Split the text by lines
lines = data.strip().split('\n')

# Remove leading and trailing spaces from each line
lines = [line.strip() for line in lines]

# Split the header line to extract column names
header = lines[0].split()

# Split the data lines into columns
rows = [line.split() for line in lines[1:]]

# Create a dataframe
df = pd.DataFrame(rows, columns=header)

# Print the dataframe
print(df)
5/20/23, 5:32‚ÄØPM - Amit: ValueError: 9 columns passed, passed data had 7 columns
5/20/23, 5:36‚ÄØPM - Amit: <Media omitted>
5/20/23, 5:37‚ÄØPM - Amit: Post Date  Value Date            Details              Chq.No             Debit         Credit               Balance 
TE                        A 
07/09/15    07/09/15     DEBIT TRANSFER                           2000.000.00                         2000.000.00Dr 
                         TFR TO  10781632742 
30/09/15    30/09/15     PART  PERIOD INTEREST                       12.822.00                        20.12.822.00Dr 
05/10/15    05/10/15     RT  9.750 TO 9.350% 
07/10/15    07/10/15     0.S. DEPOSIT TRANSFE                                       19300.00           19.93522.00Dr 
09/10/15    09/10/15     DEPOSIT  TRANSFER                                          19300.00           19.74222.00Dr 
                         TRANSFER   FROM 
                         TRF TO LOAN  A/C 
                         TFR FROM  10781632742 
31/10/15    31/10/15     INTEREST                                    15.835.00                         19.90057.00Dr 
18/11/15    18/11/15     O.S. DEPOSIT TRANSFE                                       19300.00           1970.757.00Dr 
30/11/15    30/11/15     INTEREST                                    15.229.00                         19.85.986.00Dr 
19/12/15    19/12/15     O.S. DEPOSIT TRANSFE                                       19.300.00          19.66686.00Dr 
31/12/15    31/12/15     INTEREST                                    15.707.00                         19.82.393.00Dr 
30/01/16    30/01/16     O.S. DEPOSIT TRANSFE                                       19300.00           19.63.093.00Dr 
31/01/16    31/01/16     INTEREST                                    15.629.00                         19.78.722.00Dr 
29/02/16    29/02/16     INTEREST                                    14.700.00                         19.93.422.00Dr 
10/03/16    10/03/16     CASH  REPAYMENT                                            10.000.00          19.83.422.00Dr 
14/03/16    14/03/16     CASH  REPAYMENT                                            30.000.00          19.53422.00Dr 
31/03/16    31/03/16     INTEREST                                    15.635.00                         19.69057.00Dr 
30/04/16    30/04/16     INTEREST                                    15.132.00                         19.84189.00Dr 
04/05/16    04/05/16     O.S. DEPOSIT TRANSFE                                       19300.00           19.64889.00Dr 
31/05/16    31/05/16     INTEREST                                    15.618.00                         19.80.507.00Dr 
30/06/16    30/06/16     INTEREST                                    15.220.00                         19.95.727.00Dr 
04/07/16    04/07/16     CASH  REPAYMENT                                            40000.00           19.55.727.00Dr 
                         BY CASH 
15/07/16    15/07/16     CASH  REPAYMENT                                            30.000.00          19.25.727.00Dr 
                         BY CASH 
31/07/16    31/07/16     INTEREST                                    15.431.00                         19.41158.00Dr 
31/08/16    31/08/16     INTEREST                                    15.415.00                         19.56573.00Dr 
                         CARRIED  FORWARD:                                                            40 GR G72 0NNr
5/20/23, 5:38‚ÄØPM - Siddharth: lines = data.strip().split('\n')

# Remove leading and trailing spaces from each line
lines = [line.strip() for line in lines]

# Split the header line to extract column names
header = lines[0].split()

# Split the data lines into columns
rows = [line.split()[:len(header)] for line in lines[1:]]

# Create a dataframe
df = pd.DataFrame(rows, columns=header)

# Print the dataframe
print(df)
Now, the code will create a dataframe without any errors.
5/20/23, 5:40‚ÄØPM - Amit: <Media omitted>
5/20/23, 5:40‚ÄØPM - Amit: <Media omitted>
5/20/23, 5:43‚ÄØPM - Siddharth: import cv2
import pytesseract

pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# Load image, grayscale, and Otsu's threshold
image = cv2.imread('1.png')
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

# Remove horizontal lines
horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50,1))
detect_horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)
cnts = cv2.findContours(detect_horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
for c in cnts:
    cv2.drawContours(thresh, [c], -1, (0,0,0), 2)

# Remove vertical lines
vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,15))
detect_vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=2)
cnts = cv2.findContours(detect_vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
for c in cnts:
    cv2.drawContours(thresh, [c], -1, (0,0,0), 3)

# Dilate to connect text and remove dots
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10,1))
dilate = cv2.dilate(thresh, kernel, iterations=2)
cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
for c in cnts:
    area = cv2.contourArea(c)
    if area < 500:
        cv2.drawContours(dilate, [c], -1, (0,0,0), -1)

# Bitwise-and to reconstruct image
result = cv2.bitwise_and(image, image, mask=dilate)
result[dilate==0] = (255,255,255)

# OCR
data = pytesseract.image_to_string(result, lang='eng',config='--psm 6')
print(data)

cv2.imshow('thresh', thresh)
cv2.imshow('result', result)
cv2.imshow('dilate', dilate)
cv2.waitKey()
5/20/23, 5:45‚ÄØPM - Amit: <Media omitted>
5/20/23, 5:56‚ÄØPM - Siddharth: .
5/20/23, 6:02‚ÄØPM - Siddharth: # Split the text by lines
lines = data.strip().split('\n')

# Remove leading and trailing spaces from each line
lines = [line.strip() for line in lines]

# Define regular expressions for extracting data
date_pattern = r'\d{2}/\d{2}/\d{2}'
amount_pattern = r'\d+\.\d+\.\d+\.\d+'

# Process each line and extract the data
rows = []
for line in lines:
    if re.match(date_pattern, line):
        # Line contains a date, extract the columns
        row = re.split(r'\s{2,}', line)
        rows.append(row)
    elif re.search(amount_pattern, line):
        # Line contains an amount, append it to the previous row
        rows[-1][-1] += ' ' + line

# Create a dataframe
df = pd.DataFrame(rows)

# Remove any leading/trailing spaces from column values
df = df.applymap(str.strip)

# Print the dataframe
print(df)
5/20/23, 6:04‚ÄØPM - Siddharth: output = pytesseract.image_to_string(img_rgb)
with open('test.csv','w') as f: 
    f.write(output)
5/20/23, 6:07‚ÄØPM - Amit: <Media omitted>
5/20/23, 6:10‚ÄØPM - Siddharth: df = pd.read_csv('test.csv',header=[0,1,2,3],sep=r'(\)\(|\|)',engine='python')
5/20/23, 6:13‚ÄØPM - Siddharth: .
5/20/23, 6:28‚ÄØPM - Siddharth: !pip install pdf2image
!apt-get install poppler-utils
5/20/23, 6:29‚ÄØPM - Amit: https://colab.research.google.com/drive/1JHCmca4a0bwhMR_TIWzh0gr1hG5l6Mjz?usp=sharing
5/21/23, 5:12‚ÄØPM - Amit: Pelu table nu kyare karvu chhe?
5/21/23, 5:31‚ÄØPM - Siddharth: Ratre
5/21/23, 7:59‚ÄØPM - Siddharth: For paper, we need to re-run algos and get real graphs
5/21/23, 7:59‚ÄØPM - Amit: Ha bhai
5/21/23, 7:59‚ÄØPM - Siddharth: Find good dataset if possible
5/21/23, 8:31‚ÄØPM - Amit: Quillbot ma pdpu id thi login karyu to pan access nathi
5/21/23, 8:32‚ÄØPM - Siddharth: Ask Nandan
5/21/23, 8:38‚ÄØPM - Siddharth: I found new point for Vinay Sir's paper
5/21/23, 8:38‚ÄØPM - Amit: What?
5/21/23, 8:38‚ÄØPM - Siddharth: Explainable AI
5/21/23, 8:38‚ÄØPM - Siddharth: Algo name: LIME
5/21/23, 8:39‚ÄØPM - Siddharth: Reading paper currently, will explain tomorrow
5/21/23, 8:39‚ÄØPM - Amit: ok
5/21/23, 9:01‚ÄØPM - Siddharth: Mane table-transformer send kar code, savare thodu test karish
5/21/23, 9:03‚ÄØPM - Amit: https://colab.research.google.com/drive/1-awJD9l4xFpGNpqbYyPgoujnN8M7p30V?usp=sharing
5/22/23, 1:02‚ÄØPM - Amit: Karie start?
5/22/23, 1:02‚ÄØPM - Siddharth: I need to go for haircut in half an hour
5/22/23, 1:03‚ÄØPM - Amit: No problem
5/22/23, 1:03‚ÄØPM - Siddharth: Just read this

https://github.com/Belval/pdf2image/issues/261
5/22/23, 1:20‚ÄØPM - Siddharth: Test this and give me results ASAP
5/22/23, 1:20‚ÄØPM - Siddharth: If you get table, get it working with camelot
5/22/23, 1:20‚ÄØPM - Amit: Ok
5/22/23, 1:23‚ÄØPM - Amit: Hu 2:15 e start karu chhu
5/22/23, 1:23‚ÄØPM - Amit: Atayre campus jav chhu yogesh sir e bolavyo chhe
5/22/23, 1:23‚ÄØPM - Siddharth: Okayy
5/22/23, 3:06‚ÄØPM - Siddharth: .
5/22/23, 3:11‚ÄØPM - Amit: ok I am in
5/22/23, 3:13‚ÄØPM - Siddharth: !pip install -q git+https://github.com/huggingface/transformers.git
!pip install -q timm

!pip install pdf2image
!apt-get install poppler-utils

! pip install pypdf

!pip install tabula-py
5/22/23, 3:14‚ÄØPM - Siddharth: from pdf2image import convert_from_path

images = convert_from_path('/content/Sample Statement Format Bancslink.pdf')
5/22/23, 3:14‚ÄØPM - Siddharth: !rm -rf pages
5/22/23, 3:15‚ÄØPM - Siddharth: !mkdir pages

for i in range(len(images)):
  images[i].save('/content/pages/page'+str(i)+'.jpeg')
5/22/23, 3:16‚ÄØPM - Siddharth: from huggingface_hub import hf_hub_download
from PIL import Image

file_path = '/content/pages/page0.jpeg'
image = Image.open(file_path).convert("RGB")
width, height = image.size
image.resize((int(width*0.5), int(height*0.5)))

from transformers import DetrImageProcessor

feature_extractor = DetrImageProcessor()
encoding = feature_extractor(image, return_tensors="pt")
encoding.keys()

from transformers import TableTransformerForObjectDetection

model = TableTransformerForObjectDetection.from_pretrained("microsoft/table-transformer-detection")

import torch

with torch.no_grad():
  outputs = model(**encoding)

  import matplotlib.pyplot as plt

# colors for visualization
COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],
          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]

width, height = image.size
results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=[(height, width)])[0]
5/22/23, 3:17‚ÄØPM - Siddharth: x_1 = int(results['boxes'][0][0])
x_2 = int(results['boxes'][0][2])
y_1 = int(results['boxes'][0][1])
y_2 = int(results['boxes'][0][3])
5/22/23, 3:18‚ÄØPM - Siddharth: import cv2
im = cv2.imread('/content/pages/page0.jpeg')
# cv2.imwrite('/content/image.jpeg', im[y_1:y_2, x_1:x_2])
height, width, channels = im.shape
5/22/23, 3:19‚ÄØPM - Siddharth: x_1  = x_1/width*pdf_width
y_1  = y_1/width*pdf_width
x_2  = x_2/width*pdf_width
y_2  = y_2/width*pdf_width
5/22/23, 3:20‚ÄØPM - Siddharth: from pypdf import PdfReader

reader = PdfReader('/content/Sample Statement Format Bancslink.pdf')
box = reader.pages[0].mediabox

pdf_width = box.width
pdf_height = box.height
5/22/23, 3:20‚ÄØPM - Siddharth: import tabula
df = tabula.read_pdf('/content/Sample Statement Format Bancslink.pdf', area=(y_1, x_1, y_2, x_2))
5/22/23, 3:29‚ÄØPM - Amit: Free tha tyare keje.
Mare tane database vala no demo aapvo chhe
5/22/23, 3:29‚ÄØPM - Amit: alag thi meet karishu
5/22/23, 3:30‚ÄØPM - Siddharth: üëç
5/23/23, 10:52‚ÄØAM - Amit: Reminder nakhi dav?
5/23/23, 10:52‚ÄØAM - Amit: Meeting nu
5/23/23, 10:52‚ÄØAM - Siddharth: Haaa
5/23/23, 10:55‚ÄØAM - Siddharth: Colab open rakhje
5/23/23, 10:55‚ÄØAM - Siddharth: Results sathe
5/23/23, 10:56‚ÄØAM - Amit: Ha
5/23/23, 10:56‚ÄØAM - Siddharth: Join kar, everyone in
5/23/23, 10:57‚ÄØAM - Amit: karu chhu
5/23/23, 11:12‚ÄØAM - Siddharth: Net issue
5/23/23, 11:12‚ÄØAM - Siddharth: Tell them to check whatsapp
5/23/23, 11:12‚ÄØAM - Amit: taro avaj aave j chhe
5/23/23, 11:19‚ÄØAM - Siddharth: 5-6 second ma 100 page thodu difficult to chhe pan try karishu
5/23/23, 11:19‚ÄØAM - Siddharth: 10 second ma thai jaay to pan fast kevay khub
5/23/23, 11:20‚ÄØAM - Amit: ha hu e j vicharto hato
5/23/23, 11:20‚ÄØAM - Amit: And aapno demo aa meeting pachi kari devo chhe ne
5/23/23, 11:20‚ÄØAM - Amit: database valo
5/23/23, 11:20‚ÄØAM - Siddharth: Haa
5/23/23, 11:20‚ÄØAM - Amit: ok
5/23/23, 11:20‚ÄØAM - Siddharth: Pan biji meet link ho
5/23/23, 11:20‚ÄØAM - Siddharth: Also, Ask Nandan to join that
5/23/23, 11:20‚ÄØAM - Amit: ha
5/23/23, 11:20‚ÄØAM - Amit: ok
5/23/23, 11:26‚ÄØAM - Siddharth: https://stackoverflow.com/questions/59837249/multiprocessing-python-3
5/23/23, 11:41‚ÄØAM - Amit: aapne meeting kari laie?
5/23/23, 11:42‚ÄØAM - Siddharth: Ha
5/23/23, 11:43‚ÄØAM - Amit: https://meet.google.com/drv-nxiy-qow
5/23/23, 3:04‚ÄØPM - Siddharth: Update?
5/23/23, 6:28‚ÄØPM - Amit: For loop thai gai.
Have df concate karu chhu
5/23/23, 6:31‚ÄØPM - Siddharth: Okay
5/23/23, 7:11‚ÄØPM - Amit: <Media omitted>
5/23/23, 7:12‚ÄØPM - Siddharth: I will check
5/23/23, 7:30‚ÄØPM - Amit: Tabula ni jagya par camelot use karie to points pdf ni baar vai jay chhe
5/23/23, 7:30‚ÄØPM - Amit: Error: ZeroDivisionError: float division by zero
5/23/23, 7:42‚ÄØPM - Siddharth: Flavour change kar
5/23/23, 7:42‚ÄØPM - Siddharth: Solve Thai jashe
5/23/23, 7:42‚ÄØPM - Amit: Stream chhe atyre
5/23/23, 7:43‚ÄØPM - Amit: Biko Lattice try karine jov
5/23/23, 7:43‚ÄØPM - Amit: Bijo*
5/23/23, 8:29‚ÄØPM - Siddharth: Colab mokal, taro code issue walo chhe
5/23/23, 8:29‚ÄØPM - Amit: Shu issue aave chhe
5/23/23, 8:29‚ÄØPM - Amit: ?
5/23/23, 8:29‚ÄØPM - Siddharth: Mokal code, first page j khotu aave chhe
5/23/23, 8:30‚ÄØPM - Amit: Colab SSB ma j chhe
5/23/23, 8:30‚ÄØPM - Siddharth: Nathi login, download kari mokal
5/23/23, 8:30‚ÄØPM - Amit: Colab Credentials:
Email: ssbidigital703@gmail.com
Password: sharifulhansh
5/23/23, 8:30‚ÄØPM - Siddharth: Are mokal ne
5/23/23, 8:30‚ÄØPM - Siddharth: Khub kantalo aavyo chhe
5/23/23, 8:33‚ÄØPM - Amit: <Media omitted>
5/23/23, 8:33‚ÄØPM - Amit: You deleted this message
5/23/23, 8:42‚ÄØPM - Siddharth: Nai aavto SBI ma jawab, check kar
5/23/23, 8:42‚ÄØPM - Amit: SBI ma mare khali headers nathi aavta
5/23/23, 8:42‚ÄØPM - Amit: baki bdhu ready aave chhe
5/23/23, 8:43‚ÄØPM - Amit: khali last page mathi table extract nathi thatu
5/23/23, 8:43‚ÄØPM - Siddharth: Mare kai nai aavtu
5/23/23, 8:43‚ÄØPM - Amit: wait mokalu ans
5/23/23, 8:44‚ÄØPM - Amit: <Media omitted>
5/23/23, 8:44‚ÄØPM - Amit: <Media omitted>
5/23/23, 8:44‚ÄØPM - Amit: <Media omitted>
5/23/23, 8:44‚ÄØPM - Amit: <Media omitted>
5/23/23, 8:44‚ÄØPM - Amit: <Media omitted>
5/23/23, 8:44‚ÄØPM - Amit: <Media omitted>
5/23/23, 8:44‚ÄØPM - Amit: <Media omitted>
5/23/23, 8:44‚ÄØPM - Amit: darek page ni alag file chhe
5/23/23, 8:47‚ÄØPM - Siddharth: To aama shu issue chhe?
5/23/23, 8:47‚ÄØPM - Amit: header nathi aavata and last page mathi table nathi aavtu
5/23/23, 8:52‚ÄØPM - Amit: Bro maza no hoy to muki de ladi laishu
5/23/23, 8:52‚ÄØPM - Siddharth: Haa, muki didhu
5/23/23, 8:52‚ÄØPM - Amit: Good
5/23/23, 8:52‚ÄØPM - Amit: Have cocoden no pan no karto
5/23/23, 8:52‚ÄØPM - Amit: sui ja
5/23/23, 8:52‚ÄØPM - Siddharth: Ha
5/23/23, 8:53‚ÄØPM - Amit: Kale hu and nandan session nu karvana chie etle ene evening ma free rakhje.
Koi navo task assign ni karto
5/23/23, 10:20‚ÄØPM - Amit: Taro pelo column abd row valo approach hato ne e colab mokal to
5/23/23, 10:20‚ÄØPM - Siddharth: Morning
5/23/23, 10:30‚ÄØPM - Siddharth: <Media omitted>
5/23/23, 10:30‚ÄØPM - Amit: Colab ma updated chhe changes?
5/23/23, 10:31‚ÄØPM - Amit: mari pase chhe access aa colab no etle
5/23/23, 10:31‚ÄØPM - Siddharth: Haal j download kari aa file
5/23/23, 10:31‚ÄØPM - Siddharth: So latest chhe
5/23/23, 10:31‚ÄØPM - Amit: ok
5/23/23, 10:41‚ÄØPM - Siddharth: We should contact management
5/23/23, 10:41‚ÄØPM - Amit: Das sir sathe karie meeting
5/23/23, 10:41‚ÄØPM - Siddharth: Game tetlu kaam karo koi credits j nai
5/23/23, 10:41‚ÄØPM - Amit: online chie ne etle badhane em ke kam nathi karta
5/23/23, 10:42‚ÄØPM - Siddharth: Kar Das sir ne mail and mane CC ma muk, Nandan ne pan 

And mail ma lakh ke sir khali tamari sathe vaat karvi chhe
5/23/23, 10:42‚ÄØPM - Amit: kale savare mokalie
5/23/23, 10:42‚ÄØPM - Siddharth: Ha mokal
5/23/23, 10:42‚ÄØPM - Amit: atyare mood already kharab chhe
5/23/23, 10:57‚ÄØPM - Amit: aaj mokali dav ne
5/23/23, 10:57‚ÄØPM - Amit: ?
5/23/23, 10:57‚ÄØPM - Siddharth: Haa
5/23/23, 10:58‚ÄØPM - Amit: ok
5/23/23, 11:00‚ÄØPM - Amit: aa code aapne dekhadelo chhe?
5/23/23, 11:00‚ÄØPM - Siddharth: Haa
5/23/23, 11:00‚ÄØPM - Amit: ok
5/23/23, 11:01‚ÄØPM - Siddharth: Evu hoy to tesseract walo mokli de e
5/23/23, 11:01‚ÄØPM - Siddharth: string walo
5/23/23, 11:01‚ÄØPM - Amit: ha e mokali dav
5/24/23, 12:27‚ÄØPM - Siddharth: Kal raat ni meeting ni badhi vaat karje
5/24/23, 12:27‚ÄØPM - Amit: ha
5/24/23, 1:40‚ÄØPM - Amit: To detect variable type tables in bank statement following approach should be followed:
1.	Convert PDF pages to images
2.	Capture table boundaries from images of each page
3.	Convert image coordinates to pdf coordinates
4.	Feed new coordinates to tabula/Camelot
5.	Cleaning of final data frame
5/24/23, 1:41‚ÄØPM - Amit: 1.	To detect table from image, we use some kind of deep neural network like Table Transformer by Microsoft. These models are trained on really big datasets and hence they are best possible solution to detect table and training in-house model can never match performance of these pre-trained models but dataset for training does not include all type of tables like structure of Paytm bank statement table and hence they can not be detected properly which results in uneven boundaries which becomes reason of data loss.
5/24/23, 1:41‚ÄØPM - Amit: 2.	As all the detected tables are of different kind, single library like tabula or Camelot can not give good results for all of them and boundary conditions needs to be defined but as there is no user input system cannot identify those conditions.
5/24/23, 1:41‚ÄØPM - Amit: 3.	Once we get data frame from table, as tables are different in format, pattern of error cannot be same and hence simple cleaning does not work and here too we need name of bank to write cleaning conditions which increase complexity.
5/24/23, 1:41‚ÄØPM - Amit: 4.	As bank statement is sensitive document, the data we get from model should be 100% correct. And if the conditions are general there is possibly of errors which may result in transaction wrongly flagged as fraud
5/24/23, 1:44‚ÄØPM - Siddharth: To detect variable-type tables in bank statements following approach should be followed:
1.	Convert PDF pages to images
2.	Capture table boundaries from images of each page
3.	Convert image coordinates to pdf coordinates
4.	Feed new coordinates to tabula/Camelot
5.	Cleaning of the final data frame
5/24/23, 1:45‚ÄØPM - Siddharth: 1.	To detect a table from the image, we use some kind of deep neural network like Table Transformer by Microsoft. These models are trained on really big datasets and hence they are the best possible solution to detect tables training in-house model can never match the performance of these pre-trained models but the dataset for training does not include all types of tables like the structure of Paytm bank statement table and hence they can not be detected properly which results in uneven boundaries which become reason of data loss.
5/24/23, 1:45‚ÄØPM - Siddharth: 2.	As all the detected tables are of different kind, a single library like tabula or Camelot can not give good results for all of them and boundary conditions needs to be defined but as there is no user input system cannot identify those conditions.
5/24/23, 1:46‚ÄØPM - Siddharth: 3.	Once we get the data frame from the table, as tables are different in format, a pattern of error cannot be the same and hence simple cleaning does not work here too we need the name of a bank to write cleaning conditions which increases complexity.
5/24/23, 1:46‚ÄØPM - Siddharth: 4.	As the bank statement is a sensitive document, the data we get from the model should be 100% correct. And if the conditions are general there is possible of errors that may result in transaction wrongly flagged as fraud
5/24/23, 1:57‚ÄØPM - Amit: As this problem require 100% accuracy and deep learning models cannot promise the same, we suggest to develop conventional script which works different from bank to bank. As even general approach requires information about banks then we see no benefit of using complex method for task which can be done with better accuracy and at fraction of computational resources while using conventional methods.
5/24/23, 1:57‚ÄØPM - Amit: The methodology we suggest is as follows:
1.	User input of bank name
2.	Script is written with conditions such that it works perfectly for specific bank
3.	Cleaning script and as bank name is defined, we can easily write cleaning script for specific pattern of errors.
4.	 You get results
As this method is conventional, it may require us to write more code for different banks. But as the code is written by testing all bank statements there is almost zero chance of error and as it does not use any model, system will be very fast.
5/24/23, 1:58‚ÄØPM - Siddharth: As this problem requires 100% accuracy and deep learning models cannot promise the same, we suggest developing a conventional script that works differently from bank to bank. As even the general approach requires information about banks then we see no benefit in using complex methods for a task that can be done with better accuracy and at a fraction of computational resources while using conventional methods.
5/24/23, 1:58‚ÄØPM - Siddharth: The methodology we suggest is as follows:
1.	User input of bank name
2.	Script is written with conditions such that it works perfectly for a specific bank
3.	Cleaning script as bank name is defined, we can easily write cleaning script for a specific pattern of errors.
4.	 You get results
As this method is conventional, it may require us to write more code for different banks. But as the code is written by testing all bank statements there is almost zero chance of error and as it does not use any model, the system will be very fast.
5/24/23, 4:05‚ÄØPM - Amit: ‚Ä¢	Fraud prevention in healthcare ‚Äì AI/ML models can analyze healthcare data to detect fraudulent activities, such as false insurance claims or improper billing, helping government healthcare programs & agencies prevent financial losses

‚Ä¢	Emergency healthcare management ‚Äì create an emergency healthcare management by predicting disease outbreak, analyze patient data to prioritize treatments & optimizing resource allocation during public health crisis or natural disaster 

‚Ä¢	Public health monitoring ‚Äì AI/ML models can analyze health data, Including Electronic health records & disease surveillance systems, to detect disease outbreaks, monitor population health trends & provide early warning system for public health emergencies
5/24/23, 4:05‚ÄØPM - Amit: these 3 platforms is what health ministry is looking for , Central Dept . So majority of the flows are in place but refining might need some more time
5/24/23, 4:05‚ÄØPM - Amit: Sent by saptarshi sir for health platform
5/24/23, 4:06‚ÄØPM - Siddharth: Kyare?
5/24/23, 4:06‚ÄØPM - Amit: Just now
5/24/23, 4:06‚ÄØPM - Siddharth: Cool
5/24/23, 4:06‚ÄØPM - Siddharth: We should shift to this product ASAP
5/24/23, 4:07‚ÄØPM - Siddharth: And bau j mast banavishu aa
5/24/23, 4:07‚ÄØPM - Amit: Ha 
Pan ek condition rakhishu ke direct saptarshi sir ne j update aapishu
5/24/23, 4:07‚ÄØPM - Amit: Ok?
5/24/23, 4:07‚ÄØPM - Siddharth: Haa
5/24/23, 9:57‚ÄØPM - Siddharth: We worked on 3 things today: We created document for our approach to new problem, we worked on arranging data we got from new approach to dataframes and we also checked documentation for multiprocessing.
5/25/23, 10:35‚ÄØAM - Amit: Aje ssb ma shu karvanu chhe?
5/25/23, 10:35‚ÄØAM - Siddharth: E j vicharu chhu
5/25/23, 10:36‚ÄØAM - Siddharth: Koi idea aave to keje
5/25/23, 10:36‚ÄØAM - Amit: Ha
5/25/23, 10:36‚ÄØAM - Amit: Aapne aapno approach start akri devo chhe?
5/25/23, 10:36‚ÄØAM - Siddharth: Sir e haa padya pela?
5/25/23, 10:36‚ÄØAM - Siddharth: I mean, try kari shakay
5/25/23, 10:37‚ÄØAM - Amit: Most of code juna mathi levano chhe to organize kari daie
5/25/23, 10:37‚ÄØAM - Siddharth: Ha to bapore besiye
5/25/23, 10:37‚ÄØAM - Amit: Ok
No problem.
5/25/23, 2:14‚ÄØPM - Siddharth: SAIGE par kaam karie?
5/25/23, 2:41‚ÄØPM - Siddharth: Haal
5/25/23, 2:41‚ÄØPM - Siddharth: Link mokal
5/25/23, 2:41‚ÄØPM - Amit: Mokalu 5 min ma
5/25/23, 2:56‚ÄØPM - Amit: https://meet.google.com/yfu-thqd-vum
5/25/23, 3:02‚ÄØPM - Siddharth: <Media omitted>
5/25/23, 3:17‚ÄØPM - Siddharth: pip install pdfplumber
5/25/23, 3:17‚ÄØPM - Siddharth: import pdfplumber

with pdfplumber.open("path/to/file.pdf") as pdf:
    first_page = pdf.pages[0]
    print(first_page.chars[0])
5/25/23, 3:18‚ÄØPM - Amit: {'matrix': (1, 0, 0, 1, 47.5, 781.0), 'fontname': 'Helvetica-Bold', 'adv': 7.337000000000001, 'upright': True, 'x0': 47.5, 'y0': 778.723, 'x1': 54.837, 'y1': 789.723, 'width': 7.337000000000003, 'height': 11.0, 'size': 11.0, 'object_type': 'char', 'page_number': 1, 'text': 'S', 'stroking_color': 0, 'non_stroking_color': (0, 0, 0), 'top': 52.277000000000044, 'bottom': 63.277000000000044, 'doctop': 52.277000000000044}
5/25/23, 3:19‚ÄØPM - Siddharth: import pdfplumber
pdf = pdfplumber.open("/Users/chueckingmok/Desktop/selenium/Shell Omala 68.pdf")
page = pdf.pages[1]
table=page.extract_table()

import pandas as pd
df = pd.DataFrame(table[1:], columns=table[0])
df
5/25/23, 3:21‚ÄØPM - Siddharth: import pandas as pd
import pdfplumber 
pdf = pdfplumber.open("GSAP_msds_01259319.pdf")
p1 = pdf.pages[1]
table = p1.extract_table(table_settings={"vertical_strategy": "lines", 
                                         "horizontal_strategy": "text", 
                                         "snap_tolerance": 4,})
df = pd.DataFrame(table[1:], columns=table[0])
df
5/25/23, 3:25‚ÄØPM - Siddharth: for i, s in df.iterrows():  
        try:
            if all(s[check_cols] != ''):
                lvi, last_valid = i, s
                continue
            else:  
                extra_vals = s[s != '']  
                for col in extra_vals.index:
                    last_valid[col] = last_valid[col] + " " + extra_vals[col] 
                df.iloc[lvi, :] = last_valid
        except:
            pass
5/25/23, 3:30‚ÄØPM - Siddharth: df=df.replace('\n',',',regex=True)
5/25/23, 3:32‚ÄØPM - Siddharth: import pdfplumber
import csv

with pdfplumber.open('target.pdf') as pdf, \
     open("pdf_text_pgs.csv", "w", newline="", encoding="utf-8") as f_output:

    csv_output = csv.writer(f_output)
    csv_output.writerow(['text'])

    text = []
    
    for page in pdf.pages:
        extracted_text = page.extract_text()
        
        if extracted_text:  # skip empty pages or pages with images
            text.append(extracted_text)
        
    csv_output.writerow([' '.join(text)])
5/25/23, 3:47‚ÄØPM - Siddharth: pdf = pdfplumber.open("../pdfs/background-checks.pdf")
p0 = pdf.pages[0]
im = p0.to_image()
im.reset().debug_tablefinder()
5/25/23, 4:19‚ÄØPM - Amit: <Media omitted>
5/25/23, 4:19‚ÄØPM - Amit: <Media omitted>
5/25/23, 4:35‚ÄØPM - Siddharth: <Media omitted>
5/25/23, 8:54‚ÄØPM - Amit: Layering and number of parameters
5/25/23, 8:54‚ÄØPM - Amit: Msg from yogesh sir
5/25/23, 8:54‚ÄØPM - Amit: üòÇ
5/25/23, 9:01‚ÄØPM - Siddharth: ü§¶‚Äç‚ôÇÔ∏è
5/25/23, 9:46‚ÄØPM - Siddharth: Respected Sir,

We started testing new library for same purpose today. It is 'pdfplumber', we are going through docs as well as testing code.

Thanks
5/25/23, 9:48‚ÄØPM - Amit: Havethi aapne sunday pan kaam karie ne e pan mail mokalishu.
Etle emne khabar pade ke aapne holiday par pan work kari rahiya chie
5/26/23, 9:35‚ÄØPM - Siddharth: Respected Sir,

We are working on data cleaning on our previous approach.

Thanks
5/26/23, 11:35‚ÄØPM - Amit: <Media omitted>
5/27/23, 9:12‚ÄØAM - Amit: Try karyu?
5/27/23, 9:12‚ÄØAM - Siddharth: Have karish
5/27/23, 9:12‚ÄØAM - Amit: Ok
5/27/23, 9:12‚ÄØAM - Siddharth: Kale match hati ü•πüëâüëà
5/27/23, 9:12‚ÄØAM - Amit: Thodak changes ni jaroir chhe
5/27/23, 9:13‚ÄØAM - Amit: In terms of accuracy
5/27/23, 9:13‚ÄØAM - Amit: I am on it
5/27/23, 9:13‚ÄØAM - Siddharth: Cool, send me final version
5/27/23, 9:13‚ÄØAM - Amit: Ema thodi vaar lagshe
5/27/23, 9:13‚ÄØAM - Siddharth: Ha vandho nai
5/27/23, 9:13‚ÄØAM - Amit: Aa version par tamen pi nu kam start kari dejo
5/27/23, 9:14‚ÄØAM - Amit: Because input and output to same j hahse etle
5/27/23, 9:14‚ÄØAM - Siddharth: Ha, started yesterday night already
5/27/23, 6:35‚ÄØPM - Amit: Bro me aapno final project no code graps mate rerun par mukelo chhe
5/27/23, 6:35‚ÄØPM - Siddharth: üëç
5/27/23, 6:35‚ÄØPM - Amit: 20 min still CNN nu 1st epoch start nathi thayu
5/27/23, 6:35‚ÄØPM - Amit: same issue
5/27/23, 6:35‚ÄØPM - Amit: Any solution?
5/27/23, 6:35‚ÄØPM - Siddharth: ü§£
5/27/23, 6:35‚ÄØPM - Siddharth: No
5/27/23, 6:35‚ÄØPM - Siddharth: Sir ne Kai de code ma issue
5/27/23, 6:36‚ÄØPM - Amit: Report ma je results nakhya ta e nakhi daie?
5/27/23, 6:36‚ÄØPM - Siddharth: Be paper chhe
5/27/23, 6:36‚ÄØPM - Amit: Code kya submit karvano hoy chhe
5/27/23, 6:36‚ÄØPM - Siddharth: Bhai sir ne ke koi navo topic aapo, aama koi novelty nai
5/27/23, 6:36‚ÄØPM - Siddharth: Still...
5/27/23, 6:37‚ÄØPM - Amit: To pachhi vinay sir valu j continue karie ne
5/27/23, 6:37‚ÄØPM - Amit: Yogesh sir paethi shu kam navo topic mangvo chhe
5/29/23, 6:09‚ÄØPM - Amit: Row merging valo code khali HDFC ma j perfect chale chhe
5/29/23, 6:09‚ÄØPM - Amit: Baki badha ma error aape chhe
5/29/23, 6:09‚ÄØPM - Siddharth: To karo solve
5/29/23, 6:10‚ÄØPM - Amit: E j karu chhu bapor nu pan e float numbers ley chhe column mathi etle error aape chhe.
Pan aakhi column ma kyay float j nathi. only str j chhe
5/29/23, 6:11‚ÄØPM - Siddharth: Mail ma aaje code nakhiye, error solve ni request sathe
5/29/23, 6:12‚ÄØPM - Amit: no problem
5/29/23, 6:13‚ÄØPM - Amit: Hu vicharu chhu pelo text valo code grp ma nakhie and debayan and divya ne kaie ke tame text mathi excel ma try karo
5/29/23, 6:13‚ÄØPM - Amit: what say?
5/29/23, 6:13‚ÄØPM - Siddharth: Ha ke
5/29/23, 6:13‚ÄØPM - Amit: ok
5/29/23, 6:13‚ÄØPM - Siddharth: Em lakhje ke out of all approach, this is best one
5/29/23, 6:13‚ÄØPM - Amit: ok
5/29/23, 6:13‚ÄØPM - Amit: mail karie grp ma nakhva karta?
5/29/23, 6:14‚ÄØPM - Siddharth: Mail j bhai
5/29/23, 6:14‚ÄØPM - Siddharth: Mane CC ma mukje
5/29/23, 6:14‚ÄØPM - Amit: ok
5/29/23, 6:14‚ÄØPM - Amit: Todu late thi karie
5/29/23, 6:14‚ÄØPM - Amit: 7:30?
5/29/23, 6:14‚ÄØPM - Siddharth: 9:30 be
5/29/23, 6:14‚ÄØPM - Amit: no problem
5/29/23, 9:14‚ÄØPM - Amit: Hu dinner karine aavu pachhi mail lakhu and tane mokalu
5/29/23, 9:40‚ÄØPM - Amit: Respected Sir,

Today we have completed the all per-processing steps for HDFC bank. We have set the pipeline for HDFC bank.

Apart from this, we have also worked on new algorithm which used DETR (Table Transformer from Microsoft) and Pytesseract (OCR library of Python). This is extracting complete information from Kotak, HDFC and ICICI bank, but it returns the tables as a form text. So now we have to convert this text to data frame. We tried but didn't get any working solution for this conversion. So Debayan and Divya, if you have something related to this then we can set a pipeline for variable format.
Note: This new approach is not working properly on SBI because DETR didn't detect table on 3rd page of the SBI statement. Other than this, it is working fine on other pages of same pdf.

I am attaching the colab link for this new approach.

Thank you.


Colab Link: https://colab.research.google.com/drive/1IJB9OqXlASmr5RrAo4wwEkXmMg8v8wpN?usp=sharing
5/29/23, 9:40‚ÄØPM - Amit: ok chhe?
5/29/23, 9:41‚ÄØPM - Siddharth: Haa

Hu same moklu?
5/29/23, 9:42‚ÄØPM - Amit: ha bro
5/29/23, 9:42‚ÄØPM - Siddharth: Okay
5/29/23, 9:42‚ÄØPM - Amit: To: Das sir
cc: Debayan, Divya, hr mam
5/29/23, 9:42‚ÄØPM - Siddharth: Haa
5/29/23, 9:43‚ÄØPM - Amit: sent
5/29/23, 9:43‚ÄØPM - Siddharth: I will soon
5/30/23, 11:11‚ÄØPM - Amit: FYI, I am restarting our paper related to our final project
5/30/23, 11:11‚ÄØPM - Amit: I have ideas regarding what to write in methodology
5/30/23, 11:12‚ÄØPM - Siddharth: üëç
5/30/23, 11:12‚ÄØPM - Amit: Just in the experiment section I am writing the same results as we wrote in our final report.
5/30/23, 11:12‚ÄØPM - Amit: Fake one
5/30/23, 11:13‚ÄØPM - Siddharth: I don't support it
5/30/23, 11:13‚ÄØPM - Amit: No one cares about it.
Even our mentor
5/30/23, 11:13‚ÄØPM - Siddharth: No, don't add my name please. 

Em pan maare paper ni requirements nathi
5/30/23, 11:14‚ÄØPM - Amit: Project ma hatu etle sir remove to nai j karva de.
5/30/23, 11:15‚ÄØPM - Siddharth: Thik, lakho Biju shu
5/30/23, 11:16‚ÄØPM - Amit: You are always my crime partner even if you don't want to.

You don't have a choice regarding this ‚ò∫Ô∏è
5/30/23, 11:17‚ÄØPM - Amit: Arre pakde gaye to koi nahi sath me jail me baith ke start up banayenge.

At least negative publicity to milegi.
5/30/23, 11:17‚ÄØPM - Amit: üòÇ
5/30/23, 11:18‚ÄØPM - Siddharth: Fake results ma koi jail ma na jaay be ü§¶‚Äç‚ôÇÔ∏è
5/30/23, 11:18‚ÄØPM - Siddharth: Khali don't mention dataset anywhere
5/30/23, 11:18‚ÄØPM - Amit: Bhai mane pan khabar chhe.

Aa to crime ni vaat hati etle khali em nem lakhtu
5/30/23, 11:19‚ÄØPM - Amit: Nandan ne shu thayu?
5/30/23, 11:19‚ÄØPM - Siddharth: Sick, no details as of now
5/30/23, 11:19‚ÄØPM - Amit: Okay
5/30/23, 11:19‚ÄØPM - Siddharth: Pan kai khas nai, mostly headache
5/30/23, 11:19‚ÄØPM - Amit: To no problem
5/31/23, 1:08‚ÄØPM - Amit: Aaje shu karvanu chhe SSB ma?
5/31/23, 1:08‚ÄØPM - Siddharth: SAIGE par aagal research kari em lakhi saidhu
5/31/23, 1:09‚ÄØPM - Amit: Ok to haal SAIGE j karvanu chhe ne?
5/31/23, 1:09‚ÄØPM - Siddharth: Haa

Any mail from Saptarshi sir?
5/31/23, 1:09‚ÄØPM - Amit: Ok to hu Nandan sathe account valu discuss kari lav aaje
5/31/23, 1:09‚ÄØPM - Amit: Not yet
5/31/23, 1:09‚ÄØPM - Siddharth: Bot?
5/31/23, 1:09‚ÄØPM - Amit: Ha
5/31/23, 1:09‚ÄØPM - Siddharth: Emne personal mail lakh
5/31/23, 1:10‚ÄØPM - Amit: Saige na report par?
5/31/23, 1:10‚ÄØPM - Siddharth: Haa
5/31/23, 1:12‚ÄØPM - Amit: Ok haal mokali dav
5/31/23, 5:31‚ÄØPM - Amit: <Media omitted>
5/31/23, 5:31‚ÄØPM - Amit: Bija options chhe pan ema kyay night vision specify notu etle atyare a 3 select karya chhe
5/31/23, 5:35‚ÄØPM - Siddharth: üëç
5/31/23, 6:46‚ÄØPM - Amit: aapne aa vinay sir valu paper karvanu chhe?
5/31/23, 7:01‚ÄØPM - Amit: Because mane have ichha nathi thati koi pan paper par work karvani
5/31/23, 7:01‚ÄØPM - Amit: Pan tu jo keto hoy to hu work karva ready chhu
5/31/23, 7:03‚ÄØPM - Siddharth: Same, joie chal
5/31/23, 7:03‚ÄØPM - Amit: ok
5/31/23, 7:04‚ÄØPM - Amit: Mare have product par kam chalu karvu chhe etle paper ni magazmari ma m=nathi padvu. Aa yogesh sir valu chhellu.
5/31/23, 7:11‚ÄØPM - Siddharth: Same
6/1/23, 8:54‚ÄØAM - Siddharth: Please do share in CM by tagging Nandu and Jeni
6/1/23, 2:13‚ÄØPM - Amit: Ssb ma aaje shu karvanu chhe?
6/1/23, 2:14‚ÄØPM - Siddharth: Nava project par research chalu kar
6/1/23, 2:14‚ÄØPM - Amit: Table saav side ma j muki devana chhe?
6/1/23, 2:14‚ÄØPM - Siddharth: Have shu karish?
6/1/23, 2:15‚ÄØPM - Amit: Haji baki j chhe ne alag alag bank mate set karvanu
6/1/23, 2:15‚ÄØPM - Amit: Khali HDFC nu j thayu chhr
6/1/23, 2:15‚ÄØPM - Siddharth: Bhai sir pela haa to pade karvani
6/1/23, 2:15‚ÄØPM - Siddharth: Vagar kame shu karish?
6/1/23, 2:15‚ÄØPM - Amit: Kai nai mane to kai problem nathi
6/1/23, 2:16‚ÄØPM - Amit: To SAIGE nu start kari dav
6/1/23, 2:53‚ÄØPM - Siddharth: Haa
6/1/23, 4:37‚ÄØPM - Amit: Call join karelo ssb grp ma?
6/1/23, 4:39‚ÄØPM - Siddharth: Kari lidhi vaat
6/1/23, 4:39‚ÄØPM - Amit: shu karvanu chhe?
6/1/23, 4:39‚ÄØPM - Siddharth: Karu call thodi vaar ma
6/1/23, 4:39‚ÄØPM - Amit: passbook mathi statement levana che?
6/1/23, 4:39‚ÄØPM - Siddharth: Haa
6/1/23, 4:40‚ÄØPM - Amit: kar
6/1/23, 4:41‚ÄØPM - Amit: tya sudhi hu SAIGE valu karu chhu
6/1/23, 4:42‚ÄØPM - Siddharth: Haa
6/1/23, 5:02‚ÄØPM - Amit: Dear All,

Please find a scanned pdf for SBI Passbook you'll have to extract text using amazon textract. And will have to create a bank transaction dataframes as done previously.  Consider the salary slips attached as well. Please consider the confidentiality of the shared documents and handle them carefully. Considering the urgency to the prodct please revert back immediately as soon as you receive this email. And we'll have abide by our restricted deadline of sunday evening asper mentioned by siddharth.

    Read Bank account statements through OCR.
    For salaried individuals capture employer name and account number from Bank Statement.
    Salary to be considered as per salary slip (Check through OCR or prompt through UI input)
    Comparative analysis of ITR returns, account statement and salary slip data to arrive at actual net salary. The demo platform also needs to identify average monthly surplus from the account statement.
6/1/23, 5:02‚ÄØPM - Amit: debayan no mail
6/1/23, 5:08‚ÄØPM - Amit: You deleted this message
6/1/23, 5:08‚ÄØPM - Amit: You deleted this message
6/1/23, 5:08‚ÄØPM - Amit: You deleted this message
6/1/23, 5:09‚ÄØPM - Siddharth: Mail frame kar aa badha mate
6/1/23, 5:09‚ÄØPM - Amit: ha
6/1/23, 10:49‚ÄØPM - Amit: Bhai cocoden live chhe ne?
6/1/23, 10:49‚ÄØPM - Siddharth: Ha
6/1/23, 10:49‚ÄØPM - Siddharth: https://cocoden.onrender.com/
6/1/23, 10:50‚ÄØPM - Amit: Ok msg joyo taro grp ma.
Error handling page pate ne etle features add karvanu stop kari deje.

Pachhi alhi team only marketing ma focus karshe. Badha roj different companies ne mail lakhshe.
6/1/23, 10:51‚ÄØPM - Siddharth: Ha e j, error walu pan time lage em chhe etle haal nai karto
6/2/23, 10:31‚ÄØPM - Amit: Bro minor headache chhe.
Hu details nandan pasethi lai laish meeting ni.
Chalshe ?
6/2/23, 10:32‚ÄØPM - Amit: Thanks.
As I already said I am in for sending mail to the companies.
So regarding that topic consider me I am in support
6/3/23, 10:47‚ÄØPM - Siddharth: Bhai, aa last sem wali ISRO internship nu name shu chhe? Mare Jeni mate search karvu chhe
6/3/23, 10:47‚ÄØPM - Amit: joine kav
6/3/23, 10:49‚ÄØPM - Siddharth: Thik, jaldi
6/3/23, 10:49‚ÄØPM - Amit: ha
6/3/23, 10:51‚ÄØPM - Amit: SAC-Academic Associate Programme (SAC-AAP) aa programme in under Work-Experience Internship (WEI)
6/3/23, 10:51‚ÄØPM - Siddharth: And kyare apply karvanu hoy andaje?
6/3/23, 10:52‚ÄØPM - Amit: 1 August deadline for internship in January next year
6/3/23, 10:52‚ÄØPM - Siddharth: Okay
6/3/23, 10:53‚ÄØPM - Siddharth: Kya check karyu deadline nu?
6/3/23, 10:54‚ÄØPM - Amit: Last year same hathi etle yaad hatu
6/3/23, 10:54‚ÄØPM - Amit: Website par check kari lav wait
6/3/23, 10:54‚ÄØPM - Siddharth: Kar
6/3/23, 10:56‚ÄØPM - Siddharth: Oy, aapne september ma apply karyu hatu
6/3/23, 11:00‚ÄØPM - Amit: <Media omitted>
6/3/23, 11:00‚ÄØPM - Amit: tame game tyare apply kari shako
6/3/23, 11:00‚ÄØPM - Siddharth: Website mokal
6/3/23, 11:01‚ÄØPM - Amit: Pan hu suggest e j karu chhu ke jo January thi start karvi hoy ne Internship to September end sudhi ma apply kari devay
6/3/23, 11:01‚ÄØPM - Amit: https://www.sac.gov.in/Vyom/srtd
6/3/23, 11:01‚ÄØPM - Siddharth: Got it
6/3/23, 11:01‚ÄØPM - Amit: An jo aakha ISRO mathi game tya karvi hoy to:

https://www.isro.gov.in/DoAProject.html
6/3/23, 11:02‚ÄØPM - Siddharth: Got it
6/4/23, 2:44‚ÄØPM - Amit: To hu atyare kayo mail lakhu resign ke month leave?
6/4/23, 2:44‚ÄØPM - Siddharth: Month leave, jevo personal project aave join again
6/4/23, 2:45‚ÄØPM - Amit: ok.
To lage chhe next 4 month ma start thai jashe pesonal project SSB ma?
6/4/23, 2:45‚ÄØPM - Siddharth: Ena karta jaldi
6/4/23, 2:45‚ÄØPM - Amit: ok.
6/4/23, 2:45‚ÄØPM - Siddharth: Bhai
6/4/23, 2:45‚ÄØPM - Siddharth: Hu shu kau chhu
6/4/23, 2:46‚ÄØPM - Siddharth: Geet bhai ne vaat karie aa product ni?
6/4/23, 2:46‚ÄØPM - Amit: TO atyre month leave no naku chhu joie allow kare chhe ke nai.
Jo allow nai kare to pachhi leave kari daish
6/4/23, 2:46‚ÄØPM - Amit: Best idea
6/4/23, 2:46‚ÄØPM - Amit: Emni pase hashe j customer
6/4/23, 2:46‚ÄØPM - Siddharth: Are karshe j ne, just lakhje ke talked with Das sir
6/4/23, 2:46‚ÄØPM - Siddharth: Msg kar call mate

Aapne meet set karie
6/4/23, 2:47‚ÄØPM - Amit: ha karu.
aaje ratre set karie meet?
6/4/23, 2:47‚ÄØPM - Siddharth: Haa, As soon as possible.

Em pan Sunday raja hashe emne etle hashe available
6/4/23, 2:47‚ÄØPM - Siddharth: Send me SS once you send msg
6/4/23, 2:47‚ÄØPM - Siddharth: And thunderbird open rakhje
6/4/23, 2:48‚ÄØPM - Amit: ha
6/4/23, 3:04‚ÄØPM - Amit: Respected Sir and Ma'am,

I hope this email finds you well. I am writing to formally request a period of unpaid leave for a duration of 4 months, starting from this month to end of September. The purpose of this leave is to allow me to fully dedicate myself to the preparation and completion of the necessary tests (IELTS and GRE) required for my master's degree application to a university in the United States.
I understand that this request may temporarily disrupt the workflow and require adjustments to ensure the smooth operation of the team during my absence. I assure you that I have carefully considered the impact of my decision and will take proactive measures to minimize any inconvenience caused to the company and my colleagues.
I understand the importance of open communication and maintaining a cooperative spirit within the team. Therefore, I will be accessible via email or other means of communication during my leave, should any urgent matters arise that require my attention or guidance.
I greatly appreciate your understanding and consideration of my request. I value my position at [Company Name] and am committed to maintaining a strong work ethic and delivering exceptional results upon my return.
Thank you for your attention to this matter. I look forward to discussing my request further and addressing any concerns or questions you may have. I am confident that with your support, I will be able to balance my academic pursuits with my commitment to the company.

Yours sincerely,
Amit Hirpara.
6/4/23, 3:04‚ÄØPM - Amit: have aama changes ke mane
6/4/23, 3:05‚ÄØPM - Siddharth: [Company name] ma SSB
6/4/23, 3:05‚ÄØPM - Amit: ha
6/4/23, 3:05‚ÄØPM - Siddharth: Das sir walu pan
6/4/23, 3:05‚ÄØPM - Siddharth: Also, I will try to join ASAP em pan lakh so you can join once we get project
6/4/23, 3:06‚ÄØPM - Amit: E add no karu to saru because das sir e mane end ma to em kidhu ke jo leave levu hashe to hr mam ni permission to joishe. Tumail deliver kari de hu kale office ma jaine sir and hr mam sathe vaat karish.
6/4/23, 3:06‚ÄØPM - Siddharth: this
6/4/23, 3:07‚ÄØPM - Amit: aa add karu chhu
6/4/23, 3:07‚ÄØPM - Siddharth: Geet bhai sathe vaat?
6/4/23, 3:07‚ÄØPM - Amit: aa mail drop karine emne karu msg
6/4/23, 3:07‚ÄØPM - Siddharth: Geet bhai ne em j kevanu chhe ke ame tamne per sell ek amount pay karishu each month
6/4/23, 3:08‚ÄØPM - Amit: ha same affiliation valo plan
6/4/23, 3:08‚ÄØPM - Siddharth: ha
6/4/23, 3:30‚ÄØPM - Amit: Geet bhai no no malto nathi etle rahil bhai pasethi mangavyo chhe
6/4/23, 3:30‚ÄØPM - Amit: Rahul bhai*
6/4/23, 3:30‚ÄØPM - Siddharth: Thik
Haal Nandu ne nai keto, meet ma aapne be j jaishu.

Surprise for team
6/4/23, 3:31‚ÄØPM - Siddharth: E khabar padi gai
6/4/23, 3:31‚ÄØPM - Amit: Sure üòä
6/5/23, 8:03‚ÄØAM - Siddharth: .
6/5/23, 9:31‚ÄØAM - Siddharth: <Media omitted>
6/5/23, 9:33‚ÄØAM - Siddharth: Now start your work as CFO
6/5/23, 9:39‚ÄØAM - Amit: Started Excel file for recording
6/5/23, 10:10‚ÄØAM - Amit: Haji reply nathi
6/5/23, 10:10‚ÄØAM - Siddharth: ü•π
6/5/23, 8:39‚ÄØPM - Amit: https://meet.google.com/ceq-yrri-tkk
6/5/23, 8:39‚ÄØPM - Siddharth: Aayo
6/5/23, 9:17‚ÄØPM - Siddharth: 22 USD ma pade aapnne 1 million token walu.
And 5 million token ma 30 USD
6/5/23, 9:26‚ÄØPM - Amit: Connect kare chhe pachho aavi ja
6/5/23, 9:27‚ÄØPM - Siddharth: Haa
6/5/23, 9:29‚ÄØPM - Siddharth: Aa product purto to Geet bhai ne stack aapvo pade to pan chalshe
6/5/23, 9:29‚ÄØPM - Amit: no problem
6/9/23, 5:54‚ÄØPM - Amit: Yaar SSBI no kai mail nathi unpaid leave par
6/9/23, 5:54‚ÄØPM - Amit: shu karu?
6/9/23, 5:55‚ÄØPM - Siddharth: Mail again
6/9/23, 5:55‚ÄØPM - Amit: ok
6/13/23, 10:19‚ÄØPM - Siddharth: https://meet.google.com/uwd-qyfq-cjm
6/15/23, 11:06‚ÄØPM - Amit: Yaar ye ssb ka abhi bhi reply nahi aaya leave ke regarding.

To me regular progress mail dalu ki nahi?
6/15/23, 11:07‚ÄØPM - Siddharth: Daalta rahe abhi to
6/15/23, 11:07‚ÄØPM - Siddharth: Taaki bol sake ki reply nai aaya tab tak kaam kar raha tha
6/21/23, 10:24‚ÄØPM - Siddharth: Oi, maari degree lai lidhi chhe?
6/21/23, 10:25‚ÄØPM - Siddharth: Ke baaki?
6/21/23, 10:25‚ÄØPM - Amit: Lai lidhi
6/21/23, 10:25‚ÄØPM - Amit: Dgree and transcript banne chhe mari pase
6/21/23, 10:25‚ÄØPM - Siddharth: Saras, July maa tane malu etle tara pase thi j laish have
6/21/23, 10:26‚ÄØPM - Amit: Sem 8 nu result nathi malvanu ho
6/21/23, 10:27‚ÄØPM - Amit: Transcript thi j kam chalavanu chhe have
6/21/23, 10:27‚ÄØPM - Siddharth: Okay bhai
6/23/23, 3:01‚ÄØPM - Siddharth: Oi, add 25 USD to cost list
6/28/23, 11:26‚ÄØAM - Amit: Maru ssb nu id tara ma login chhe ne?
6/28/23, 11:27‚ÄØAM - Amit: To kalno progress mail send kari dene maro
6/28/23, 11:27‚ÄØAM - Siddharth: Logout thai gayu
6/28/23, 11:27‚ÄØAM - Amit: Kai vandho nai
6/28/23, 11:27‚ÄØAM - Siddharth: And me j last 6-7 di thi mail nai karyo due to error in my ID
6/28/23, 11:27‚ÄØAM - Amit: Haji solve nathi thai?
6/28/23, 11:27‚ÄØAM - Siddharth: Na yaar
6/28/23, 11:28‚ÄØAM - Amit: Thai jashe
6/28/23, 11:28‚ÄØAM - Siddharth: Haa, nai to em pan thoda time ma resign karu chhu so no worries
6/28/23, 11:28‚ÄØAM - Amit: Kem?

Shu thayu?
6/28/23, 11:28‚ÄØAM - Siddharth: Kai nai, better offer
6/28/23, 11:28‚ÄØAM - Amit: From sphinix?
6/28/23, 11:28‚ÄØAM - Siddharth: Haan ji
6/28/23, 11:29‚ÄØAM - Amit: Good
6/28/23, 11:29‚ÄØAM - Siddharth: To shu kevu, lai levay ne?
6/28/23, 11:29‚ÄØAM - Amit: Ha be aavi opportunity thodi miss karay
6/28/23, 11:29‚ÄØAM - Amit: Lai leje aa vakhte miss na karto
6/28/23, 11:29‚ÄØAM - Siddharth: Okay bhai
7/6/23, 3:18‚ÄØPM - Siddharth: SBI nu koi bank statement hoy to mokal
7/6/23, 6:41‚ÄØPM - Amit: Laptop ma chhe
Room par jaine mokalu
7/6/23, 8:22‚ÄØPM - Siddharth: üëç
7/11/23, 12:10‚ÄØPM - Amit: Ti haji resign nthi karyu?
7/11/23, 12:10‚ÄØPM - Amit: Te*
7/11/23, 12:11‚ÄØPM - Siddharth: Kari didhhu, notice period par chhu
7/11/23, 12:11‚ÄØPM - Amit: Ketla time mate?
7/11/23, 12:13‚ÄØPM - Siddharth: 1.5 month
7/11/23, 12:14‚ÄØPM - Amit: Ok 
What about Nandan?
7/11/23, 12:39‚ÄØPM - Siddharth: Haji interview nai thayu
7/11/23, 12:46‚ÄØPM - Amit: Ok
7/17/23, 5:27‚ÄØPM - Siddharth: Bhai, payment system figure out kari de please üôè
7/17/23, 5:27‚ÄØPM - Siddharth: Pakku startup hu etle pahochadi daish ke tare US nai javu pade bas
7/17/23, 5:28‚ÄØPM - Amit: Kai use karvani chhe?
7/17/23, 5:28‚ÄØPM - Siddharth: Paddle ke Lemon, je thay e
7/17/23, 5:28‚ÄØPM - Amit: ok
7/17/23, 5:28‚ÄØPM - Amit: Jaou chhu
7/21/23, 10:57‚ÄØAM - Amit: Jaydeep kon chhe?
7/21/23, 10:57‚ÄØAM - Siddharth: PDEU MTech
7/21/23, 10:57‚ÄØAM - Siddharth: New in ML team
7/21/23, 10:57‚ÄØAM - Amit: Tari jaya par?
7/21/23, 10:57‚ÄØAM - Amit: Jagya*
7/21/23, 10:57‚ÄØAM - Siddharth: Na, haal to hu chhu
7/21/23, 10:58‚ÄØAM - Amit: Tu kyare leave kare chho?
7/21/23, 10:58‚ÄØAM - Siddharth: Addition ni jarur hati
7/21/23, 10:58‚ÄØAM - Siddharth: 31st August haji to chhek
7/21/23, 10:58‚ÄØAM - Amit: Means haji next month?
7/21/23, 10:58‚ÄØAM - Siddharth: Haan
7/21/23, 10:58‚ÄØAM - Amit: Very bad
7/21/23, 10:58‚ÄØAM - Siddharth: Pahochi hayo Surat?
7/21/23, 10:58‚ÄØAM - Amit: üòÇ
7/21/23, 10:58‚ÄØAM - Amit: Ha
7/21/23, 10:58‚ÄØAM - Siddharth: Nandu aaje hostel aavva niklyo
7/21/23, 10:58‚ÄØAM - Amit: Sphinix bhai vala ma thai gayu confirme?
7/21/23, 10:59‚ÄØAM - Siddharth: Haan confirm j chhe, just waiting for joining letter
7/21/23, 10:59‚ÄØAM - Siddharth: To aaje call par startup discuss karie? 
Have no plan?
7/21/23, 10:59‚ÄØAM - Amit: Ema September thi start?
7/21/23, 10:59‚ÄØAM - Amit: Ha
7/21/23, 10:59‚ÄØAM - Siddharth: Yup
7/21/23, 10:59‚ÄØAM - Siddharth: Okay, bapore karu call
7/21/23, 10:59‚ÄØAM - Amit: Ok
7/22/23, 4:10‚ÄØPM - Siddharth: RPi mikli shakish?
7/22/23, 4:36‚ÄØPM - Amit: Dhruvil ne puchhine kav
7/22/23, 4:46‚ÄØPM - Siddharth: Jaldi ke
7/23/23, 9:50‚ÄØAM - Siddharth: Bhai, jaldi
7/23/23, 9:52‚ÄØAM - Amit: Ek kam kar ne dhruvil ne j direct call kar ne eni pase chhe e parcel kari deshe
7/23/23, 10:30‚ÄØAM - Siddharth: Are pan tare setup karvi padshe basic OS sathe
7/23/23, 10:30‚ÄØAM - Siddharth: Hostel maa e loko kevi reete karshe?
7/23/23, 10:31‚ÄØAM - Amit: E to dhruvil kari deshe and I guess ene kadach kari pan dodhi hashe because e keto hato ke ene use kari hati etle
7/23/23, 10:31‚ÄØAM - Siddharth: Naa, tare SSH set karvu padshe
7/23/23, 10:31‚ÄØAM - Siddharth: Aapna specific settings mate
7/23/23, 10:32‚ÄØAM - Siddharth: I have someone who want to buy 4-5 devices and we don't even have prototype
7/23/23, 10:46‚ÄØAM - Amit: Kya mokalvani chhe?
7/23/23, 10:47‚ÄØAM - Siddharth: 307, JMD
7/24/23, 10:23‚ÄØAM - Siddharth: Bhai, tu je PG maa hato eno number aap ne, Jeni ne joie chhe
7/24/23, 10:24‚ÄØAM - Siddharth: Urgent chhe, mokal ne
7/24/23, 10:25‚ÄØAM - Amit: 7600001136

Jitendra bhai
7/24/23, 10:25‚ÄØAM - Siddharth: Thanks
7/26/23, 8:02‚ÄØPM - Siddharth: Bhai
7/26/23, 8:02‚ÄØPM - Siddharth: Maara banne documents taari paase chhe eni PDF mokal plz
7/26/23, 8:05‚ÄØPM - Amit: Mokalu.
Thodi vaar lagshe.
7/26/23, 8:06‚ÄØPM - Siddharth: Okay
7/26/23, 9:06‚ÄØPM - Siddharth: Reminder
7/26/23, 9:30‚ÄØPM - Amit: <Media omitted>
7/26/23, 9:30‚ÄØPM - Amit: <Media omitted>
7/26/23, 9:31‚ÄØPM - Amit: <Media omitted>
7/26/23, 9:31‚ÄØPM - Amit: <Media omitted>
7/26/23, 9:31‚ÄØPM - Siddharth: Done ne badha?
7/26/23, 9:31‚ÄØPM - Amit: Ha
7/26/23, 9:31‚ÄØPM - Siddharth: Thanks vro üôè
7/28/23, 6:33‚ÄØAM - Amit: <Media omitted>
7/28/23, 8:23‚ÄØAM - Siddharth: üéâ
7/28/23, 8:32‚ÄØAM - Amit: Thanks
7/31/23, 10:06‚ÄØPM - Siddharth: RPi?
7/31/23, 10:50‚ÄØPM - Amit: Dhruvi pase chhe mare leva javani chhe.

Pan hamna varsad no noto gayo. Hu lai aavish aaj kal ma.
7/31/23, 11:02‚ÄØPM - Siddharth: üëç
8/1/23, 9:50‚ÄØAM - Siddharth: RPi nu jaldi karje, hu address moklish
8/1/23, 9:50‚ÄØAM - Amit: Ha
8/3/23, 9:37‚ÄØPM - Siddharth: Bhai shu scene chhe yaar Pi no?
8/3/23, 9:38‚ÄØPM - Siddharth: More than week now
8/4/23, 7:34‚ÄØAM - Amit: Hu Saturday javano chhu dhruvil ne tya
8/4/23, 9:16‚ÄØAM - Siddharth: Okay
8/4/23, 9:16‚ÄØAM - Amit: Parcel nandan ne karvano chhe ne?
8/4/23, 9:16‚ÄØAM - Siddharth: Jenish
8/4/23, 9:17‚ÄØAM - Amit: Means JMD j chhe ne?
8/4/23, 9:17‚ÄØAM - Siddharth: Naa, e hu kaish, tu lai to aav
8/4/23, 9:17‚ÄØAM - Amit: Ok
8/15/23, 4:05‚ÄØPM - Siddharth: Te RPi mokli didhi hati?
8/15/23, 4:05‚ÄØPM - Siddharth: Mane koi update nathi koi taraf thi etle puchhu chhu
8/15/23, 8:35‚ÄØPM - Amit: Na haji mari pase j chhe.
Hu mokalvano j chhu hamna.
8/15/23, 8:35‚ÄØPM - Amit: Maje haji os check karvano time noto malyo etle late thayu
8/15/23, 8:36‚ÄØPM - Amit: Bu the way Naimish and Dhruvil ne aavi gayo letter Waterloo mathi
8/15/23, 8:36‚ÄØPM - Amit: Jan 2024 intake mate
8/15/23, 8:37‚ÄØPM - Amit: To vicharu chhu e loko jay e pela last trip plan kari laie sathe
8/15/23, 8:37‚ÄØPM - Siddharth: I know
8/15/23, 8:37‚ÄØPM - Siddharth: Karie kaik thay to
8/15/23, 8:37‚ÄØPM - Siddharth: Please fast
8/15/23, 8:37‚ÄØPM - Amit: Ha
8/15/23, 8:38‚ÄØPM - Amit: Koi sari jagya hoy to keje
8/15/23, 8:38‚ÄØPM - Siddharth: Haa
8/17/23, 1:17‚ÄØPM - Amit: Aapne koi hackathon ma Rajeev sir mentor hata?
8/17/23, 1:17‚ÄØPM - Siddharth: Haan
8/17/23, 1:17‚ÄØPM - Amit: Kai?
8/17/23, 1:17‚ÄØPM - Amit: SIH?
8/17/23, 1:18‚ÄØPM - Siddharth: Vinay sir ne Rajiv sir banne hata e 

IIC wali
8/17/23, 1:18‚ÄØPM - Siddharth: Haa, SIH
8/17/23, 1:18‚ÄØPM - Amit: Ok thanks buddy
8/17/23, 1:19‚ÄØPM - Amit: Ema farmer valu problem statement hatu ne ?

Equipment rent karva valu?
8/17/23, 1:19‚ÄØPM - Siddharth: Haan
8/18/23, 11:08‚ÄØAM - Amit: Bro Shakti mam no number send karne
8/18/23, 11:09‚ÄØAM - Siddharth: Shit, delete thai gayo chhe
8/18/23, 11:09‚ÄØAM - Amit: üò≠
8/18/23, 11:09‚ÄØAM - Siddharth: Vegas bhai
8/18/23, 11:09‚ÄØAM - Amit: Ok
8/26/23, 11:07‚ÄØAM - Siddharth: Bhai, your address?
My brother will collect my docs from you.
8/26/23, 11:12‚ÄØAM - Amit: 143, Ganga Jamna Soc, Gate no. 3, Near Tapovan circle, Nana Varachha, Surat.
8/26/23, 11:13‚ÄØAM - Siddharth: You available for next 1-2 days na?
8/26/23, 11:14‚ÄØAM - Amit: Ha ha
8/26/23, 11:14‚ÄØAM - Siddharth: Okayy
8/26/23, 11:15‚ÄØAM - Amit: Je divase taro bhai aavavno hoy mane msg kari deje
8/26/23, 11:15‚ÄØAM - Siddharth: Okayyy
8/29/23, 5:07‚ÄØPM - Siddharth: Broo, RPi nu shu chhe kai de have.
8/29/23, 10:01‚ÄØPM - Amit: Hu college javano chhu 20 tarikhe tyare leto javanu chhu
8/29/23, 10:03‚ÄØPM - Siddharth: Someone will collect from your house in next few days
8/29/23, 10:05‚ÄØPM - Amit: Eni jaroor nathi hu javano j chhu college
8/29/23, 10:05‚ÄØPM - Amit: Hu Jenish ne aapi daish
8/29/23, 10:05‚ÄØPM - Siddharth: Jeni e fix karyu chhe
8/29/23, 10:05‚ÄØPM - Amit: Ha to ene msg kari dav hu
8/29/23, 10:16‚ÄØPM - Siddharth: Bhai, thodi jaldi joie chhe, moklavi deje ne
9/3/23, 6:58‚ÄØPM - Siddharth: Pi ma SD card hatu ne?
9/3/23, 7:02‚ÄØPM - Amit: Ha
9/3/23, 7:02‚ÄØPM - Amit: Handover kari didhi
9/3/23, 7:02‚ÄØPM - Siddharth: üëçüëçüëç
9/3/23, 7:02‚ÄØPM - Siddharth: Haan e mane call aavyo hato
9/26/23, 4:14‚ÄØPM - Amit: Call?
9/26/23, 4:14‚ÄØPM - Siddharth: Haan kar
9/28/23, 9:09‚ÄØAM - Amit: Send me the resources for website
9/28/23, 9:09‚ÄØAM - Siddharth: Haan 10 min
9/28/23, 1:15‚ÄØPM - Siddharth: First page will be search page, ema search pramane next page par badha search result nu list and je element par click kare e page par eni details, simple
9/28/23, 1:15‚ÄØPM - Siddharth: API Nandu paase thi lai le
9/28/23, 2:35‚ÄØPM - Amit: Ok
9/29/23, 5:18‚ÄØPM - Amit: <Media omitted>
9/29/23, 5:18‚ÄØPM - Amit: for my reference
9/29/23, 5:19‚ÄØPM - Siddharth: Okayy
I downloaded locally in-case needed
9/29/23, 5:19‚ÄØPM - Amit: üëç
9/30/23, 7:55‚ÄØAM - Amit: Bro thinking about buying a macbook.
Any suggestions?
9/30/23, 10:12‚ÄØAM - Siddharth: Go ahead, best idea
9/30/23, 10:22‚ÄØAM - Amit: Is it good for ML training?
9/30/23, 10:23‚ÄØAM - Siddharth: Kayu le chhe e ke
9/30/23, 10:23‚ÄØAM - Amit: you suggest
9/30/23, 10:23‚ÄØAM - Siddharth: M2 chip is compulsory now. And minimum 16gb ram
9/30/23, 10:23‚ÄØAM - Amit: I think Macook Air 15'' M2 chip
9/30/23, 10:23‚ÄØAM - Siddharth: Hu tane models kau joi chal
9/30/23, 10:23‚ÄØAM - Amit: ok
9/30/23, 10:37‚ÄØAM - Siddharth: Bhai aa to 8gb chhe
9/30/23, 10:37‚ÄØAM - Siddharth: Nai chale, badha LLM overflow thay chhe
9/30/23, 10:39‚ÄØAM - Amit: Tare 8GB chhe Asuss ma?
9/30/23, 10:39‚ÄØAM - Amit: Asus*
9/30/23, 10:39‚ÄØAM - Siddharth: Haan
9/30/23, 10:40‚ÄØAM - Siddharth: Majority nava models nai chalta
9/30/23, 10:40‚ÄØAM - Amit: Then the minimum option for me is MacBook pro 14'' M2 pro chip
9/30/23, 10:40‚ÄØAM - Siddharth: And tane khabar chhe Colab pro is not that good
9/30/23, 10:40‚ÄØAM - Siddharth: Link mokal
9/30/23, 10:40‚ÄØAM - Amit: Etle to levu chhe.
Nakar atyare j no colab use karu
9/30/23, 10:40‚ÄØAM - Siddharth: Haa e j
9/30/23, 10:41‚ÄØAM - Amit: https://www.apple.com/in/shop/buy-mac/macbook-pro/14-inch-macbook-pro
9/30/23, 10:42‚ÄØAM - Siddharth: Bhai saras chhe
9/30/23, 10:42‚ÄØAM - Amit: Price pan saras chhe üòÖ
9/30/23, 10:42‚ÄØAM - Siddharth: Haan üòÇ
9/30/23, 10:42‚ÄØAM - Siddharth: Pan PC set na thatu hoy etle long term mate aa j best
9/30/23, 10:43‚ÄØAM - Amit: Ha have je laish e long term mate j levu padshe
9/30/23, 10:43‚ÄØAM - Siddharth: Bhai literally, etlu performance chhe ne aa M2 chip nu
9/30/23, 10:43‚ÄØAM - Siddharth: To lai le aa, no second thoughts. 

Because Mac thi better koi laptop nai
9/30/23, 10:44‚ÄØAM - Amit: Thinking ke jo mac j levu hoy to USA thi sastu nai pade?
9/30/23, 10:44‚ÄØAM - Siddharth: Haan, extremely sastu comparison maa
9/30/23, 10:45‚ÄØAM - Amit: And next year sudhima koi new model aavshe to automatically jina models ni price down thai jashe + student discount
9/30/23, 10:45‚ÄØAM - Siddharth: 1.5 pan nai thata aana tya to

Ahi to sidha 2
9/30/23, 10:45‚ÄØAM - Amit: Ha me kale convert karine joya
9/30/23, 10:45‚ÄØAM - Siddharth: Haan
And jo startup thai jaay to pachhi ahi thi lai levanu, simple
9/30/23, 10:45‚ÄØAM - Amit: Almost 50K save thay che
9/30/23, 10:46‚ÄØAM - Siddharth: Haan e j
9/30/23, 10:46‚ÄØAM - Amit: Ha ema to koi doubt nai
9/30/23, 10:46‚ÄØAM - Siddharth: Chal hu shower pachhi vaat karu
9/30/23, 10:46‚ÄØAM - Amit: Ok
9/30/23, 11:05‚ÄØAM - Siddharth: Bhai, em to Lambda labs na GPU instance extremely cheap

Laptop naa change kare to use that
9/30/23, 11:05‚ÄØAM - Siddharth: A100 level GPU pan less than 1 USD per hour
9/30/23, 11:06‚ÄØAM - Amit: Pan aam pan laptop to change karvu j chhe mare
9/30/23, 11:06‚ÄØAM - Siddharth: To Mac sivay kaik haal le
9/30/23, 11:06‚ÄØAM - Amit: Arre hu wait kari laish no problem
9/30/23, 11:06‚ÄØAM - Siddharth: Because US ma sastu padshe. 

And jo US javanu naa thay to startup maa to PC j build Kari laishu
9/30/23, 11:07‚ÄØAM - Amit: I can wait 1 year
9/30/23, 11:07‚ÄØAM - Amit: So no problem.
Aa to hu atyare research karto to ke jo USA thi na levu hoy to pachhi atyre j ahiya thi lai lav
9/30/23, 11:23‚ÄØAM - Siddharth: Okay saras
10/1/23, 8:54‚ÄØPM - Siddharth: <Media omitted>
10/1/23, 8:59‚ÄØPM - Siddharth: <Media omitted>
10/4/23, 6:08‚ÄØPM - Siddharth: <Media omitted>
10/4/23, 6:08‚ÄØPM - Amit: PERFECT BUDDY
10/4/23, 6:09‚ÄØPM - Siddharth: <Media omitted>
10/6/23, 10:05‚ÄØAM - Siddharth: <Media omitted>
10/6/23, 10:30‚ÄØAM - Siddharth: Thai gayu buy?
10/6/23, 11:04‚ÄØAM - Amit: Haal mummy sathe baar chhu bapore ghare jaine joi lav
10/6/23, 11:04‚ÄØAM - Amit: Pela frd sathe vaat thai marketing vishe?
10/6/23, 11:10‚ÄØAM - Siddharth: Karu chhu 1130 e e free chhe tyare
10/6/23, 11:13‚ÄØAM - Amit: Ok üëå
10/6/23, 12:26‚ÄØPM - Siddharth: Call kyare Karu?
10/6/23, 12:27‚ÄØPM - Amit: Ene ke mane?
10/6/23, 12:47‚ÄØPM - Siddharth: Tane
10/6/23, 12:47‚ÄØPM - Amit: atyare kar vandho nai
10/6/23, 12:47‚ÄØPM - Siddharth: Okay, 1 min
10/6/23, 5:47‚ÄØPM - Amit: mare mlbrothers no seesion time out thai gayo chhe.
10/6/23, 5:48‚ÄØPM - Amit: to domain tu lai leje ne pls
10/6/23, 5:48‚ÄØPM - Siddharth: Kari de login, details moklu
10/6/23, 5:48‚ÄØPM - Siddharth: Maare Biju kaam chalu chhe
10/6/23, 5:48‚ÄØPM - Siddharth: MLBrothers2024@#
10/6/23, 10:16‚ÄØPM - Amit: leafylives.in
10/6/23, 10:24‚ÄØPM - Siddharth: leafy-lives.onrender.com
10/6/23, 10:24‚ÄØPM - Siddharth: 216.24.57.1
10/6/23, 10:31‚ÄØPM - Siddharth: https://leafylives.in/
10/9/23, 5:00‚ÄØPM - Siddharth: Bhai
10/9/23, 5:00‚ÄØPM - Siddharth: bhai
10/9/23, 5:00‚ÄØPM - Siddharth: bhai
10/9/23, 5:00‚ÄØPM - Siddharth: bhai
10/9/23, 5:34‚ÄØPM - Amit: Sorry bro net bandh hatu
10/9/23, 5:34‚ÄØPM - Amit: Bol ne
10/9/23, 5:34‚ÄØPM - Siddharth: <Media omitted>
10/9/23, 5:34‚ÄØPM - Amit: Te order karyu?
10/9/23, 5:35‚ÄØPM - Siddharth: Na, pan ichcha chhe
10/9/23, 5:35‚ÄØPM - Siddharth: Bhai just 2248
10/9/23, 5:35‚ÄØPM - Siddharth: Imagine
10/9/23, 5:35‚ÄØPM - Amit: Ha to lai le
10/9/23, 5:35‚ÄØPM - Amit: Mechanical
10/9/23, 5:35‚ÄØPM - Amit: Wired or not?
10/9/23, 5:35‚ÄØPM - Siddharth: Haan vroo
10/9/23, 5:35‚ÄØPM - Siddharth: Mechanical aatlu sastu
10/9/23, 5:35‚ÄØPM - Siddharth: Haan wired
10/9/23, 5:35‚ÄØPM - Amit: Bro look pan cool chhe
10/9/23, 5:35‚ÄØPM - Amit: Lai le
10/9/23, 5:35‚ÄØPM - Siddharth: Haan
10/9/23, 5:36‚ÄØPM - Amit: Mare pan levu hatu pan have mac par focus chhe ü§§
10/9/23, 5:36‚ÄØPM - Siddharth: Aapne banne shodhta hata etle tane pan moklyu

Because aa level na aapne joya e badha 10k+ hata
10/9/23, 5:36‚ÄØPM - Amit: Ha e j ne
10/9/23, 5:36‚ÄØPM - Amit: No need for second thoughts

Buy it
10/9/23, 5:36‚ÄØPM - Siddharth: Haan
10/11/23, 9:01‚ÄØPM - Siddharth: FOR MY REFERENCCE

{% for section in blog_post['sections'] %}
        <section>
            <!-- Display section title -->
            <h3>{{ section['title'] }}</h3>

            <!-- Display section image -->
            {% if section['image'] %}
            <img src="{{ section['image'] }}" alt="Image">
            {% endif %}
            
            <!-- Display section content -->
            {{ section['content'] }}
        </section>
        {% endfor %}
10/13/23, 6:14‚ÄØPM - Siddharth: 2 datasets
10/13/23, 6:14‚ÄØPM - Siddharth: https://www.kaggle.com/datasets/abhinavmoudgil95/short-jokes
10/13/23, 6:14‚ÄØPM - Siddharth: https://github.com/taivop/joke-dataset
10/13/23, 6:14‚ÄØPM - Amit: Ok
10/13/23, 6:14‚ÄØPM - Siddharth: https://cordova.apache.org/

Cordova
10/13/23, 6:14‚ÄØPM - Siddharth: Focus on great design bhai
10/13/23, 6:15‚ÄØPM - Amit: Dall e dambhal lega
10/13/23, 6:15‚ÄØPM - Siddharth: Haan
10/14/23, 9:48‚ÄØAM - Siddharth: Update on joke app?
10/14/23, 9:54‚ÄØAM - Amit: Working on it today
10/14/23, 9:54‚ÄØAM - Siddharth: Also, can you pay for render?
I will manage API part
10/14/23, 9:54‚ÄØAM - Siddharth: Note: It is 20 USD a month
10/14/23, 9:55‚ÄØAM - Amit: Let me check
10/14/23, 9:55‚ÄØAM - Siddharth: I mean, just UPI me, I have credit card
10/14/23, 9:55‚ÄØAM - Siddharth: Because it will need credit card
10/14/23, 9:56‚ÄØAM - Amit: Me dekh leta hu.
Aaj hi pay karna he?
10/14/23, 9:56‚ÄØAM - Siddharth: Yup
10/14/23, 9:56‚ÄØAM - Siddharth: Kal PH launch hai
10/14/23, 9:56‚ÄØAM - Amit: Ok
Ha pata he.
Me dekhta hu render.
10/14/23, 9:56‚ÄØAM - Siddharth: Okay
10/14/23, 11:57‚ÄØAM - Amit: we have to first add card details in render
10/14/23, 11:57‚ÄØAM - Siddharth: I know that
10/14/23, 11:58‚ÄØAM - Amit: To details?
10/14/23, 11:58‚ÄØAM - Siddharth: Maru card chhe, but I have so many spendings I cannot spend more 20 USD a month
10/14/23, 12:00‚ÄØPM - Amit: To konu credit card add karvanu chhe?
10/14/23, 12:00‚ÄØPM - Siddharth: Be card maaru, but someone needs to pay that 20 to me
10/14/23, 12:01‚ÄØPM - Amit: Acchha ok
10/14/23, 12:02‚ÄØPM - Amit: to details to de add kari dav.
Because first details save karvani chhe. Pachhi game tyare payment kari shakay.
10/14/23, 12:02‚ÄØPM - Amit: And hu send kari daish.
10/14/23, 12:02‚ÄØPM - Siddharth: E hu kari daish add
10/14/23, 12:02‚ÄØPM - Siddharth: Haal card maari paase nathi etle
10/14/23, 12:03‚ÄØPM - Amit: ok.
To ketla send karvana chhe?
10/14/23, 12:03‚ÄØPM - Amit: INR ke
10/14/23, 12:03‚ÄØPM - Siddharth: E hu kaish tane add karta
10/14/23, 10:06‚ÄØPM - Siddharth: Joke app update?
10/14/23, 10:10‚ÄØPM - Amit: Sorry bro aaje match na chakkar ma baki rahi gayu.

Kale aakhi divas free j chhu. Kale complete kari daish.
10/14/23, 10:10‚ÄØPM - Siddharth: Haan no issues, hu pan match ma j hato
10/14/23, 10:10‚ÄØPM - Siddharth: Aato just as leading engineering I needed to ask, biju kai nai
10/14/23, 10:10‚ÄØPM - Amit: Arre no problem.
It's good to ask.üëç
10/14/23, 10:11‚ÄØPM - Amit: Kale hu tane demo aapi daish.
(With basic CSS)
10/14/23, 10:11‚ÄØPM - Siddharth: Done
10/14/23, 10:12‚ÄØPM - Siddharth: CSS ma help joie to keje. After all this time, I am literally an expert
10/14/23, 10:12‚ÄØPM - Siddharth: üòÖ
10/15/23, 9:46‚ÄØAM - Amit: Total reddit jokes: 194553
For my reference
10/15/23, 9:46‚ÄØAM - Siddharth: Cool
10/15/23, 12:06‚ÄØPM - Siddharth: Cordova ma banave chhe ne?
10/15/23, 12:06‚ÄØPM - Amit: Haal to basic website prepare karu chhu.
Ek vaar e create thai jay etle pachhi ene cordova ma shift kari daish
10/15/23, 12:06‚ÄØPM - Siddharth: Na, Cordova kar direct
10/15/23, 12:07‚ÄØPM - Amit: ok
10/15/23, 12:08‚ÄØPM - Siddharth: Because bhai Cordova test thai jaay
10/15/23, 12:08‚ÄØPM - Amit: ok ok
10/15/23, 4:53‚ÄØPM - Siddharth: Update on jokes app?
10/15/23, 4:58‚ÄØPM - Amit: on it.
Logic completed.
Now working with cordova\
10/15/23, 4:59‚ÄØPM - Siddharth: Cool
Can I see design?
10/15/23, 5:00‚ÄØPM - Amit: <Media omitted>
10/15/23, 5:01‚ÄØPM - Siddharth: Cool, I was hoping CSS
10/15/23, 5:01‚ÄØPM - Amit: Jo cordova ma vaar nai lage to basic CSS pan aaje pati jashe.
10/15/23, 5:01‚ÄØPM - Siddharth: Haan okay
10/15/23, 5:05‚ÄØPM - Amit: Mare net slow chhe etle first time install and setup ma thodi vaar lage hhe
10/15/23, 5:05‚ÄØPM - Amit: chhe*
10/15/23, 5:05‚ÄØPM - Siddharth: Haan okay
10/15/23, 7:00‚ÄØPM - Amit: <Media omitted>
10/15/23, 7:00‚ÄØPM - Amit: Now need to convert this into apk
10/15/23, 7:01‚ÄØPM - Amit: For that I need to setup Java, SDK, Gradle and other stuff
10/15/23, 7:01‚ÄØPM - Amit: Need some time for that
10/15/23, 7:02‚ÄØPM - Amit: BTW

There not a single line in CSS file. This is cordova's deafult look
10/15/23, 7:39‚ÄØPM - Siddharth: Cool
10/18/23, 10:00‚ÄØAM - Siddharth: 2 kaam:
1. Show me design of joke app
2. Ads kai reete add karay ema e joi le
10/18/23, 11:37‚ÄØAM - Amit: https://meet.google.com/zjt-iqmx-ycu
10/18/23, 11:38‚ÄØAM - Amit: npm install -g cordova
10/18/23, 11:38‚ÄØAM - Amit: cordova requirements
10/18/23, 11:38‚ÄØAM - Amit: <Media omitted>
10/18/23, 11:40‚ÄØAM - Siddharth: https://twitter.com/adamlyttleapps/status/1714421214658379974
10/18/23, 11:53‚ÄØAM - Siddharth: <Media omitted>
10/18/23, 12:15‚ÄØPM - Amit: cordova build android
10/18/23, 1:14‚ÄØPM - Siddharth: Use this color: #FAF5EC
10/18/23, 1:19‚ÄØPM - Siddharth: https://pin.it/6kpgBJy

Aa jo for background
10/18/23, 1:19‚ÄØPM - Amit: Chale evu chhe
10/18/23, 1:20‚ÄØPM - Siddharth: Use it 
Joi le pela app ma kevu lage che
10/18/23, 1:20‚ÄØPM - Amit: Aa color match thay chhe aa bg sathe?
10/18/23, 1:20‚ÄØPM - Siddharth: Na
10/18/23, 1:20‚ÄØPM - Siddharth: E ignore kar
10/18/23, 1:20‚ÄØPM - Amit: Ok
10/18/23, 1:56‚ÄØPM - Siddharth: <Media omitted>
10/18/23, 1:56‚ÄØPM - Siddharth: Nope
10/18/23, 1:57‚ÄØPM - Amit: Not working
10/18/23, 4:09‚ÄØPM - Siddharth: https://play.google.com/store/apps/details?id=com.fireshooters.joke&hl=en_GB
10/18/23, 4:17‚ÄØPM - Amit: <Media omitted>
10/18/23, 4:18‚ÄØPM - Siddharth: Will do, joke funny chhe?
10/18/23, 4:18‚ÄØPM - Amit: Bdha to funny nai hoy
10/18/23, 4:18‚ÄØPM - Siddharth: Majority?
10/18/23, 4:18‚ÄØPM - Amit: Te je GitHub link mokali hati ne emathi j lidhi chhe
10/18/23, 4:18‚ÄØPM - Amit: Ha
10/18/23, 4:19‚ÄØPM - Siddharth: Haaan to okay
10/18/23, 5:12‚ÄØPM - Siddharth: https://youtube.com/shorts/hwaJrJbXycA?si=OPt_ovmppt2HM4YP
10/18/23, 5:35‚ÄØPM - Siddharth: Apps:

Video Compression
Image Compression
Image format converter
Quotes app
Video sound enhancer
WhatsApp status cutter (Split video in small videos)
Currency converter app
Invoice maker
Multiple dictionary apps
Recipe app (not GPT, via database, we may make database with GPT)
Indian recipe app
Unit converter
QR Scanner
QR generator
Coin toss app
10/18/23, 5:35‚ÄØPM - Siddharth: Bija bol
10/18/23, 5:37‚ÄØPM - Amit: Bro pela aatli to banavi leva de üòÇ
10/18/23, 5:37‚ÄØPM - Siddharth: Barabar chhe ne list?
Now I have idea, call when free
10/18/23, 5:37‚ÄØPM - Amit: Ok
10/18/23, 5:38‚ÄØPM - Amit: Hu tane half and hour ma karu call
10/18/23, 5:46‚ÄØPM - Siddharth: Few more by Jeni:

Area and volume calculator
Properties calculator like stress, strain etc.
Periodic table
Metal property table like strength, hardness, ductility and all
Audio extractor from video
Ringtone maker
10/19/23, 9:00‚ÄØAM - Siddharth: Mokal link
10/19/23, 9:00‚ÄØAM - Amit: Wait mokalu
10/19/23, 9:02‚ÄØAM - Amit: https://meet.google.com/ewu-aupk-zdm
10/19/23, 9:02‚ÄØAM - Siddharth: 1 min
10/19/23, 9:49‚ÄØAM - Siddharth: Thayu ke nai studio?
10/19/23, 9:50‚ÄØAM - Amit: still installing.
10/19/23, 9:51‚ÄØAM - Siddharth: <Media omitted>
10/19/23, 9:52‚ÄØAM - Amit: Ha. Jo bg remover and editor banavie to stripe to add karvu j padshe.
10/19/23, 9:52‚ÄØAM - Siddharth: Haan e j
10/19/23, 9:52‚ÄØAM - Amit: aama only ad revenue no chale
10/19/23, 9:53‚ÄØAM - Siddharth: Haan, basic bg remover can work on normal phone but powerful need GPUs
10/19/23, 9:54‚ÄØAM - Siddharth: Free image background remover android launch karvu chhe?
10/19/23, 9:55‚ÄØAM - Amit: Try kari shakay.
But Javascript ma chhe library?
10/19/23, 9:55‚ÄØAM - Siddharth: I can try atleast, it can be great app
10/19/23, 9:55‚ÄØAM - Amit: Aapne to kai kharcho nathi etle free chale.
10/19/23, 9:56‚ÄØAM - Siddharth: Haan
10/19/23, 9:56‚ÄØAM - Amit: And plus ema add revenue pan saro thashe
10/19/23, 9:56‚ÄØAM - Amit: because of high downloads
10/19/23, 9:56‚ÄØAM - Siddharth: And most imp, aa aakhu paid walu image platform launch karie etle audience mali jaay
10/19/23, 9:56‚ÄØAM - Amit: Ha
10/19/23, 9:56‚ÄØAM - Amit: Try kari shakay jo Java Script ma koi lbrary hoy to
10/19/23, 9:56‚ÄØAM - Siddharth: Chal, hu karu try pela core JS thi, pachhi cordova ma
10/19/23, 9:57‚ÄØAM - Siddharth: And average result pan chale free app ma (obv paid ma to deep learning approach aave pan ahiya nai)
10/19/23, 9:57‚ÄØAM - Amit: Ha free hoy etle joi complaint pan na kari shake
10/19/23, 9:57‚ÄØAM - Siddharth: Haan
10/19/23, 10:58‚ÄØAM - Amit: TCS ma use deactive aave chhe ne?
10/19/23, 10:58‚ÄØAM - Amit: user*
10/19/23, 10:58‚ÄØAM - Siddharth: Haan
10/19/23, 10:58‚ÄØAM - Siddharth: E nai thay change bhaiii
10/19/23, 10:58‚ÄØAM - Amit: Maybe e mail juniors mate hashe
10/19/23, 10:58‚ÄØAM - Siddharth: Haan, evu j lage chhe
10/19/23, 10:58‚ÄØAM - Amit: ok
10/19/23, 10:58‚ÄØAM - Siddharth: Studio?
10/19/23, 10:58‚ÄØAM - Amit: Re installing
10/19/23, 10:59‚ÄØAM - Siddharth: Okay
10/19/23, 10:59‚ÄØAM - Amit: <Media omitted>
10/19/23, 10:59‚ÄØAM - Siddharth: Cool
10/19/23, 11:22‚ÄØAM - Amit: <Media omitted>
10/19/23, 11:41‚ÄØAM - Siddharth: But Emulator not required for us
10/19/23, 11:41‚ÄØAM - Siddharth: Copy error and send plz
10/19/23, 11:44‚ÄØAM - Amit: Android Emulator, Google APIs Intel x86_64 Atom 
System Image and 3 more SDK components were not 
installed
10/19/23, 11:44‚ÄØAM - Siddharth: You selected Emulator while installing?
10/19/23, 11:44‚ÄØAM - Amit: no
10/19/23, 11:45‚ÄØAM - Siddharth: To to issue naa aavo joie, karu check
10/19/23, 11:45‚ÄØAM - Amit: pan cancel kari dav to
10/19/23, 11:45‚ÄØAM - Siddharth: Show details button chhe?
10/19/23, 11:45‚ÄØAM - Amit: java.io.IOException: Connection closed at byte 
4456416. Expected 333020049 bytes.

Warning: An error occurred while preparing SDK 
package Android Emulator: Connection closed at 
byte 4456416. Expected 333020049 bytes..

java.io.IOException: Connection closed at byte 
6553552. Expected 1541568459 bytes.

Warning: An error occurred while preparing SDK 
package Google APIs Intel x86_64 Atom System 
Image: Connection closed at byte 6553552. Expected 
1541568459 bytes..
java.io.IOException: Connection closed at byte 
4456416. Expected 53812451 bytes.

Warning: An error occurred while preparing SDK 
package Sources for Android 34: Connection closed 
at byte 4456416. Expected 53812451 bytes..

java.io.IOException: Connection closed at byte 
2359280. Expected 63180079 bytes.

Warning: An error occurred while preparing SDK 
package Android SDK Platform 34: Connection closed 
at byte 2359280. Expected 63180079 bytes..

java.io.IOException: Connection closed at byte 
4456416. Expected 58253258 bytes.

Warning: An error occurred while preparing SDK 
package Android SDK Build-Tools 34: Connection 
closed at byte 4456416. Expected 58253258 bytes..
10/19/23, 11:46‚ÄØAM - Amit: Pan cancel kari dav to nai chale?
10/19/23, 11:46‚ÄØAM - Amit: kamnu install to thai gayu chhe
10/19/23, 11:46‚ÄØAM - Siddharth: Haan chale
10/19/23, 11:46‚ÄØAM - Siddharth: Try kar, Cordova work kare ke nai
10/19/23, 11:46‚ÄØAM - Siddharth: Nai to meet ma aavie
10/19/23, 11:46‚ÄØAM - Amit: <Media omitted>
10/19/23, 11:47‚ÄØAM - Siddharth: Cordova try kar ne
10/19/23, 11:48‚ÄØAM - Amit: Same error
10/19/23, 11:48‚ÄØAM - Siddharth: Meet?
10/19/23, 11:48‚ÄØAM - Amit: ha
10/19/23, 11:49‚ÄØAM - Amit: wait joning in 2 min
10/19/23, 11:49‚ÄØAM - Siddharth: Okay, join kare etle msg kar
10/19/23, 11:52‚ÄØAM - Amit: Joined
10/19/23, 11:52‚ÄØAM - Siddharth: Aayo
10/19/23, 12:12‚ÄØPM - Siddharth: Thayu kai progress?
10/19/23, 12:14‚ÄØPM - Amit: Still installing
10/19/23, 12:14‚ÄØPM - Siddharth: Okay, same screen ke kai aagal thayu?
10/19/23, 12:15‚ÄØPM - Amit: <Media omitted>
10/19/23, 12:15‚ÄØPM - Siddharth: Copy kari mokal
10/19/23, 12:16‚ÄØPM - Amit: Preparing "Install Sources for Android 34 (revision 1)".
Downloading https://dl.google.com/android/repository/sources-34_r01.zip
java.io.IOException: Connection closed at byte 2097136. Expected 49356035 bytes.
Warning: An error occurred while preparing SDK package Sources for Android 34: Connection closed at byte 2097136. Expected 49356035 bytes..
"Install Sources for Android 34 (revision 1)" failed.
Preparing "Install Android SDK Platform 34 (revision 2)".
Downloading https://dl.google.com/android/repository/platform-34-ext7_r02.zip
java.io.IOException: Connection closed at byte 4194272. Expected 60820799 bytes.
Warning: An error occurred while preparing SDK package Android SDK Platform 34: Connection closed at byte 4194272. Expected 60820799 bytes..
"Install Android SDK Platform 34 (revision 2)" failed.
Preparing "Install Android SDK Build-Tools 34 v.34.0.0".
Downloading https://dl.google.com/android/repository/build-tools_r34-windows.zip
10/19/23, 12:16‚ÄØPM - Amit: Maybe android 34 mara ma nai chaltu hoy because of system requirements?
10/19/23, 12:17‚ÄØPM - Siddharth: Stop this, run android studio as admin, start same process
10/19/23, 12:17‚ÄØPM - Amit: ok
10/19/23, 12:17‚ÄØPM - Siddharth: And one more step
10/19/23, 12:18‚ÄØPM - Siddharth: delete uncompleted download in "[Android SDK folder]\.downloadIntermediates"
10/19/23, 12:18‚ÄØPM - Siddharth: After this, start process
10/19/23, 12:18‚ÄØPM - Amit: ok
10/19/23, 12:18‚ÄØPM - Siddharth: Appdata local android sdk ma hashe
10/19/23, 12:19‚ÄØPM - Amit: <Media omitted>
10/19/23, 12:20‚ÄØPM - Siddharth: Jou wait
10/19/23, 12:20‚ÄØPM - Siddharth: C:\Users\youruser\.android\cache
10/19/23, 12:20‚ÄØPM - Siddharth: ema jo
10/19/23, 12:20‚ÄØPM - Amit: ok
10/19/23, 12:21‚ÄØPM - Amit: <Media omitted>
10/19/23, 12:22‚ÄØPM - Siddharth: Hidden?
10/19/23, 12:22‚ÄØPM - Amit: no
10/19/23, 12:22‚ÄØPM - Siddharth: To no issue, start studio as admin and do it
10/19/23, 12:22‚ÄØPM - Amit: ok
10/19/23, 12:25‚ÄØPM - Amit: started installing
10/19/23, 12:31‚ÄØPM - Amit: <Media omitted>
10/19/23, 12:51‚ÄØPM - Siddharth: SDK version kayu chhe?
10/19/23, 12:52‚ÄØPM - Amit: no idea.
Android 34 chhe
10/19/23, 12:52‚ÄØPM - Siddharth: Also, android studio jo install noto thato to open kem no thy chhe?
10/19/23, 12:54‚ÄØPM - Amit: Android studion ma to emulator and boja 2 SDK package install nota thaya. Baki biju badhu to thai gayu hatu. Etle open to thay chhe pan SDK pelu install nathi thayu ne etle adhuru chhe
10/19/23, 12:54‚ÄØPM - Siddharth: Jova de mane chal
10/19/23, 1:07‚ÄØPM - Siddharth: Taaru net kevu chhe?
10/19/23, 1:07‚ÄØPM - Siddharth: Because io error kadach net disconnect na lidhe hoy
10/19/23, 1:07‚ÄØPM - Amit: Disconnect to nathi thayu but thodu slow chhe
10/19/23, 1:07‚ÄØPM - Siddharth: Achcha, jou wait
10/19/23, 1:08‚ÄØPM - Amit: Haal installing chalu rakhyu chhe jya sudhi koi error na aave tya sudhi
10/19/23, 1:08‚ÄØPM - Siddharth: SDK, Android studio banne delete kar, fresh start aap puro jo have error aave to
10/19/23, 1:08‚ÄØPM - Amit: Jo aa installing no thay to complete restart kari laish
10/19/23, 1:09‚ÄØPM - Siddharth: Haan
10/19/23, 2:37‚ÄØPM - Siddharth: Update?
10/19/23, 3:42‚ÄØPM - Siddharth: Update?
10/19/23, 4:09‚ÄØPM - Amit: No thyau.
Have restart karvanu chhe aakhu.


Atyre baar chhu ghare jaine karu.
10/19/23, 4:12‚ÄØPM - Siddharth: Na, bijo idea chhe, call karje
10/19/23, 4:18‚ÄØPM - Amit: Pan me already badhu delete kari dishu chhe
10/19/23, 4:19‚ÄØPM - Amit: Have nave thi j install karvu padshe
10/19/23, 4:19‚ÄØPM - Siddharth: Haan to kar, aaje karvu chhe setup
10/19/23, 4:19‚ÄØPM - Amit: Ha
10/19/23, 6:49‚ÄØPM - Amit: This time some new things are installing.

Maybe aa vakhte thai jate
10/19/23, 6:57‚ÄØPM - Amit: <Media omitted>
10/19/23, 6:58‚ÄØPM - Siddharth: Dinner pachhi karie
10/19/23, 6:58‚ÄØPM - Amit: ok
10/19/23, 6:58‚ÄØPM - Siddharth: Dhaivat ne pan meet nu kai de, Nandu ne time puchhi
10/19/23, 7:15‚ÄØPM - Amit: Dinner kari le pachhi Dhaivat sathe meet chhe.
10/19/23, 7:15‚ÄØPM - Amit: Nandu garba ma javano chhe 7:30 e
10/19/23, 7:24‚ÄØPM - Siddharth: Okay
10/19/23, 7:26‚ÄØPM - Amit: Mokalu link?
10/19/23, 7:26‚ÄØPM - Siddharth: Dhaivat?
10/19/23, 7:27‚ÄØPM - Amit: E ready j chhe.
Tu dinner kari le eni j rah hati
10/19/23, 7:27‚ÄØPM - Siddharth: Dinner done, mokal link
10/19/23, 7:27‚ÄØPM - Amit: Ok
10/19/23, 7:34‚ÄØPM - Siddharth: App ideas:

Hindi stories
English stories
Kabir ke dohe
Horror stories
Math riddles
Logical riddles 
Hindi jokes
Hindi recipes
Hindi quotes
10/19/23, 8:58‚ÄØPM - Siddharth: Update?
10/19/23, 8:58‚ÄØPM - Amit: bas download thay chhe SDK ne baki badhu
10/19/23, 8:58‚ÄØPM - Amit: <Media omitted>
10/19/23, 8:58‚ÄØPM - Amit: ?
10/19/23, 8:58‚ÄØPM - Siddharth: üëç
10/19/23, 8:59‚ÄØPM - Amit: aa to pela pan aavelu
10/19/23, 8:59‚ÄØPM - Amit: I guess aa vakhte thai jay to saru
10/19/23, 9:00‚ÄØPM - Siddharth: Haan thava de
10/19/23, 9:18‚ÄØPM - Siddharth: Thayu?
10/19/23, 9:19‚ÄØPM - Amit: Installing
10/19/23, 9:19‚ÄØPM - Siddharth: Okay
10/19/23, 9:33‚ÄØPM - Amit: I need your review for MS in AI at Northeaster University, Boston campus
10/19/23, 9:33‚ÄØPM - Siddharth: Jou kale
10/19/23, 9:33‚ÄØPM - Amit: Northeastern University, Boston
10/19/23, 9:33‚ÄØPM - Amit: Joine jalde keje.
It's urgent
10/19/23, 9:34‚ÄØPM - Siddharth: Kale chalshe ne?
10/19/23, 9:34‚ÄØPM - Amit: ha kale chalshe
10/19/23, 9:34‚ÄØPM - Siddharth: Okay
10/19/23, 9:34‚ÄØPM - Amit: But please honest review.
10/19/23, 9:34‚ÄØPM - Siddharth: Haan
10/19/23, 9:50‚ÄØPM - Amit: Failing
10/19/23, 9:51‚ÄØPM - Amit: <Media omitted>
10/19/23, 9:51‚ÄØPM - Amit: Ek kam kar have tu SDK ne upload karine drive link mane mokal
10/19/23, 9:51‚ÄØPM - Amit: Hu ene unzip karine path ma set kari daish.
10/19/23, 9:55‚ÄØPM - Siddharth: Okay
10/20/23, 8:30‚ÄØAM - Amit: SDK folder ni drive link send karje etle hu path set kari dav
10/20/23, 8:30‚ÄØAM - Amit: ASAP
10/20/23, 8:30‚ÄØAM - Siddharth: Not possible, death in family
10/20/23, 8:30‚ÄØAM - Siddharth: No laptop for day
10/20/23, 8:31‚ÄØAM - Amit: Kon?
10/20/23, 8:31‚ÄØAM - Siddharth: Dada na bhai
10/20/23, 8:31‚ÄØAM - Amit: ohhh.
10/20/23, 8:31‚ÄØAM - Siddharth: Matlab dada j
10/20/23, 8:31‚ÄØAM - Amit: ok no problem
10/20/23, 8:31‚ÄØAM - Siddharth: Ratre moklu
10/20/23, 8:32‚ÄØAM - Amit: Vandho nai
10/21/23, 11:05‚ÄØAM - Amit: Ghare?
10/21/23, 1:45‚ÄØPM - Siddharth: Haal pahochyo
10/21/23, 4:06‚ÄØPM - Amit: To peli SDK file upload karine drive link mokalje
10/21/23, 8:27‚ÄØPM - Amit: Any suggestions?
10/21/23, 8:28‚ÄØPM - Siddharth: Are haji busy j chhu
10/21/23, 8:28‚ÄØPM - Amit: Ok no p
10/21/23, 8:28‚ÄØPM - Amit: No problem*
10/22/23, 2:54‚ÄØPM - Amit: Tu peli drive link mokalje ne sdk ni
10/22/23, 2:54‚ÄØPM - Amit: Aaje hu set kari dav cordova
10/22/23, 2:55‚ÄØPM - Amit: Raja chhe to
10/22/23, 4:49‚ÄØPM - Siddharth: Okay
10/22/23, 5:39‚ÄØPM - Siddharth: https://drive.google.com/file/d/14DZJoKCiRV7mfB9vJKTvfQ5kBZ1T_A1K/view?usp=share_link
10/23/23, 10:42‚ÄØAM - Amit: SDK folder mathi kya kya folder na path set karvana chhe?
10/23/23, 10:43‚ÄØAM - Siddharth: Meet maa aav 10 min pachhi
10/23/23, 10:43‚ÄØAM - Amit: Ok
10/23/23, 10:51‚ÄØAM - Amit: Ready tha etle keje link mokalu
10/23/23, 10:51‚ÄØAM - Siddharth: Haan, haal meet ma chhu, kau tane
10/23/23, 11:06‚ÄØAM - Siddharth: <Media omitted>
10/23/23, 11:06‚ÄØAM - Amit: ok
10/23/23, 11:06‚ÄØAM - Siddharth: Try kari ke mane
10/23/23, 11:06‚ÄØAM - Amit: ha
10/23/23, 11:06‚ÄØAM - Siddharth: Btw, tare apps nai banavvani have, pan set kari de atleast
10/23/23, 11:07‚ÄØAM - Amit: ha
10/23/23, 11:07‚ÄØAM - Siddharth: Code part khali hu j manage karish, because biju kai kaam nai thai rahyu etle tamne 4 loko ne proper work assign thai jashe

Aaje ratre meet
10/23/23, 11:51‚ÄØAM - Siddharth: Thayu?
10/23/23, 11:52‚ÄØAM - Amit: ha. requirements satisfy thai gai. build thava mukyu chhe
10/23/23, 11:52‚ÄØAM - Siddharth: Okay
10/23/23, 11:56‚ÄØAM - Siddharth: Reddit joke json mokal
10/23/23, 11:59‚ÄØAM - Amit: <Media omitted>
10/23/23, 1:19‚ÄØPM - Siddharth: Update?
10/23/23, 1:58‚ÄØPM - Amit: <Media omitted>
10/23/23, 1:58‚ÄØPM - Amit: Mare java jdk version 1.8 chhe
10/23/23, 1:59‚ÄØPM - Amit: tare kayu chhe?
10/23/23, 1:59‚ÄØPM - Siddharth: How to check?
10/23/23, 2:00‚ÄØPM - Amit: java -version
10/23/23, 2:00‚ÄØPM - Amit: java version "1.8.0_381"
10/23/23, 2:00‚ÄØPM - Siddharth: 1.8 j chhe
10/23/23, 2:00‚ÄØPM - Siddharth: Copy paste error plz
10/23/23, 2:01‚ÄØPM - Amit: A problem occurred configuring root project 'HelloWorld'.
> Could not resolve all files for configuration ':classpath'.
   > Could not resolve com.android.tools.build:gradle:7.4.2.
     Required by:
         project :
      > No matching variant of com.android.tools.build:gradle:7.4.2 was found. The consumer was configured to find a runtime of a library compatible with Java 8, packaged as a jar, and its dependencies declared externally, as well as attribute 'org.gradle.plugin.api-version' with value '7.6' but:
          - Variant 'apiElements' capability com.android.tools.build:gradle:7.4.2 declares a library, packaged as a jar, and its dependencies declared externally:
              - Incompatible because this component declares an API of a component compatible with Java 11 and the consumer needed a runtime of a component compatible with Java 8
              - Other compatible attribute:
                  - Doesn't say anything about org.gradle.plugin.api-version (required '7.6')
          - Variant 'javadocElements' capability com.android.tools.build:gradle:7.4.2 declares a runtime of a component, and its dependencies declared externally:
              - Incompatible because this component declares documentation and the consumer needed a library
              - Other compatible attributes:
                  - Doesn't say anything about its target Java version (required compatibility with Java 8)
                  - Doesn't say anything about its elements (required them packaged as a jar)
                  - Doesn't say anything about org.gradle.plugin.api-version (required '7.6')
          - Variant 'runtimeElements' capability com.android.tools.build:gradle:7.4.2 declares a runtime of a library, packaged as a jar, and its dependencies declared externally:
              - Incompatible because this component declares a component compatible with Java 11 and the consumer needed a component compatible with Java 8
              - Other compatible attribute:
                  - Doesn't say anything about org.gradle.plugin.api-version (required '7.6')
          - Variant 'sourcesElements' capability com.android.tools.build:gradle:7.4.2 declares a runtime of a component, and its dependencies declared externally:
              - Incompatible because this component declares documentation and the consumer needed a library
              - Other compatible attributes:
                  - Doesn't say anything about its target Java version (required compatibility with Java 8)
                  - Doesn't say anything about its elements (required them packaged as a jar)
                  - Doesn't say anything about org.gradle.plugin.api-version (required '7.6')
10/23/23, 2:01‚ÄØPM - Amit: ANDROID_HOME=undefined (recommended setting)
ANDROID_SDK_ROOT=undefined (DEPRECATED)

Tare aa be variable   set chhe path ma?
10/23/23, 2:01‚ÄØPM - Siddharth: That is normal, e to e j aave
10/23/23, 2:01‚ÄØPM - Amit: ok
10/23/23, 2:05‚ÄØPM - Siddharth: build.gradle file jo
10/23/23, 2:06‚ÄØPM - Siddharth: Tya kaik issue lage chhe
10/23/23, 2:06‚ÄØPM - Amit: project ni andar?
10/23/23, 2:07‚ÄØPM - Siddharth: Haan
Project -> Platform -> Android
10/23/23, 2:07‚ÄØPM - Siddharth: classpath "com.android.tools.build:gradle:${cordovaConfig.AGP_VERSION}"


Ne replace kar with

classpath "com.android.tools.build:gradle:7.6"
10/23/23, 2:08‚ÄØPM - Amit: aa ek j class path change karvano chhe ne?
10/23/23, 2:08‚ÄØPM - Siddharth: yup
10/23/23, 2:09‚ÄØPM - Amit: done
10/23/23, 2:09‚ÄØPM - Amit: re build?
10/23/23, 2:09‚ÄØPM - Siddharth: yup
10/23/23, 2:10‚ÄØPM - Amit: <Media omitted>
10/23/23, 2:11‚ÄØPM - Amit: <Media omitted>
10/23/23, 2:12‚ÄØPM - Siddharth: Haan to pan e j error hati ne

Ek kaam kar, Android ma .gradle folder hashe eno SS MOKAL
10/23/23, 2:12‚ÄØPM - Amit: <Media omitted>
10/23/23, 2:14‚ÄØPM - Siddharth: 7.6 chhe to khara
10/23/23, 2:14‚ÄØPM - Amit: ha. eto me pela check karyu tu
10/23/23, 2:15‚ÄØPM - Siddharth: Jova de
10/23/23, 2:18‚ÄØPM - Amit: ek kam karto tara project ni zip mokal to.
E unzip karine try kari lav. Because aa project jyare android studio set karta hata e pelanu chhe etle
10/23/23, 2:19‚ÄØPM - Siddharth: <Media omitted>
10/23/23, 2:24‚ÄØPM - Amit: same error
10/23/23, 2:24‚ÄØPM - Siddharth: Some issue with gradle 
Need to check
10/23/23, 2:25‚ÄØPM - Siddharth: Send this
10/23/23, 2:25‚ÄØPM - Amit: FAILURE: Build failed with an exception.
> Connecting to Daemon
* What went wrong:
A problem occurred configuring root project 'HelloWorld'.
> Could not resolve all files for configuration ':classpath'.
   > Could not find com.android.tools.build:gradle:7.6.
     Searched in the following locations:
       - https://dl.google.com/dl/android/maven2/com/android/tools/build/gradle/7.6/gradle-7.6.pom
       - https://repo.maven.apache.org/maven2/com/android/tools/build/gradle/7.6/gradle-7.6.pom
     Required by:
         project :
10/23/23, 2:26‚ÄØPM - Siddharth: Looks like I know issue
10/23/23, 2:29‚ÄØPM - Siddharth: C:\Users\<your_username>\.gradle\caches

Aa folder chhe?
10/23/23, 2:29‚ÄØPM - Siddharth: Hidden pan check karje
10/23/23, 2:30‚ÄØPM - Amit: yes
10/23/23, 2:30‚ÄØPM - Siddharth: Delete it and try again
10/23/23, 2:32‚ÄØPM - Amit: <Media omitted>
10/23/23, 2:33‚ÄØPM - Siddharth: It means phone is not properly connected with PC
10/23/23, 2:33‚ÄØPM - Siddharth: USB debugging on chhe?
10/23/23, 2:34‚ÄØPM - Amit: ha but let me check
10/23/23, 2:34‚ÄØPM - Siddharth: Build start thay etle phone ma pop up aavvu joie
10/23/23, 2:34‚ÄØPM - Siddharth: USB allow mate nu
10/23/23, 2:36‚ÄØPM - Amit: <Media omitted>
10/23/23, 2:36‚ÄØPM - Amit: on j chhe
10/23/23, 2:36‚ÄØPM - Siddharth: .
10/23/23, 2:37‚ÄØPM - Amit: no pop up direct error
10/23/23, 2:37‚ÄØPM - Siddharth: Send error
10/23/23, 2:37‚ÄØPM - Amit: * What went wrong:
A problem occurred evaluating root project 'HelloWorld'.
> java.util.concurrent.ExecutionException: org.gradle.api.GradleException: Failed to create Jar file C:\Users\admin\.gradle\caches\jars-9\5e3a236f0f69ba1604cfba4a87b07728\versioncompare-1.4.1.jar.
10/23/23, 2:39‚ÄØPM - Amit: <Media omitted>
10/23/23, 2:39‚ÄØPM - Siddharth: Internet issue chhe?
10/23/23, 2:39‚ÄØPM - Amit: no
10/23/23, 2:39‚ÄØPM - Siddharth: Cache delete kari ek vaar try kar
10/23/23, 2:40‚ÄØPM - Amit: cache badha delete nathi thata ho.
File open dekhde chhe
10/23/23, 2:40‚ÄØPM - Amit: restart karine pachhi cache delete karu
10/23/23, 2:40‚ÄØPM - Siddharth: PC restart kari delete kar
10/23/23, 2:44‚ÄØPM - Amit: * What went wrong:
A problem occurred configuring root project 'HelloWorld'.
> Could not resolve all files for configuration ':classpath'.
   > Could not find com.android.tools.build:gradle:7.6.
     Searched in the following locations:
       - https://dl.google.com/dl/android/maven2/com/android/tools/build/gradle/7.6/gradle-7.6.pom
       - https://repo.maven.apache.org/maven2/com/android/tools/build/gradle/7.6/gradle-7.6.pom
     Required by:
         project :
10/23/23, 2:44‚ÄØPM - Amit: same error
10/23/23, 2:44‚ÄØPM - Siddharth: Jou
10/23/23, 2:53‚ÄØPM - Siddharth: Meet?
10/23/23, 2:53‚ÄØPM - Amit: ha link mokal
10/23/23, 2:54‚ÄØPM - Siddharth: Moklu, tu android studio chalu kar
10/23/23, 2:54‚ÄØPM - Siddharth: https://meet.google.com/tvp-gfkc-bqi
10/23/23, 3:23‚ÄØPM - Amit: * What went wrong:
A problem occurred configuring root project 'JokeBox - 15000+ funny jokes'.
> Could not resolve all files for configuration ':classpath'.
   > Could not resolve com.android.tools.build:gradle:7.4.2.
     Required by:
         project :
      > No matching variant of com.android.tools.build:gradle:7.4.2 was found. The consumer was configured to find a runtime of a library compatible with Java 8, packaged as a jar, and its dependencies declared externally, as well as attribute 'org.gradle.plugin.api-version' with value '7.6' but:
          - Variant 'apiElements' capability com.android.tools.build:gradle:7.4.2 declares a library, packaged as a jar, and its dependencies declared externally:
              - Incompatible because this component declares an API of a component compatible with Java 11 and the consumer needed a runtime of a component compatible with Java 8
              - Other compatible attribute:
                  - Doesn't say anything about org.gradle.plugin.api-version (required '7.6')
          - Variant 'javadocElements' capability com.android.tools.build:gradle:7.4.2 declares a runtime of a component, and its dependencies declared externally:
              - Incompatible because this component declares documentation and the consumer needed a library
              - Other compatible attributes:
                  - Doesn't say anything about its target Java version (required compatibility with Java 8)
                  - Doesn't say anything about its elements (required them packaged as a jar)
                  - Doesn't say anything about org.gradle.plugin.api-version (required '7.6')
          - Variant 'runtimeElements' capability com.android.tools.build:gradle:7.4.2 declares a runtime of a library, packaged as a jar, and its dependencies declared externally:
              - Incompatible because this component declares a component compatible with Java 11 and the consumer needed a component compatible with Java 8
              - Other compatible attribute:
                  - Doesn't say anything about org.gradle.plugin.api-version (required '7.6')
          - Variant 'sourcesElements' capability com.android.tools.build:gradle:7.4.2 declares a runtime of a component, and its dependencies declared externally:
              - Incompatible because this component declares documentation and the consumer needed a library
              - Other compatible attributes:
                  - Doesn't say anything about its target Java version (required compatibility with Java 8)
                  - Doesn't say anything about its elements (required them packaged as a jar)
                  - Doesn't say anything about org.gradle.plugin.api-version (required '7.6')
10/23/23, 3:24‚ÄØPM - Siddharth: distributionUrl=https\://services.gradle.org/distributions/gradle-7.6-all.zip
10/24/23, 12:26‚ÄØPM - Amit: Bro aaj launch he to final apk toda jaldi bhej dena taki playstore ke poster banane me ss le sake
10/24/23, 12:27‚ÄØPM - Siddharth: Bhai UI same rahega to wo use karo
10/24/23, 12:27‚ÄØPM - Amit: ok.
10/24/23, 6:08‚ÄØPM - Amit: <Media omitted>
10/24/23, 6:08‚ÄØPM - Amit: <Media omitted>
10/24/23, 6:08‚ÄØPM - Amit: <Media omitted>
10/24/23, 6:09‚ÄØPM - Siddharth: 1,00,000+ kari de
10/24/23, 6:12‚ÄØPM - Amit: Ok.
Call me
10/26/23, 9:05‚ÄØAM - Amit: Jenish and I will work on Twitter. 

I talked with him and we will manage Twitter.
10/26/23, 9:05‚ÄØAM - Siddharth: Okay
10/26/23, 5:58‚ÄØPM - Siddharth: https://youtu.be/IIJ895HYVwY?si=kOzw5Na8rk0YDW7E
10/26/23, 7:46‚ÄØPM - Amit: https://www.instagram.com/reel/Cyu64XZSGeM/?igshid=MzRlODBiNWFlZA==
10/26/23, 7:47‚ÄØPM - Siddharth: Joie chalo
10/29/23, 5:50‚ÄØPM - Amit: Can we change detail page's url from
https://leafylives.in/detail/Rose%20Marie%20Magnolia/334
to
https://leafylives.in/rose-marie-magnolia
10/29/23, 5:51‚ÄØPM - Siddharth: yeah, we can, but indexing will be pushed further late, should not do
10/29/23, 5:51‚ÄØPM - Siddharth: Indexing is extremely slow process.
10/29/23, 5:52‚ÄØPM - Amit: ok. Then we will take care when we push any new url
10/29/23, 5:52‚ÄØPM - Siddharth: Okay
10/29/23, 5:53‚ÄØPM - Siddharth: It is advisable not to change URL pattern because if you change it, entire discovery process starts from point 0 and it can take month or even more
10/29/23, 5:54‚ÄØPM - Amit: But we have to do it for blogs at least.
Because on that page, we need more views than any other page.
10/29/23, 5:55‚ÄØPM - Amit: And it is beneficiary to add your primary keyword in url
10/29/23, 5:56‚ÄØPM - Amit: It will help google to find our page easily
10/29/23, 5:56‚ÄØPM - Siddharth: Okay, let me see what I can do.
Because URLs are automatic means changing pattern will change URL in old blogs too.

And they are already ranked
10/29/23, 5:57‚ÄØPM - Siddharth: But yeah, blogs ma karvu padshe, current URL has 0 and 1, e nai chale.

Word is important
10/29/23, 5:57‚ÄØPM - Amit: I know that.
That's why I am asking you that we can do this or not
10/29/23, 5:58‚ÄØPM - Amit: I will share a keyword for both blogs by end of the day.
10/29/23, 6:00‚ÄØPM - Amit: https://www.monrovia.com/rose-marie-magnolia.html

See this is the first result on google when I search specific flower name.
10/29/23, 6:22‚ÄØPM - Amit: 1. https://leafylives.in/indoor-gardening
2. https://leafylives.in/pet-friendly-plants
10/29/23, 6:22‚ÄØPM - Amit: Blog url suggetions
10/30/23, 10:04‚ÄØAM - Siddharth: https://twitter.com/finegardening

Take blog ideas from here
10/30/23, 5:11‚ÄØPM - Amit: Can we change title tag?
10/30/23, 5:12‚ÄØPM - Siddharth: Shu chhe title?
10/30/23, 5:13‚ÄØPM - Amit: For individual Blogs
10/30/23, 5:13‚ÄØPM - Amit: Currently it is big as per google pixel length
10/30/23, 5:13‚ÄØPM - Siddharth: Kale me ne Nandu e try karyu, nai thati URL change
10/30/23, 5:13‚ÄØPM - Amit: Thinking
10/30/23, 5:14‚ÄØPM - Amit: For Blogs?
10/30/23, 5:14‚ÄØPM - Siddharth: Ame saaro evo time spend karyo pan URL change nai thata figureout
10/30/23, 5:14‚ÄØPM - Siddharth: Haan
10/30/23, 5:14‚ÄØPM - Amit: What about title tag?
10/30/23, 5:15‚ÄØPM - Siddharth: E thashe
Shu karvu e keje, evu hashe to blog matadata thi j kari daishu
10/30/23, 5:15‚ÄØPM - Siddharth: Darek blog nu em saperate thai jashe
10/30/23, 5:15‚ÄØPM - Amit: Ha haal to blog ma j change karvana chhe because ema lengthy chhe etle
10/30/23, 5:15‚ÄØPM - Amit: OK.End of the day tane send karu banne blogs na.
10/30/23, 5:16‚ÄØPM - Siddharth: Okay to karie 1-2 divas ma e, haal pela page indexing par kaam chale chhe
10/30/23, 5:16‚ÄØPM - Siddharth: Okay
10/30/23, 5:16‚ÄØPM - Amit: Hu tane send to kari dav.
Pachhi tu tari rite proper time laine replace kari deje.
10/30/23, 5:16‚ÄØPM - Siddharth: Okay bhai, done
10/31/23, 9:14‚ÄØAM - Siddharth: Bhai
10/31/23, 9:14‚ÄØAM - Siddharth: bhai
10/31/23, 9:14‚ÄØAM - Siddharth: bhai
10/31/23, 9:14‚ÄØAM - Amit: bol
10/31/23, 9:14‚ÄØAM - Siddharth: Call kar jaldi
10/31/23, 9:51‚ÄØAM - Siddharth: Mocha Rose Big Leaf Maple
10/31/23, 9:53‚ÄØAM - Amit: We need to change title and meta tag for each plant. We have to make it dynamically as per plant name
10/31/23, 9:53‚ÄØAM - Siddharth: Okay, aaje sanje karie e
10/31/23, 9:53‚ÄØAM - Amit: It will help us to rank goon on SERP
10/31/23, 9:53‚ÄØAM - Siddharth: SERP?
10/31/23, 9:53‚ÄØAM - Amit: Search Engine Result Page
10/31/23, 9:53‚ÄØAM - Siddharth: Okay
10/31/23, 10:17‚ÄØAM - Siddharth: https://leafy-life.com/

They have traffic of 60000 a month
10/31/23, 10:31‚ÄØAM - Siddharth: https://www.expireddomains.net/expired-domains/
10/31/23, 10:32‚ÄØAM - Amit: ok
10/31/23, 11:00‚ÄØAM - Siddharth: https://home.fandom.com/wiki/Gardening#References

References ma plant care encyclopedia par click kar
10/31/23, 11:05‚ÄØAM - Amit: Redirecting our website?
10/31/23, 11:05‚ÄØAM - Amit: How?
10/31/23, 11:05‚ÄØAM - Siddharth: lol
10/31/23, 11:05‚ÄØAM - Siddharth: I just added it
10/31/23, 11:05‚ÄØAM - Siddharth: It was open for edit so I did
10/31/23, 11:06‚ÄØAM - Siddharth: And domain authority is 91 bhai
10/31/23, 11:06‚ÄØAM - Amit: Great Work üëçüëç
10/31/23, 11:06‚ÄØAM - Siddharth: üòÇ
10/31/23, 8:59‚ÄØPM - Siddharth: If we reach 200 users a day, you will be paying for render, done?
10/31/23, 9:43‚ÄØPM - Amit: Yes.
No problem.
10/31/23, 9:43‚ÄØPM - Amit: Monthly 2000 thi 3000 ma koi problem nathi
10/31/23, 9:44‚ÄØPM - Siddharth: Haan etlu j thashe
10/31/23, 9:44‚ÄØPM - Amit: Vadhare thai to pan vandho nai.
Salary hoy etle chale.
10/31/23, 9:45‚ÄØPM - Siddharth: And revenue aave to growth to exponential
10/31/23, 9:46‚ÄØPM - Amit: Ha bro
10/31/23, 9:47‚ÄØPM - Amit: Bas ek vaar revenue start thay etle team ma badhane confidence aavi jay ke aapne right path par chie
10/31/23, 9:47‚ÄØPM - Siddharth: Haan bhai, e j to
10/31/23, 9:55‚ÄØPM - Siddharth: Yaar 200 a day aave ne 3-4 divas constant aave to pachhi ads nu karie
10/31/23, 10:04‚ÄØPM - Amit: Ha pachhi to start j kari devay.
11/2/23, 7:28‚ÄØPM - Amit: https://huggingface.co/spaces/AP123/IllusionDiffusion
11/2/23, 7:28‚ÄØPM - Amit: Bro pls check karine kene ke aani API work kare chhe ke nai
11/2/23, 7:28‚ÄØPM - Siddharth: Half hr aap
11/2/23, 8:35‚ÄØPM - Amit: Working?
11/2/23, 8:35‚ÄØPM - Siddharth: Model to ghani vaar vapryu chhe past ma, haal check karu
11/2/23, 8:40‚ÄØPM - Siddharth: Load bau batave chhe, not working
11/2/23, 8:50‚ÄØPM - Amit: Ok
11/2/23, 8:51‚ÄØPM - Siddharth: Bhai, working now
11/2/23, 8:51‚ÄØPM - Amit: Py file mokal ne mane
11/2/23, 8:52‚ÄØPM - Siddharth: Py file nathi, main to sidha link ma run karyu
11/2/23, 8:52‚ÄØPM - Amit: Link ma to me try karyu tu.
Eni Python ma API work kare chhe ke nai e check karvu hatu
11/2/23, 8:56‚ÄØPM - Siddharth: SD to mara machine par na run thay vroo
11/2/23, 8:56‚ÄØPM - Siddharth: Very heavy
11/2/23, 8:57‚ÄØPM - Amit: Ok no problem
11/3/23, 4:32‚ÄØPM - Siddharth: Aa jo jara: (copy paste)

How to build shit that pops üëá

1. Find successful app on the store

2. Does app have technical moat? If yes, find another app

3. Is the app fun? Does it leverage a core human driver (lust, greed, anger, social validation)? Can it capture attention within 2 seconds of an ad playing? If no, find another idea

 4. If the app has been around in the store for long, it‚Äôs likely bloated. Figure out what the core loop is, from user activation to monetisation

5. Get rid of all other features

6. Take the core loop, boil it down to two features. Figure out how to build them in less than 2 weeks. If you can‚Äôt, simplify the idea until you can

7. Take the monetisation model, convert it to a simple subscription paywall

8. Add paywall between the two features

9. Add user onboarding, followed by paywall, followed by rating screen

10. Research high-volume keywords. Focus on 1-2

11. Remove or largely diminish monetisation for the first 3-4 days. Run ads. Keep doing that until you have a solid number of reviews and you get indexed for the keyword you chose

12. Crank up the monetisation until reviews start to suffer. Balance it out at ~4 stars

13. Drop the ads, see if the app floats on its own
11/3/23, 5:11‚ÄØPM - Siddharth: https://youtube.com/shorts/Yh9ru9hSQ8A?si=E1gS68FmtWlWFXvE
11/3/23, 5:14‚ÄØPM - Amit: Aa joi me
11/3/23, 5:14‚ÄØPM - Amit: Flow saro lage chhe reading thi
11/3/23, 5:15‚ÄØPM - Siddharth: Something we can build but difficult to market.

For now, ads is best for us, atleast for first 5000 USD a month
11/3/23, 5:15‚ÄØPM - Siddharth: Bhai, we need to reach 5000 fast
11/3/23, 5:16‚ÄØPM - Siddharth: 5000 USD is minimum to even plan office
11/3/23, 5:17‚ÄØPM - Amit: SEO ma direct traffic nahi aave. Saro evo time leshe top rank par aavva mate
11/3/23, 5:17‚ÄØPM - Siddharth: Bijo koi rasto?
11/3/23, 5:19‚ÄØPM - Amit: False traffic to nathi dekhadvo ne?
11/3/23, 5:20‚ÄØPM - Siddharth: Na
11/3/23, 5:20‚ÄØPM - Siddharth: False traffic thi paisa naa aave
11/3/23, 5:22‚ÄØPM - Amit: I know paisa no aave but starting ma users to aave traffic hoy to ans SERP ma pan ghani help thay jo traffic hoy to. 
But jo search engine ne khabar pade to blocklist pan kari de.
11/3/23, 5:22‚ÄØPM - Siddharth: Haan, e risk na levay
11/3/23, 5:22‚ÄØPM - Amit: üíØ
11/3/23, 5:23‚ÄØPM - Siddharth: Time lage e nai chale, vicharo
11/3/23, 5:24‚ÄØPM - Amit: What about ek YouTube channel start karine em AI generated content push karta jaie. And aapni channel pan aapne aani j products ni videos pan puch kari shakishu.
11/3/23, 5:24‚ÄØPM - Siddharth: Karo try
11/3/23, 5:25‚ÄØPM - Amit: Niche decide karvu padshe channel mate
11/3/23, 5:25‚ÄØPM - Siddharth: Plants j ne
11/3/23, 5:25‚ÄØPM - Amit: Informative rakhvi chhe ke entertainment?
11/3/23, 5:26‚ÄØPM - Siddharth: Info
11/3/23, 5:26‚ÄØPM - Amit: Pan hu Cocoden mate channel suggest karu chhu not only for Leafy Lives
11/3/23, 5:27‚ÄØPM - Siddharth: We going by name Burst Neuron
11/3/23, 5:27‚ÄØPM - Amit: Ok. To BN ni channel chhe j ema j push karvana start karie to?
11/3/23, 5:34‚ÄØPM - Siddharth: Chale
11/3/23, 5:39‚ÄØPM - Amit: Discuss karie Nandu saathe aa vaat
11/3/23, 5:39‚ÄØPM - Siddharth: Okay, msg drop kar ene, ask time
11/8/23, 4:25‚ÄØPM - Siddharth: Bhai
11/8/23, 4:26‚ÄØPM - Amit: Bil
11/8/23, 4:26‚ÄØPM - Amit: Bol
11/8/23, 4:29‚ÄØPM - Siddharth: Prod ma updates chhe, badha features check kar
11/8/23, 4:29‚ÄØPM - Amit: Ok
11/8/23, 4:31‚ÄØPM - Amit: Working fine
11/8/23, 4:44‚ÄØPM - Siddharth: Check everything about programmatic seo
11/8/23, 5:32‚ÄØPM - Amit: Atyre vaal kapava aavyo chhu.
Ghare jaine check kari lav
11/9/23, 12:00‚ÄØPM - Amit: You deleted this message
11/9/23, 12:00‚ÄØPM - Amit: You deleted this message
11/9/23, 1:04‚ÄØPM - Amit: <Media omitted>
11/15/23, 10:45‚ÄØAM - Siddharth: Mumbai?
11/15/23, 11:10‚ÄØAM - Amit: Mare nai mel pade 15 thi 20 sudhi
11/15/23, 11:11‚ÄØAM - Amit: Mare bije javanu chhe family sathe etle
11/21/23, 4:53‚ÄØPM - Amit: Blog vali .py file mokal ne
11/21/23, 4:54‚ÄØPM - Siddharth: <Media omitted>
11/21/23, 5:54‚ÄØPM - Amit: <Media omitted>
11/21/23, 5:54‚ÄØPM - Amit: blog added
11/21/23, 6:18‚ÄØPM - Siddharth: How many?
11/21/23, 6:28‚ÄØPM - Amit: 1
11/21/23, 6:28‚ÄØPM - Amit: Bakina karu chhu
11/21/23, 6:35‚ÄØPM - Siddharth: 1-1 prod ma na nakhi shakhu vroo

Sitemap banavvo, multiple submission, priority indexing ne Biju ghanu hoy chhe

Atleast 4 blogs at a time
11/21/23, 6:36‚ÄØPM - Siddharth: And blog tu nai kare to chalshe, focus on backlink
11/21/23, 6:36‚ÄØPM - Amit: Np problem.
11/22/23, 1:48‚ÄØPM - Amit: Bro need some time for backlinks.

Going Hospital with mom
11/22/23, 1:48‚ÄØPM - Siddharth: Okay
11/22/23, 1:48‚ÄØPM - Siddharth: Shu thayu?
11/22/23, 1:49‚ÄØPM - Amit: Arre pag ma dukhe chhe to batava mate jav chhu
11/22/23, 1:49‚ÄØPM - Siddharth: Okay okay
11/22/23, 2:30‚ÄØPM - Siddharth: <Media omitted>
11/22/23, 2:31‚ÄØPM - Amit: 733 Indexed üëçüëè
11/22/23, 9:26‚ÄØPM - Amit: Vande bharat ma breakfast and lunch book karvu pade ke ticket ma include hoy?
11/22/23, 9:26‚ÄØPM - Siddharth: Change hoy chhe etle ticket ma check kari levanu
11/22/23, 9:26‚ÄØPM - Amit: Change means?
11/22/23, 9:27‚ÄØPM - Siddharth: Means ghana routes ma nathi, etle change hoi shake
11/22/23, 9:27‚ÄØPM - Amit: Tare include hatu?
11/22/23, 9:27‚ÄØPM - Siddharth: Yup
Sanj ni hati train etle evening snacks, tea e badhu hatu
11/22/23, 9:28‚ÄØPM - Amit: Kyathi kya ni hati?
11/22/23, 9:28‚ÄØPM - Siddharth: Gandhinagar - Surat
11/22/23, 9:35‚ÄØPM - Amit: Tare CC hatu ke EC?
11/22/23, 9:35‚ÄØPM - Siddharth: CC means normal ne?
11/22/23, 9:35‚ÄØPM - Siddharth: EC Executive?
11/22/23, 9:35‚ÄØPM - Amit: Ticket price ketli hati?
11/22/23, 9:35‚ÄØPM - Amit: Yes
11/22/23, 9:36‚ÄØPM - Siddharth: CC mostly
11/22/23, 9:36‚ÄØPM - Siddharth: 800 something
11/22/23, 9:36‚ÄØPM - Amit: To CC
11/22/23, 9:36‚ÄØPM - Amit: EC 1500 chhe
11/22/23, 9:37‚ÄØPM - Amit: General ma koi problem to noto nem
11/22/23, 9:37‚ÄØPM - Amit: ?
11/22/23, 9:37‚ÄØPM - Siddharth: Nope
11/22/23, 10:26‚ÄØPM - Amit: Booked Vande Bharat for 2nd Dec
11/22/23, 10:26‚ÄØPM - Siddharth: Great
11/22/23, 10:27‚ÄØPM - Siddharth: Hu Surat 3 ke 4 e aavish ho
11/22/23, 10:27‚ÄØPM - Amit: Amari sathe j aavi jaje
11/22/23, 10:27‚ÄØPM - Siddharth: Leave mate apply nai karu bhai, divse kaam karish, sanje farishu, okay ne?
11/22/23, 10:27‚ÄØPM - Siddharth: Hu jou chhu e
11/22/23, 10:27‚ÄØPM - Amit: Ha bhai.
WFH ma leave no levay
11/22/23, 10:28‚ÄØPM - Amit: Aree jovanu shu return ma sathe j aavi ja train ma
11/22/23, 10:28‚ÄØPM - Siddharth: Haan, and leave na lau to work load ochho re etle startup par kaam chalu re
11/22/23, 10:28‚ÄØPM - Siddharth: Kaish hu tane chal ne
11/22/23, 10:28‚ÄØPM - Amit: Ok
11/24/23, 4:44‚ÄØPM - Amit: <Media omitted>
11/27/23, 8:44‚ÄØAM - Amit: Bro what about Ayodhya?
11/27/23, 9:06‚ÄØAM - Siddharth: Karie vro
11/27/23, 10:53‚ÄØAM - Amit: Bro gpt je rite response dekhade ene kai style kevay?
11/27/23, 10:55‚ÄØAM - Siddharth: Matlab bhai?
11/27/23, 10:55‚ÄØAM - Amit: Arre chatgpt response ma je rite dsplay kare ne e. Looking like printing while thinking. <This message was edited>
11/27/23, 10:56‚ÄØAM - Siddharth: Streaming
11/27/23, 10:56‚ÄØAM - Amit: ok
11/27/23, 5:40‚ÄØPM - Amit: <Media omitted>
11/27/23, 5:40‚ÄØPM - Amit: <Media omitted>
11/27/23, 7:01‚ÄØPM - Amit: Can we change python version in render?
11/27/23, 7:15‚ÄØPM - Siddharth: Yes
11/27/23, 7:16‚ÄØPM - Amit: how?
11/27/23, 7:16‚ÄØPM - Siddharth: Nandu e karyu hatu thoda time pela, mostly settings ma
11/27/23, 7:16‚ÄØPM - Amit: ok
11/27/23, 7:16‚ÄØPM - Amit: ene puchhi lav
11/28/23, 9:02‚ÄØPM - Siddharth: Nandu na pela Thanos wala ne e pic chhe?
11/28/23, 9:03‚ÄØPM - Amit: Nai bro
11/28/23, 9:03‚ÄØPM - Siddharth: Okay, mali gaya
11/28/23, 9:03‚ÄØPM - Amit: Mane mokal
11/28/23, 9:03‚ÄØPM - Siddharth: Okay
11/28/23, 9:04‚ÄØPM - Siddharth: <Media omitted>
11/28/23, 9:04‚ÄØPM - Siddharth: <Media omitted>
11/28/23, 9:04‚ÄØPM - Siddharth: <Media omitted>
11/28/23, 9:04‚ÄØPM - Siddharth: <Media omitted>
11/28/23, 9:04‚ÄØPM - Siddharth: <Media omitted>
11/28/23, 9:04‚ÄØPM - Amit: Thanks
11/28/23, 9:48‚ÄØPM - Siddharth: https://github.com/h4cklinker/Backlinker

Check fast
11/28/23, 9:49‚ÄØPM - Amit: Atyare baar chhu ghare jaine run karu command
11/28/23, 9:49‚ÄØPM - Siddharth: Jaldi joi keje mane shu chhe aa exactly
11/28/23, 9:50‚ÄØPM - Amit: Ok
11/28/23, 9:52‚ÄØPM - Amit: https://github.com/h4cklinker/Backlinker/blob/master/urlbacklinks.json
11/28/23, 9:52‚ÄØPM - Amit: Code replace this ulrs with our website url
11/28/23, 9:52‚ÄØPM - Siddharth: Okay try kar
11/28/23, 9:52‚ÄØPM - Amit: Ghare jaine run karu
11/28/23, 9:53‚ÄØPM - Siddharth: Haa, aaje karje khali
11/28/23, 9:53‚ÄØPM - Amit: Aavu generator to mane pan malyu tu online.

But ema generate thayeli link safe noti.
11/28/23, 9:54‚ÄØPM - Amit: https://smallseotools.com/backlink-maker/
11/28/23, 9:54‚ÄØPM - Amit: This one
11/28/23, 9:54‚ÄØPM - Amit: Aa try karine tane kav
11/28/23, 9:55‚ÄØPM - Siddharth: Got it
11/29/23, 12:08‚ÄØPM - Siddharth: Bhai
11/29/23, 12:08‚ÄØPM - Siddharth: bhai
11/29/23, 12:08‚ÄØPM - Siddharth: bhai
11/29/23, 12:08‚ÄØPM - Siddharth: bhai
11/29/23, 12:08‚ÄØPM - Siddharth: bhai
11/29/23, 12:08‚ÄØPM - Siddharth: bhai
11/29/23, 12:09‚ÄØPM - Siddharth: bhai
11/29/23, 12:09‚ÄØPM - Siddharth: bhai
11/29/23, 12:09‚ÄØPM - Siddharth: bhai
11/29/23, 12:09‚ÄØPM - Siddharth: bhai
11/29/23, 12:09‚ÄØPM - Siddharth: bhai
11/29/23, 12:09‚ÄØPM - Amit: bol
11/29/23, 12:09‚ÄØPM - Siddharth: Convocation wala badha mail chhe ne
11/29/23, 12:09‚ÄØPM - Siddharth: E Smitpandya777@gmail.com forward kar plz
11/29/23, 12:09‚ÄØPM - Amit: ha
11/29/23, 12:09‚ÄØPM - Siddharth: Hu maari system ma nathi
11/29/23, 12:09‚ÄØPM - Amit: ok
11/29/23, 12:09‚ÄØPM - Siddharth: Thay etle ke mane
11/29/23, 12:11‚ÄØPM - Amit: done
11/29/23, 12:11‚ÄØPM - Siddharth: Cool
11/29/23, 1:09‚ÄØPM - Siddharth: Any update?
11/29/23, 1:09‚ÄØPM - Amit: Sorry bro bhuli gayo.
Hamna run karu script
11/29/23, 1:09‚ÄØPM - Siddharth: Okay bhai
11/29/23, 4:51‚ÄØPM - Amit: Kya hum medium pe gardening ke blog post kar sakte he?
11/29/23, 4:51‚ÄØPM - Siddharth: Haan

And reference ma niche aapni links
11/29/23, 4:52‚ÄØPM - Amit: Ha.
Matalab me soch raha hu blogs me ho sake utne plants dalu and har plant ki apni link
11/29/23, 4:52‚ÄØPM - Amit: SO multiple link in one blog
11/29/23, 4:52‚ÄØPM - Siddharth: Yes, start doing this
11/29/23, 4:52‚ÄØPM - Amit: ok
11/29/23, 4:52‚ÄØPM - Siddharth: Medium par high activity means high traffic
11/29/23, 4:53‚ÄØPM - Amit: And domain authority is also high means high quality backlinks
11/29/23, 4:53‚ÄØPM - Siddharth: Haan e j
11/29/23, 4:53‚ÄØPM - Amit: And aa blogs aapni website thi alag hashe ne?
11/29/23, 4:53‚ÄØPM - Siddharth: Same banne jagya e vro
11/29/23, 4:54‚ÄØPM - Siddharth: Lakhay chhe to have aapni site par pan nakhi j daishu ne
11/29/23, 4:54‚ÄØPM - Siddharth: Like, already je 8 blog chhe e j pela nakh Medium par bhai

Links wala changes kari deje bas
11/29/23, 4:54‚ÄØPM - Amit: I am thinking ke aapni site par alag content hoy to saru as compared to other content we post on other platforms
11/30/23, 8:45‚ÄØPM - Amit: Shree Ram vs Dragon tune generate kiya he?
11/30/23, 8:46‚ÄØPM - Siddharth: Haan
11/30/23, 8:46‚ÄØPM - Amit: Kyu IND vs CHINA?
11/30/23, 8:46‚ÄØPM - Siddharth: Yup
12/3/23, 9:01‚ÄØAM - Amit: <Media omitted>
12/3/23, 9:01‚ÄØAM - Amit: <Media omitted>
12/3/23, 9:27‚ÄØAM - Siddharth: Haan, moklya uncle e
12/5/23, 10:24‚ÄØAM - Amit: Ketla vagya ni train chhe?
12/5/23, 10:25‚ÄØAM - Siddharth: 2
12/5/23, 10:25‚ÄØAM - Amit: Sidho mara ghare aavavano ne?
12/5/23, 10:25‚ÄØAM - Siddharth: Na, aaje bhai sathe bahar javanu che, aavish hu pachhi
12/5/23, 10:25‚ÄØAM - Amit: Kyare?
12/5/23, 10:25‚ÄØAM - Siddharth: 10 days tya j chhu so no worries
12/5/23, 10:26‚ÄØAM - Amit: Pan kale sanje mari ghare jamanu chhe
12/5/23, 10:26‚ÄØAM - Siddharth: I will let you know.
12/5/23, 10:26‚ÄØAM - Amit: Naimish and Dhruvil pan chhe
12/5/23, 10:26‚ÄØAM - Siddharth: Okay, to done
12/5/23, 10:27‚ÄØAM - Amit: ema evu chhe pachhi marriage start thay chhe ne etle ghare koi nai hoy etle kale rakhyu chhe
12/5/23, 10:27‚ÄØAM - Siddharth: Got it
12/5/23, 10:27‚ÄØAM - Amit: To kale sanje mari ghare.
Bijo kai plan no banavto kal no
